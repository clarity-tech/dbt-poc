2021-04-14 11:34:44.264998 (MainThread): Running with dbt=0.19.1
2021-04-14 11:34:44.397337 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/home/msonowal/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-04-14 11:34:44.397790 (MainThread): Tracking: tracking
2021-04-14 11:34:44.403522 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc22bfd97c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc22a734af0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc22bffb9a0>]}
2021-04-14 11:34:44.408965 (MainThread): Partial parsing not enabled
2021-04-14 11:34:44.409484 (MainThread): Parsing macros/etc.sql
2021-04-14 11:34:44.411556 (MainThread): Parsing macros/adapters.sql
2021-04-14 11:34:44.423576 (MainThread): Parsing macros/catalog.sql
2021-04-14 11:34:44.427087 (MainThread): Parsing macros/materializations/seed.sql
2021-04-14 11:34:44.428822 (MainThread): Parsing macros/materializations/copy.sql
2021-04-14 11:34:44.431728 (MainThread): Parsing macros/materializations/table.sql
2021-04-14 11:34:44.438221 (MainThread): Parsing macros/materializations/incremental.sql
2021-04-14 11:34:44.446344 (MainThread): Parsing macros/materializations/view.sql
2021-04-14 11:34:44.448113 (MainThread): Parsing macros/materializations/snapshot.sql
2021-04-14 11:34:44.449648 (MainThread): Parsing macros/core.sql
2021-04-14 11:34:44.452104 (MainThread): Parsing macros/adapters/common.sql
2021-04-14 11:34:44.477835 (MainThread): Parsing macros/etc/is_incremental.sql
2021-04-14 11:34:44.478857 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-04-14 11:34:44.480102 (MainThread): Parsing macros/etc/query.sql
2021-04-14 11:34:44.480744 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-04-14 11:34:44.481313 (MainThread): Parsing macros/etc/datetime.sql
2021-04-14 11:34:44.486746 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-04-14 11:34:44.487752 (MainThread): Parsing macros/materializations/helpers.sql
2021-04-14 11:34:44.493057 (MainThread): Parsing macros/materializations/common/merge.sql
2021-04-14 11:34:44.501546 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-04-14 11:34:44.514493 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-04-14 11:34:44.518496 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-04-14 11:34:44.519639 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-04-14 11:34:44.522765 (MainThread): Parsing macros/materializations/view/view.sql
2021-04-14 11:34:44.526667 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-04-14 11:34:44.527748 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-04-14 11:34:44.546989 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-04-14 11:34:44.558370 (MainThread): Parsing macros/materializations/table/table.sql
2021-04-14 11:34:44.562563 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-04-14 11:34:44.564263 (MainThread): Parsing macros/schema_tests/unique.sql
2021-04-14 11:34:44.565284 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-04-14 11:34:44.566191 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-04-14 11:34:44.570451 (MainThread): Partial parsing not enabled
2021-04-14 11:34:44.585145 (MainThread): Acquiring new bigquery connection "model.dbt_poc.customers".
2021-04-14 11:34:44.590719 (MainThread): Acquiring new bigquery connection "model.dbt_poc.my_second_dbt_model".
2021-04-14 11:34:44.592884 (MainThread): Acquiring new bigquery connection "model.dbt_poc.my_first_dbt_model".
2021-04-14 11:34:44.632072 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5734965e-18a3-4502-ab3b-e070802adc09', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc229836820>]}
2021-04-14 11:34:44.634863 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5734965e-18a3-4502-ab3b-e070802adc09', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc22bf5eac0>]}
2021-04-14 11:34:44.634984 (MainThread): Found 3 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-04-14 11:34:44.635433 (MainThread): 
2021-04-14 11:34:44.635582 (MainThread): Acquiring new bigquery connection "master".
2021-04-14 11:34:44.636146 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_poc-dbt-310711".
2021-04-14 11:34:44.636318 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-04-14 11:34:45.730315 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "create_poc-dbt-310711_dbt_poc_ds".
2021-04-14 11:34:45.730567 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "create_poc-dbt-310711_dbt_poc_ds".
2021-04-14 11:34:45.730646 (ThreadPoolExecutor-0_0): Creating schema "poc-dbt-310711.dbt_poc_ds".
2021-04-14 11:34:45.730724 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state closed
2021-04-14 11:34:45.736643 (ThreadPoolExecutor-0_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-04-14 11:34:47.181228 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_poc-dbt-310711_dbt_poc_ds".
2021-04-14 11:34:47.181414 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-04-14 11:34:47.187344 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-04-14 11:34:47.187865 (ThreadPoolExecutor-1_0): unclosed <socket.socket fd=7, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.7', 49184), raddr=('142.250.196.170', 443)>
2021-04-14 11:34:47.187999 (ThreadPoolExecutor-1_0): unclosed <socket.socket fd=8, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.7', 54088), raddr=('142.250.67.42', 443)>
2021-04-14 11:34:48.239910 (MainThread): 17:04:48 | Concurrency: 1 threads (target='dev')
2021-04-14 11:34:48.240087 (MainThread): 17:04:48 | 
2021-04-14 11:34:48.241760 (Thread-1): Began running node model.dbt_poc.my_first_dbt_model
2021-04-14 11:34:48.242033 (Thread-1): 17:04:48 | 1 of 2 START table model dbt_poc_ds.my_first_dbt_model............... [RUN]
2021-04-14 11:34:48.242476 (Thread-1): Acquiring new bigquery connection "model.dbt_poc.my_first_dbt_model".
2021-04-14 11:34:48.242585 (Thread-1): Compiling model.dbt_poc.my_first_dbt_model
2021-04-14 11:34:48.244922 (Thread-1): Writing injected SQL for node "model.dbt_poc.my_first_dbt_model"
2021-04-14 11:34:48.245251 (Thread-1): finished collecting timing info
2021-04-14 11:34:48.272018 (Thread-1): Writing runtime SQL for node "model.dbt_poc.my_first_dbt_model"
2021-04-14 11:34:48.272244 (Thread-1): Opening a new connection, currently in state closed
2021-04-14 11:34:48.275368 (Thread-1): On model.dbt_poc.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "db_bigq_profile", "target_name": "dev", "node_id": "model.dbt_poc.my_first_dbt_model"} */


  create or replace table `poc-dbt-310711`.`dbt_poc_ds`.`my_first_dbt_model`
  
  
  OPTIONS()
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
    
2021-04-14 11:34:51.667764 (Thread-1): finished collecting timing info
2021-04-14 11:34:51.668162 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5734965e-18a3-4502-ab3b-e070802adc09', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc22981bca0>]}
2021-04-14 11:34:51.668464 (Thread-1): 17:04:51 | 1 of 2 OK created table model dbt_poc_ds.my_first_dbt_model.......... [CREATE TABLE (2.0 rows, 0.0 Bytes processed) in 3.43s]
2021-04-14 11:34:51.668584 (Thread-1): Finished running node model.dbt_poc.my_first_dbt_model
2021-04-14 11:34:51.669074 (Thread-1): Began running node model.dbt_poc.my_second_dbt_model
2021-04-14 11:34:51.669312 (Thread-1): 17:04:51 | 2 of 2 START view model dbt_poc_ds.my_second_dbt_model............... [RUN]
2021-04-14 11:34:51.669692 (Thread-1): Acquiring new bigquery connection "model.dbt_poc.my_second_dbt_model".
2021-04-14 11:34:51.669787 (Thread-1): Compiling model.dbt_poc.my_second_dbt_model
2021-04-14 11:34:51.670356 (Thread-1): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.7', 49192), raddr=('142.250.196.170', 443)>
2021-04-14 11:34:51.670483 (Thread-1): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.7', 54096), raddr=('142.250.67.42', 443)>
2021-04-14 11:34:51.672093 (Thread-1): Writing injected SQL for node "model.dbt_poc.my_second_dbt_model"
2021-04-14 11:34:51.672220 (Thread-1): finished collecting timing info
2021-04-14 11:34:51.682010 (Thread-1): Writing runtime SQL for node "model.dbt_poc.my_second_dbt_model"
2021-04-14 11:34:51.682132 (Thread-1): Opening a new connection, currently in state closed
2021-04-14 11:34:51.685137 (Thread-1): On model.dbt_poc.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "db_bigq_profile", "target_name": "dev", "node_id": "model.dbt_poc.my_second_dbt_model"} */


  create or replace view `poc-dbt-310711`.`dbt_poc_ds`.`my_second_dbt_model`
  OPTIONS()
  as -- Use the `ref` function to select from other models

select *
from `poc-dbt-310711`.`dbt_poc_ds`.`my_first_dbt_model`
where id = 1;


2021-04-14 11:34:53.130874 (Thread-1): finished collecting timing info
2021-04-14 11:34:53.131318 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5734965e-18a3-4502-ab3b-e070802adc09', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc22981bca0>]}
2021-04-14 11:34:53.131650 (Thread-1): 17:04:53 | 2 of 2 OK created view model dbt_poc_ds.my_second_dbt_model.......... [OK in 1.46s]
2021-04-14 11:34:53.131778 (Thread-1): Finished running node model.dbt_poc.my_second_dbt_model
2021-04-14 11:34:53.132520 (MainThread): Acquiring new bigquery connection "master".
2021-04-14 11:34:53.132724 (MainThread): 17:04:53 | 
2021-04-14 11:34:53.132803 (MainThread): 17:04:53 | Finished running 1 table model, 1 view model in 8.50s.
2021-04-14 11:34:53.132870 (MainThread): Connection 'master' was properly closed.
2021-04-14 11:34:53.132916 (MainThread): Connection 'model.dbt_poc.my_second_dbt_model' was properly closed.
2021-04-14 11:34:53.134292 (MainThread): unclosed <socket.socket fd=5, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.7', 49180), raddr=('142.250.196.170', 443)>
2021-04-14 11:34:53.135452 (MainThread): unclosed <socket.socket fd=6, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.7', 54084), raddr=('142.250.67.42', 443)>
2021-04-14 11:34:53.135549 (MainThread): unclosed <socket.socket fd=7, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.7', 49188), raddr=('142.250.196.170', 443)>
2021-04-14 11:34:53.135635 (MainThread): unclosed <socket.socket fd=8, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.7', 54092), raddr=('142.250.67.42', 443)>
2021-04-14 11:34:53.136740 (MainThread): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.7', 49196), raddr=('142.250.196.170', 443)>
2021-04-14 11:34:53.136818 (MainThread): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.7', 54100), raddr=('142.250.67.42', 443)>
2021-04-14 11:34:53.139407 (MainThread): 
2021-04-14 11:34:53.139503 (MainThread): Completed successfully
2021-04-14 11:34:53.139579 (MainThread): 
Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
2021-04-14 11:34:53.139693 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc2297cab80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc2297d25e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc228687310>]}
2021-04-14 11:34:53.139862 (MainThread): Flushing usage events
2021-04-14 11:36:50.956220 (MainThread): Running with dbt=0.19.1
2021-04-14 11:36:51.089869 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/home/msonowal/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-04-14 11:36:51.090232 (MainThread): Tracking: tracking
2021-04-14 11:36:51.096138 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f91e1b81820>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f91e0295b80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f91e1b96910>]}
2021-04-14 11:36:51.101511 (MainThread): Partial parsing not enabled
2021-04-14 11:36:51.102021 (MainThread): Parsing macros/etc.sql
2021-04-14 11:36:51.103743 (MainThread): Parsing macros/adapters.sql
2021-04-14 11:36:51.115694 (MainThread): Parsing macros/catalog.sql
2021-04-14 11:36:51.119174 (MainThread): Parsing macros/materializations/seed.sql
2021-04-14 11:36:51.120911 (MainThread): Parsing macros/materializations/copy.sql
2021-04-14 11:36:51.123844 (MainThread): Parsing macros/materializations/table.sql
2021-04-14 11:36:51.130373 (MainThread): Parsing macros/materializations/incremental.sql
2021-04-14 11:36:51.138575 (MainThread): Parsing macros/materializations/view.sql
2021-04-14 11:36:51.140374 (MainThread): Parsing macros/materializations/snapshot.sql
2021-04-14 11:36:51.141920 (MainThread): Parsing macros/core.sql
2021-04-14 11:36:51.144387 (MainThread): Parsing macros/adapters/common.sql
2021-04-14 11:36:51.170264 (MainThread): Parsing macros/etc/is_incremental.sql
2021-04-14 11:36:51.171287 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-04-14 11:36:51.172522 (MainThread): Parsing macros/etc/query.sql
2021-04-14 11:36:51.173164 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-04-14 11:36:51.173741 (MainThread): Parsing macros/etc/datetime.sql
2021-04-14 11:36:51.179373 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-04-14 11:36:51.180410 (MainThread): Parsing macros/materializations/helpers.sql
2021-04-14 11:36:51.185912 (MainThread): Parsing macros/materializations/common/merge.sql
2021-04-14 11:36:51.194558 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-04-14 11:36:51.207850 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-04-14 11:36:51.211906 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-04-14 11:36:51.213055 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-04-14 11:36:51.216194 (MainThread): Parsing macros/materializations/view/view.sql
2021-04-14 11:36:51.220207 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-04-14 11:36:51.221273 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-04-14 11:36:51.240406 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-04-14 11:36:51.252188 (MainThread): Parsing macros/materializations/table/table.sql
2021-04-14 11:36:51.256456 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-04-14 11:36:51.258145 (MainThread): Parsing macros/schema_tests/unique.sql
2021-04-14 11:36:51.259207 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-04-14 11:36:51.260145 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-04-14 11:36:51.264307 (MainThread): Partial parsing not enabled
2021-04-14 11:36:51.278662 (MainThread): Acquiring new bigquery connection "model.dbt_poc.customers".
2021-04-14 11:36:51.284204 (MainThread): Acquiring new bigquery connection "model.dbt_poc.my_second_dbt_model".
2021-04-14 11:36:51.286330 (MainThread): Acquiring new bigquery connection "model.dbt_poc.my_first_dbt_model".
2021-04-14 11:36:51.325612 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a3ed2853-4ecb-45ed-80c0-610b301d1071', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f91df28abb0>]}
2021-04-14 11:36:51.328405 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a3ed2853-4ecb-45ed-80c0-610b301d1071', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f91e1affa30>]}
2021-04-14 11:36:51.328517 (MainThread): Found 3 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-04-14 11:36:51.328952 (MainThread): 
2021-04-14 11:36:51.329099 (MainThread): Acquiring new bigquery connection "master".
2021-04-14 11:36:51.329774 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_poc-dbt-310711".
2021-04-14 11:36:51.330027 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-04-14 11:36:52.313205 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_poc-dbt-310711_dbt_poc_ds".
2021-04-14 11:36:52.313442 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-04-14 11:36:52.319410 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-04-14 11:36:53.287673 (MainThread): 17:06:53 | Concurrency: 1 threads (target='dev')
2021-04-14 11:36:53.287850 (MainThread): 17:06:53 | 
2021-04-14 11:36:53.289758 (Thread-1): Began running node model.dbt_poc.my_first_dbt_model
2021-04-14 11:36:53.290013 (Thread-1): 17:06:53 | 1 of 3 START table model dbt_poc_ds.my_first_dbt_model............... [RUN]
2021-04-14 11:36:53.290264 (Thread-1): Acquiring new bigquery connection "model.dbt_poc.my_first_dbt_model".
2021-04-14 11:36:53.290372 (Thread-1): Compiling model.dbt_poc.my_first_dbt_model
2021-04-14 11:36:53.292763 (Thread-1): Writing injected SQL for node "model.dbt_poc.my_first_dbt_model"
2021-04-14 11:36:53.293025 (Thread-1): finished collecting timing info
2021-04-14 11:36:53.307440 (Thread-1): Opening a new connection, currently in state closed
2021-04-14 11:36:53.310516 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-04-14 11:36:54.245915 (Thread-1): Writing runtime SQL for node "model.dbt_poc.my_first_dbt_model"
2021-04-14 11:36:54.246139 (Thread-1): On model.dbt_poc.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "db_bigq_profile", "target_name": "dev", "node_id": "model.dbt_poc.my_first_dbt_model"} */


  create or replace table `poc-dbt-310711`.`dbt_poc_ds`.`my_first_dbt_model`
  
  
  OPTIONS()
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
    
2021-04-14 11:36:56.788670 (Thread-1): finished collecting timing info
2021-04-14 11:36:56.788996 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a3ed2853-4ecb-45ed-80c0-610b301d1071', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f91df3269a0>]}
2021-04-14 11:36:56.789242 (Thread-1): 17:06:56 | 1 of 3 OK created table model dbt_poc_ds.my_first_dbt_model.......... [CREATE TABLE (2.0 rows, 0.0 Bytes processed) in 3.50s]
2021-04-14 11:36:56.789341 (Thread-1): Finished running node model.dbt_poc.my_first_dbt_model
2021-04-14 11:36:56.789431 (Thread-1): Began running node model.dbt_poc.customers
2021-04-14 11:36:56.789816 (Thread-1): 17:06:56 | 2 of 3 START view model dbt_poc_ds.customers......................... [RUN]
2021-04-14 11:36:56.790011 (Thread-1): Acquiring new bigquery connection "model.dbt_poc.customers".
2021-04-14 11:36:56.790085 (Thread-1): Compiling model.dbt_poc.customers
2021-04-14 11:36:56.791181 (Thread-1): Writing injected SQL for node "model.dbt_poc.customers"
2021-04-14 11:36:56.791352 (Thread-1): finished collecting timing info
2021-04-14 11:36:56.803997 (Thread-1): Writing runtime SQL for node "model.dbt_poc.customers"
2021-04-14 11:36:56.804132 (Thread-1): Opening a new connection, currently in state closed
2021-04-14 11:36:56.807190 (Thread-1): On model.dbt_poc.customers: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "db_bigq_profile", "target_name": "dev", "node_id": "model.dbt_poc.customers"} */


  create or replace view `poc-dbt-310711`.`dbt_poc_ds`.`customers`
  OPTIONS()
  as with customers as (

    select
        id as customer_id,
        first_name,
        last_name

    from `dbt-tutorial`.jaffle_shop.customers

),

orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from `dbt-tutorial`.jaffle_shop.orders

),

customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final;


2021-04-14 11:36:58.616611 (Thread-1): finished collecting timing info
2021-04-14 11:36:58.616856 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a3ed2853-4ecb-45ed-80c0-610b301d1071', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f91df4363a0>]}
2021-04-14 11:36:58.617027 (Thread-1): 17:06:58 | 2 of 3 OK created view model dbt_poc_ds.customers.................... [OK in 1.83s]
2021-04-14 11:36:58.617093 (Thread-1): Finished running node model.dbt_poc.customers
2021-04-14 11:36:58.617157 (Thread-1): Began running node model.dbt_poc.my_second_dbt_model
2021-04-14 11:36:58.617247 (Thread-1): 17:06:58 | 3 of 3 START view model dbt_poc_ds.my_second_dbt_model............... [RUN]
2021-04-14 11:36:58.617371 (Thread-1): Acquiring new bigquery connection "model.dbt_poc.my_second_dbt_model".
2021-04-14 11:36:58.617544 (Thread-1): Compiling model.dbt_poc.my_second_dbt_model
2021-04-14 11:36:58.618773 (Thread-1): Writing injected SQL for node "model.dbt_poc.my_second_dbt_model"
2021-04-14 11:36:58.618933 (Thread-1): finished collecting timing info
2021-04-14 11:36:58.619889 (Thread-1): Writing runtime SQL for node "model.dbt_poc.my_second_dbt_model"
2021-04-14 11:36:58.620021 (Thread-1): Opening a new connection, currently in state closed
2021-04-14 11:36:58.623075 (Thread-1): On model.dbt_poc.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "db_bigq_profile", "target_name": "dev", "node_id": "model.dbt_poc.my_second_dbt_model"} */


  create or replace view `poc-dbt-310711`.`dbt_poc_ds`.`my_second_dbt_model`
  OPTIONS()
  as -- Use the `ref` function to select from other models

select *
from `poc-dbt-310711`.`dbt_poc_ds`.`my_first_dbt_model`
where id = 1;


2021-04-14 11:36:58.624820 (Thread-1): unclosed <socket.socket fd=5, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.7', 49230), raddr=('142.250.196.170', 443)>
2021-04-14 11:36:58.624908 (Thread-1): unclosed <socket.socket fd=6, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.7', 54134), raddr=('142.250.67.42', 443)>
2021-04-14 11:36:58.624962 (Thread-1): unclosed <socket.socket fd=8, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.7', 54138), raddr=('142.250.67.42', 443)>
2021-04-14 11:36:58.625021 (Thread-1): unclosed <socket.socket fd=7, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.7', 49234), raddr=('142.250.196.170', 443)>
2021-04-14 11:36:58.625081 (Thread-1): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.7', 54142), raddr=('142.250.67.42', 443)>
2021-04-14 11:36:58.625138 (Thread-1): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.7', 49238), raddr=('142.250.196.170', 443)>
2021-04-14 11:36:58.625202 (Thread-1): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.7', 49242), raddr=('142.250.196.170', 443)>
2021-04-14 11:36:58.625252 (Thread-1): unclosed <socket.socket fd=14, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.7', 54146), raddr=('142.250.67.42', 443)>
2021-04-14 11:37:00.359382 (Thread-1): finished collecting timing info
2021-04-14 11:37:00.359809 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a3ed2853-4ecb-45ed-80c0-610b301d1071', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f91df326ac0>]}
2021-04-14 11:37:00.360128 (Thread-1): 17:07:00 | 3 of 3 OK created view model dbt_poc_ds.my_second_dbt_model.......... [OK in 1.74s]
2021-04-14 11:37:00.360252 (Thread-1): Finished running node model.dbt_poc.my_second_dbt_model
2021-04-14 11:37:00.361244 (MainThread): Acquiring new bigquery connection "master".
2021-04-14 11:37:00.361532 (MainThread): 17:07:00 | 
2021-04-14 11:37:00.361656 (MainThread): 17:07:00 | Finished running 1 table model, 2 view models in 9.03s.
2021-04-14 11:37:00.361754 (MainThread): Connection 'master' was properly closed.
2021-04-14 11:37:00.361831 (MainThread): Connection 'model.dbt_poc.my_second_dbt_model' was properly closed.
2021-04-14 11:37:00.365978 (MainThread): 
2021-04-14 11:37:00.366113 (MainThread): Completed successfully
2021-04-14 11:37:00.366216 (MainThread): 
Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
2021-04-14 11:37:00.366364 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f91df2d0190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f91df2e1a00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f91df2e19d0>]}
2021-04-14 11:37:00.366545 (MainThread): Flushing usage events
2021-04-14 11:42:49.761533 (MainThread): Running with dbt=0.19.1
2021-04-14 11:42:49.893496 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/home/msonowal/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-04-14 11:42:49.893859 (MainThread): Tracking: tracking
2021-04-14 11:42:49.899793 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f332b77b760>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3329e98df0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f332b77a940>]}
2021-04-14 11:42:49.905065 (MainThread): Partial parsing not enabled
2021-04-14 11:42:49.905568 (MainThread): Parsing macros/etc.sql
2021-04-14 11:42:49.907241 (MainThread): Parsing macros/adapters.sql
2021-04-14 11:42:49.918866 (MainThread): Parsing macros/catalog.sql
2021-04-14 11:42:49.922269 (MainThread): Parsing macros/materializations/seed.sql
2021-04-14 11:42:49.923985 (MainThread): Parsing macros/materializations/copy.sql
2021-04-14 11:42:49.926934 (MainThread): Parsing macros/materializations/table.sql
2021-04-14 11:42:49.933315 (MainThread): Parsing macros/materializations/incremental.sql
2021-04-14 11:42:49.941419 (MainThread): Parsing macros/materializations/view.sql
2021-04-14 11:42:49.943181 (MainThread): Parsing macros/materializations/snapshot.sql
2021-04-14 11:42:49.944669 (MainThread): Parsing macros/core.sql
2021-04-14 11:42:49.947111 (MainThread): Parsing macros/adapters/common.sql
2021-04-14 11:42:49.972304 (MainThread): Parsing macros/etc/is_incremental.sql
2021-04-14 11:42:49.973306 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-04-14 11:42:49.974519 (MainThread): Parsing macros/etc/query.sql
2021-04-14 11:42:49.975170 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-04-14 11:42:49.975731 (MainThread): Parsing macros/etc/datetime.sql
2021-04-14 11:42:49.981447 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-04-14 11:42:49.982532 (MainThread): Parsing macros/materializations/helpers.sql
2021-04-14 11:42:49.987921 (MainThread): Parsing macros/materializations/common/merge.sql
2021-04-14 11:42:49.996510 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-04-14 11:42:50.009463 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-04-14 11:42:50.013578 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-04-14 11:42:50.014715 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-04-14 11:42:50.017775 (MainThread): Parsing macros/materializations/view/view.sql
2021-04-14 11:42:50.021648 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-04-14 11:42:50.022693 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-04-14 11:42:50.041125 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-04-14 11:42:50.052423 (MainThread): Parsing macros/materializations/table/table.sql
2021-04-14 11:42:50.056526 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-04-14 11:42:50.058144 (MainThread): Parsing macros/schema_tests/unique.sql
2021-04-14 11:42:50.059173 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-04-14 11:42:50.060081 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-04-14 11:42:50.064160 (MainThread): Partial parsing not enabled
2021-04-14 11:42:50.078441 (MainThread): Acquiring new bigquery connection "model.dbt_poc.customers".
2021-04-14 11:42:50.084660 (MainThread): Acquiring new bigquery connection "model.dbt_poc.my_second_dbt_model".
2021-04-14 11:42:50.086776 (MainThread): Acquiring new bigquery connection "model.dbt_poc.my_first_dbt_model".
2021-04-14 11:42:50.126084 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'dfc7f988-5eb6-4e60-a349-5af1bea5fc12', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3328e8dbe0>]}
2021-04-14 11:42:50.128924 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'dfc7f988-5eb6-4e60-a349-5af1bea5fc12', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f332b6fe760>]}
2021-04-14 11:42:50.129036 (MainThread): Found 3 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-04-14 11:42:50.129466 (MainThread): 
2021-04-14 11:42:50.129624 (MainThread): Acquiring new bigquery connection "master".
2021-04-14 11:42:50.130388 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_poc-dbt-310711".
2021-04-14 11:42:50.130659 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-04-14 11:42:50.924107 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_poc-dbt-310711_dbt_poc_ds".
2021-04-14 11:42:50.924344 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-04-14 11:42:50.930024 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-04-14 11:42:51.920645 (MainThread): 17:12:51 | Concurrency: 1 threads (target='dev')
2021-04-14 11:42:51.920824 (MainThread): 17:12:51 | 
2021-04-14 11:42:51.922723 (Thread-1): Began running node model.dbt_poc.my_first_dbt_model
2021-04-14 11:42:51.923017 (Thread-1): 17:12:51 | 1 of 3 START table model dbt_poc_ds.my_first_dbt_model............... [RUN]
2021-04-14 11:42:51.923282 (Thread-1): Acquiring new bigquery connection "model.dbt_poc.my_first_dbt_model".
2021-04-14 11:42:51.923387 (Thread-1): Compiling model.dbt_poc.my_first_dbt_model
2021-04-14 11:42:51.925816 (Thread-1): Writing injected SQL for node "model.dbt_poc.my_first_dbt_model"
2021-04-14 11:42:51.926083 (Thread-1): finished collecting timing info
2021-04-14 11:42:51.942217 (Thread-1): Opening a new connection, currently in state closed
2021-04-14 11:42:51.945365 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-04-14 11:42:52.951115 (Thread-1): Writing runtime SQL for node "model.dbt_poc.my_first_dbt_model"
2021-04-14 11:42:52.951336 (Thread-1): On model.dbt_poc.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "db_bigq_profile", "target_name": "dev", "node_id": "model.dbt_poc.my_first_dbt_model"} */


  create or replace table `poc-dbt-310711`.`dbt_poc_ds`.`my_first_dbt_model`
  
  
  OPTIONS()
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
    
2021-04-14 11:42:55.553563 (Thread-1): finished collecting timing info
2021-04-14 11:42:55.553965 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dfc7f988-5eb6-4e60-a349-5af1bea5fc12', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f332903be50>]}
2021-04-14 11:42:55.554278 (Thread-1): 17:12:55 | 1 of 3 OK created table model dbt_poc_ds.my_first_dbt_model.......... [CREATE TABLE (2.0 rows, 0.0 Bytes processed) in 3.63s]
2021-04-14 11:42:55.554399 (Thread-1): Finished running node model.dbt_poc.my_first_dbt_model
2021-04-14 11:42:55.554523 (Thread-1): Began running node model.dbt_poc.customers
2021-04-14 11:42:55.554693 (Thread-1): 17:12:55 | 2 of 3 START table model dbt_poc_ds.customers........................ [RUN]
2021-04-14 11:42:55.555087 (Thread-1): Acquiring new bigquery connection "model.dbt_poc.customers".
2021-04-14 11:42:55.555279 (Thread-1): Compiling model.dbt_poc.customers
2021-04-14 11:42:55.557173 (Thread-1): Writing injected SQL for node "model.dbt_poc.customers"
2021-04-14 11:42:55.557384 (Thread-1): finished collecting timing info
2021-04-14 11:42:55.558551 (Thread-1): Opening a new connection, currently in state closed
2021-04-14 11:42:55.563388 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-04-14 11:42:56.531969 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-04-14 11:42:56.872217 (Thread-1): Writing runtime SQL for node "model.dbt_poc.customers"
2021-04-14 11:42:56.872557 (Thread-1): On model.dbt_poc.customers: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "db_bigq_profile", "target_name": "dev", "node_id": "model.dbt_poc.customers"} */


  create or replace table `poc-dbt-310711`.`dbt_poc_ds`.`customers`
  
  
  OPTIONS()
  as (
    

with customers as (

    select
        id as customer_id,
        first_name,
        last_name

    from `dbt-tutorial`.jaffle_shop.customers

),

orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from `dbt-tutorial`.jaffle_shop.orders

),

customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final
  );
    
2021-04-14 11:42:59.538212 (Thread-1): finished collecting timing info
2021-04-14 11:42:59.538677 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dfc7f988-5eb6-4e60-a349-5af1bea5fc12', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f33285c0e20>]}
2021-04-14 11:42:59.539078 (Thread-1): 17:12:59 | 2 of 3 OK created table model dbt_poc_ds.customers................... [CREATE TABLE (100.0 rows, 4.3 KB processed) in 3.98s]
2021-04-14 11:42:59.539285 (Thread-1): Finished running node model.dbt_poc.customers
2021-04-14 11:42:59.539493 (Thread-1): Began running node model.dbt_poc.my_second_dbt_model
2021-04-14 11:42:59.539940 (Thread-1): 17:12:59 | 3 of 3 START view model dbt_poc_ds.my_second_dbt_model............... [RUN]
2021-04-14 11:42:59.540371 (Thread-1): Acquiring new bigquery connection "model.dbt_poc.my_second_dbt_model".
2021-04-14 11:42:59.540536 (Thread-1): Compiling model.dbt_poc.my_second_dbt_model
2021-04-14 11:42:59.543397 (Thread-1): Writing injected SQL for node "model.dbt_poc.my_second_dbt_model"
2021-04-14 11:42:59.543675 (Thread-1): finished collecting timing info
2021-04-14 11:42:59.555695 (Thread-1): Writing runtime SQL for node "model.dbt_poc.my_second_dbt_model"
2021-04-14 11:42:59.555942 (Thread-1): Opening a new connection, currently in state closed
2021-04-14 11:42:59.559060 (Thread-1): On model.dbt_poc.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "db_bigq_profile", "target_name": "dev", "node_id": "model.dbt_poc.my_second_dbt_model"} */


  create or replace view `poc-dbt-310711`.`dbt_poc_ds`.`my_second_dbt_model`
  OPTIONS()
  as -- Use the `ref` function to select from other models

select *
from `poc-dbt-310711`.`dbt_poc_ds`.`my_first_dbt_model`
where id = 1;


2021-04-14 11:42:59.559767 (Thread-1): unclosed <socket.socket fd=5, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.7', 44176), raddr=('172.217.167.138', 443)>
2021-04-14 11:42:59.559853 (Thread-1): unclosed <socket.socket fd=6, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.7', 54230), raddr=('142.250.67.42', 443)>
2021-04-14 11:42:59.559904 (Thread-1): unclosed <socket.socket fd=8, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.7', 54234), raddr=('142.250.67.42', 443)>
2021-04-14 11:42:59.559961 (Thread-1): unclosed <socket.socket fd=7, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.7', 44180), raddr=('172.217.167.138', 443)>
2021-04-14 11:42:59.560018 (Thread-1): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.7', 54238), raddr=('142.250.67.42', 443)>
2021-04-14 11:42:59.560073 (Thread-1): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.7', 44184), raddr=('172.217.167.138', 443)>
2021-04-14 11:42:59.560129 (Thread-1): unclosed <socket.socket fd=14, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.7', 54244), raddr=('142.250.67.42', 443)>
2021-04-14 11:42:59.560183 (Thread-1): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.7', 44190), raddr=('172.217.167.138', 443)>
2021-04-14 11:43:01.258203 (Thread-1): finished collecting timing info
2021-04-14 11:43:01.258597 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dfc7f988-5eb6-4e60-a349-5af1bea5fc12', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3328f11b20>]}
2021-04-14 11:43:01.258898 (Thread-1): 17:13:01 | 3 of 3 OK created view model dbt_poc_ds.my_second_dbt_model.......... [OK in 1.72s]
2021-04-14 11:43:01.259042 (Thread-1): Finished running node model.dbt_poc.my_second_dbt_model
2021-04-14 11:43:01.260035 (MainThread): Acquiring new bigquery connection "master".
2021-04-14 11:43:01.260344 (MainThread): 17:13:01 | 
2021-04-14 11:43:01.260495 (MainThread): 17:13:01 | Finished running 2 table models, 1 view model in 11.13s.
2021-04-14 11:43:01.260602 (MainThread): Connection 'master' was properly closed.
2021-04-14 11:43:01.260667 (MainThread): Connection 'model.dbt_poc.my_second_dbt_model' was properly closed.
2021-04-14 11:43:01.264898 (MainThread): 
2021-04-14 11:43:01.265032 (MainThread): Completed successfully
2021-04-14 11:43:01.265150 (MainThread): 
Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
2021-04-14 11:43:01.265302 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3328fa26a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3328eeddf0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3328fa8760>]}
2021-04-14 11:43:01.265470 (MainThread): Flushing usage events
2021-04-14 11:46:23.529446 (MainThread): Running with dbt=0.19.1
2021-04-14 11:46:23.666204 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/home/msonowal/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-04-14 11:46:23.666584 (MainThread): Tracking: tracking
2021-04-14 11:46:23.672370 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f10e3e20070>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f10e257cc10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f10e3e429a0>]}
2021-04-14 11:46:23.677849 (MainThread): Partial parsing not enabled
2021-04-14 11:46:23.678375 (MainThread): Parsing macros/etc.sql
2021-04-14 11:46:23.680094 (MainThread): Parsing macros/adapters.sql
2021-04-14 11:46:23.692151 (MainThread): Parsing macros/catalog.sql
2021-04-14 11:46:23.695533 (MainThread): Parsing macros/materializations/seed.sql
2021-04-14 11:46:23.697256 (MainThread): Parsing macros/materializations/copy.sql
2021-04-14 11:46:23.700120 (MainThread): Parsing macros/materializations/table.sql
2021-04-14 11:46:23.706474 (MainThread): Parsing macros/materializations/incremental.sql
2021-04-14 11:46:23.714420 (MainThread): Parsing macros/materializations/view.sql
2021-04-14 11:46:23.716182 (MainThread): Parsing macros/materializations/snapshot.sql
2021-04-14 11:46:23.717683 (MainThread): Parsing macros/core.sql
2021-04-14 11:46:23.720106 (MainThread): Parsing macros/adapters/common.sql
2021-04-14 11:46:23.745929 (MainThread): Parsing macros/etc/is_incremental.sql
2021-04-14 11:46:23.746932 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-04-14 11:46:23.748145 (MainThread): Parsing macros/etc/query.sql
2021-04-14 11:46:23.748791 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-04-14 11:46:23.749360 (MainThread): Parsing macros/etc/datetime.sql
2021-04-14 11:46:23.755020 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-04-14 11:46:23.756041 (MainThread): Parsing macros/materializations/helpers.sql
2021-04-14 11:46:23.761603 (MainThread): Parsing macros/materializations/common/merge.sql
2021-04-14 11:46:23.770063 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-04-14 11:46:23.782873 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-04-14 11:46:23.786873 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-04-14 11:46:23.788068 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-04-14 11:46:23.791214 (MainThread): Parsing macros/materializations/view/view.sql
2021-04-14 11:46:23.795185 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-04-14 11:46:23.796247 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-04-14 11:46:23.815893 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-04-14 11:46:23.827465 (MainThread): Parsing macros/materializations/table/table.sql
2021-04-14 11:46:23.831770 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-04-14 11:46:23.833500 (MainThread): Parsing macros/schema_tests/unique.sql
2021-04-14 11:46:23.834549 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-04-14 11:46:23.835507 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-04-14 11:46:23.839717 (MainThread): Partial parsing not enabled
2021-04-14 11:46:23.853898 (MainThread): Acquiring new bigquery connection "model.dbt_poc.customers".
2021-04-14 11:46:23.860031 (MainThread): Acquiring new bigquery connection "model.dbt_poc.my_second_dbt_model".
2021-04-14 11:46:23.862173 (MainThread): Acquiring new bigquery connection "model.dbt_poc.my_first_dbt_model".
2021-04-14 11:46:23.901058 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '30794f76-0370-4b51-a299-8a992e6ad190', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f10e16b2d00>]}
2021-04-14 11:46:23.903963 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '30794f76-0370-4b51-a299-8a992e6ad190', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f10e3da57c0>]}
2021-04-14 11:46:23.904079 (MainThread): Found 3 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-04-14 11:46:23.904534 (MainThread): 
2021-04-14 11:46:23.904697 (MainThread): Acquiring new bigquery connection "master".
2021-04-14 11:46:23.905299 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_poc-dbt-310711".
2021-04-14 11:46:23.905477 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-04-14 11:46:25.028216 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_poc-dbt-310711_dbt_poc_ds".
2021-04-14 11:46:25.028461 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-04-14 11:46:25.034540 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-04-14 11:46:26.065964 (MainThread): 17:16:26 | Concurrency: 4 threads (target='dev')
2021-04-14 11:46:26.066163 (MainThread): 17:16:26 | 
2021-04-14 11:46:26.068220 (Thread-1): Began running node model.dbt_poc.my_first_dbt_model
2021-04-14 11:46:26.068391 (Thread-2): Began running node model.dbt_poc.customers
2021-04-14 11:46:26.068641 (Thread-1): 17:16:26 | 1 of 3 START table model dbt_poc_ds.my_first_dbt_model............... [RUN]
2021-04-14 11:46:26.068838 (Thread-2): 17:16:26 | 2 of 3 START table model dbt_poc_ds.customers........................ [RUN]
2021-04-14 11:46:26.069134 (Thread-1): Acquiring new bigquery connection "model.dbt_poc.my_first_dbt_model".
2021-04-14 11:46:26.069491 (Thread-2): Acquiring new bigquery connection "model.dbt_poc.customers".
2021-04-14 11:46:26.069623 (Thread-1): Compiling model.dbt_poc.my_first_dbt_model
2021-04-14 11:46:26.069756 (Thread-2): Compiling model.dbt_poc.customers
2021-04-14 11:46:26.072257 (Thread-1): Writing injected SQL for node "model.dbt_poc.my_first_dbt_model"
2021-04-14 11:46:26.074402 (Thread-2): Writing injected SQL for node "model.dbt_poc.customers"
2021-04-14 11:46:26.074729 (Thread-2): finished collecting timing info
2021-04-14 11:46:26.074841 (Thread-1): finished collecting timing info
2021-04-14 11:46:26.100364 (Thread-2): Opening a new connection, currently in state init
2021-04-14 11:46:26.104856 (Thread-1): Opening a new connection, currently in state closed
2021-04-14 11:46:26.110571 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-04-14 11:46:26.111192 (Thread-2): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-04-14 11:46:27.059167 (Thread-2): Writing runtime SQL for node "model.dbt_poc.customers"
2021-04-14 11:46:27.059402 (Thread-2): On model.dbt_poc.customers: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "db_bigq_profile", "target_name": "dev", "node_id": "model.dbt_poc.customers"} */


  create or replace table `poc-dbt-310711`.`dbt_poc_ds`.`customers`
  
  
  OPTIONS()
  as (
    

with customers as (

    select
        id as customer_id,
        first_name,
        last_name

    from `dbt-tutorial`.jaffle_shop.customers

),

orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from `dbt-tutorial`.jaffle_shop.orders

),

customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final
  );
    
2021-04-14 11:46:27.099417 (Thread-1): Writing runtime SQL for node "model.dbt_poc.my_first_dbt_model"
2021-04-14 11:46:27.099798 (Thread-1): On model.dbt_poc.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "db_bigq_profile", "target_name": "dev", "node_id": "model.dbt_poc.my_first_dbt_model"} */


  create or replace table `poc-dbt-310711`.`dbt_poc_ds`.`my_first_dbt_model`
  
  
  OPTIONS()
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
    
2021-04-14 11:46:29.421670 (Thread-1): finished collecting timing info
2021-04-14 11:46:29.422018 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '30794f76-0370-4b51-a299-8a992e6ad190', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f10e0d0abe0>]}
2021-04-14 11:46:29.422272 (Thread-1): 17:16:29 | 1 of 3 OK created table model dbt_poc_ds.my_first_dbt_model.......... [CREATE TABLE (2.0 rows, 0.0 Bytes processed) in 3.35s]
2021-04-14 11:46:29.422377 (Thread-1): Finished running node model.dbt_poc.my_first_dbt_model
2021-04-14 11:46:29.422814 (Thread-4): Began running node model.dbt_poc.my_second_dbt_model
2021-04-14 11:46:29.423146 (Thread-4): 17:16:29 | 3 of 3 START view model dbt_poc_ds.my_second_dbt_model............... [RUN]
2021-04-14 11:46:29.423473 (Thread-4): Acquiring new bigquery connection "model.dbt_poc.my_second_dbt_model".
2021-04-14 11:46:29.423582 (Thread-4): Compiling model.dbt_poc.my_second_dbt_model
2021-04-14 11:46:29.426075 (Thread-4): Writing injected SQL for node "model.dbt_poc.my_second_dbt_model"
2021-04-14 11:46:29.426349 (Thread-4): finished collecting timing info
2021-04-14 11:46:29.428843 (Thread-4): unclosed <socket.socket fd=5, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.7', 44336), raddr=('172.217.167.138', 443)>
2021-04-14 11:46:29.429014 (Thread-4): unclosed <socket.socket fd=6, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.7', 54390), raddr=('142.250.67.42', 443)>
2021-04-14 11:46:29.429117 (Thread-4): unclosed <socket.socket fd=8, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.7', 54394), raddr=('142.250.67.42', 443)>
2021-04-14 11:46:29.429221 (Thread-4): unclosed <socket.socket fd=7, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.7', 44340), raddr=('172.217.167.138', 443)>
2021-04-14 11:46:29.440015 (Thread-4): Writing runtime SQL for node "model.dbt_poc.my_second_dbt_model"
2021-04-14 11:46:29.440206 (Thread-4): Opening a new connection, currently in state init
2021-04-14 11:46:29.443231 (Thread-4): On model.dbt_poc.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "db_bigq_profile", "target_name": "dev", "node_id": "model.dbt_poc.my_second_dbt_model"} */


  create or replace view `poc-dbt-310711`.`dbt_poc_ds`.`my_second_dbt_model`
  OPTIONS()
  as -- Use the `ref` function to select from other models

select *
from `poc-dbt-310711`.`dbt_poc_ds`.`my_first_dbt_model`
where id = 1;


2021-04-14 11:46:30.067181 (Thread-2): finished collecting timing info
2021-04-14 11:46:30.067586 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '30794f76-0370-4b51-a299-8a992e6ad190', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f10e1723160>]}
2021-04-14 11:46:30.067891 (Thread-2): 17:16:30 | 2 of 3 OK created table model dbt_poc_ds.customers................... [CREATE TABLE (100.0 rows, 4.3 KB processed) in 4.00s]
2021-04-14 11:46:30.068015 (Thread-2): Finished running node model.dbt_poc.customers
2021-04-14 11:46:31.173232 (Thread-4): finished collecting timing info
2021-04-14 11:46:31.173619 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '30794f76-0370-4b51-a299-8a992e6ad190', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f10e15f6070>]}
2021-04-14 11:46:31.173915 (Thread-4): 17:16:31 | 3 of 3 OK created view model dbt_poc_ds.my_second_dbt_model.......... [OK in 1.75s]
2021-04-14 11:46:31.174041 (Thread-4): Finished running node model.dbt_poc.my_second_dbt_model
2021-04-14 11:46:31.175272 (MainThread): Acquiring new bigquery connection "master".
2021-04-14 11:46:31.175618 (MainThread): 17:16:31 | 
2021-04-14 11:46:31.175730 (MainThread): 17:16:31 | Finished running 2 table models, 1 view model in 7.27s.
2021-04-14 11:46:31.175815 (MainThread): Connection 'master' was properly closed.
2021-04-14 11:46:31.175876 (MainThread): Connection 'model.dbt_poc.my_first_dbt_model' was properly closed.
2021-04-14 11:46:31.175932 (MainThread): Connection 'model.dbt_poc.customers' was properly closed.
2021-04-14 11:46:31.175985 (MainThread): Connection 'model.dbt_poc.my_second_dbt_model' was properly closed.
2021-04-14 11:46:31.177196 (MainThread): unclosed <socket.socket fd=5, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.7', 44352), raddr=('172.217.167.138', 443)>
2021-04-14 11:46:31.177335 (MainThread): unclosed <socket.socket fd=6, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.7', 54406), raddr=('142.250.67.42', 443)>
2021-04-14 11:46:31.180224 (MainThread): 
2021-04-14 11:46:31.180318 (MainThread): Completed successfully
2021-04-14 11:46:31.180397 (MainThread): 
Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
2021-04-14 11:46:31.180515 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f10e15bf670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f10e044d910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f10e15c86d0>]}
2021-04-14 11:46:31.180654 (MainThread): Flushing usage events
2021-04-14 11:46:41.745347 (MainThread): Running with dbt=0.19.1
2021-04-14 11:46:41.884120 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/home/msonowal/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-04-14 11:46:41.884506 (MainThread): Tracking: tracking
2021-04-14 11:46:41.890536 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedb6124640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedb4832b20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedb61388e0>]}
2021-04-14 11:46:41.896115 (MainThread): Partial parsing not enabled
2021-04-14 11:46:41.896641 (MainThread): Parsing macros/etc.sql
2021-04-14 11:46:41.898372 (MainThread): Parsing macros/adapters.sql
2021-04-14 11:46:41.910562 (MainThread): Parsing macros/catalog.sql
2021-04-14 11:46:41.914066 (MainThread): Parsing macros/materializations/seed.sql
2021-04-14 11:46:41.915848 (MainThread): Parsing macros/materializations/copy.sql
2021-04-14 11:46:41.918814 (MainThread): Parsing macros/materializations/table.sql
2021-04-14 11:46:41.925749 (MainThread): Parsing macros/materializations/incremental.sql
2021-04-14 11:46:41.934496 (MainThread): Parsing macros/materializations/view.sql
2021-04-14 11:46:41.936316 (MainThread): Parsing macros/materializations/snapshot.sql
2021-04-14 11:46:41.937878 (MainThread): Parsing macros/core.sql
2021-04-14 11:46:41.940291 (MainThread): Parsing macros/adapters/common.sql
2021-04-14 11:46:41.966613 (MainThread): Parsing macros/etc/is_incremental.sql
2021-04-14 11:46:41.967655 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-04-14 11:46:41.968881 (MainThread): Parsing macros/etc/query.sql
2021-04-14 11:46:41.969574 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-04-14 11:46:41.970139 (MainThread): Parsing macros/etc/datetime.sql
2021-04-14 11:46:41.975778 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-04-14 11:46:41.976938 (MainThread): Parsing macros/materializations/helpers.sql
2021-04-14 11:46:41.982833 (MainThread): Parsing macros/materializations/common/merge.sql
2021-04-14 11:46:41.991942 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-04-14 11:46:42.005104 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-04-14 11:46:42.009177 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-04-14 11:46:42.010315 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-04-14 11:46:42.013512 (MainThread): Parsing macros/materializations/view/view.sql
2021-04-14 11:46:42.017518 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-04-14 11:46:42.018729 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-04-14 11:46:42.038400 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-04-14 11:46:42.050313 (MainThread): Parsing macros/materializations/table/table.sql
2021-04-14 11:46:42.055069 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-04-14 11:46:42.056769 (MainThread): Parsing macros/schema_tests/unique.sql
2021-04-14 11:46:42.057829 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-04-14 11:46:42.058766 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-04-14 11:46:42.063082 (MainThread): Partial parsing not enabled
2021-04-14 11:46:42.077687 (MainThread): Acquiring new bigquery connection "model.dbt_poc.customers".
2021-04-14 11:46:42.083332 (MainThread): Acquiring new bigquery connection "model.dbt_poc.my_second_dbt_model".
2021-04-14 11:46:42.085447 (MainThread): Acquiring new bigquery connection "model.dbt_poc.my_first_dbt_model".
2021-04-14 11:46:42.126333 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ada53eb5-1747-4d0c-b7bf-d5caa7733553', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedb3828b80>]}
2021-04-14 11:46:42.129194 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ada53eb5-1747-4d0c-b7bf-d5caa7733553', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedb60acc70>]}
2021-04-14 11:46:42.129310 (MainThread): Found 3 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-04-14 11:46:42.129769 (MainThread): 
2021-04-14 11:46:42.129925 (MainThread): Acquiring new bigquery connection "master".
2021-04-14 11:46:42.130514 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_poc-dbt-310711".
2021-04-14 11:46:42.130695 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-04-14 11:46:43.080164 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_poc-dbt-310711_dbt_poc_ds".
2021-04-14 11:46:43.080411 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-04-14 11:46:43.085861 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-04-14 11:46:44.048715 (MainThread): 17:16:44 | Concurrency: 4 threads (target='dev')
2021-04-14 11:46:44.048913 (MainThread): 17:16:44 | 
2021-04-14 11:46:44.051178 (Thread-1): Began running node model.dbt_poc.my_first_dbt_model
2021-04-14 11:46:44.051366 (Thread-2): Began running node model.dbt_poc.customers
2021-04-14 11:46:44.051619 (Thread-1): 17:16:44 | 1 of 3 START table model dbt_poc_ds.my_first_dbt_model............... [RUN]
2021-04-14 11:46:44.051830 (Thread-2): 17:16:44 | 2 of 3 START table model dbt_poc_ds.customers........................ [RUN]
2021-04-14 11:46:44.052123 (Thread-1): Acquiring new bigquery connection "model.dbt_poc.my_first_dbt_model".
2021-04-14 11:46:44.052422 (Thread-2): Acquiring new bigquery connection "model.dbt_poc.customers".
2021-04-14 11:46:44.052544 (Thread-1): Compiling model.dbt_poc.my_first_dbt_model
2021-04-14 11:46:44.052658 (Thread-2): Compiling model.dbt_poc.customers
2021-04-14 11:46:44.055147 (Thread-1): Writing injected SQL for node "model.dbt_poc.my_first_dbt_model"
2021-04-14 11:46:44.056230 (Thread-2): Writing injected SQL for node "model.dbt_poc.customers"
2021-04-14 11:46:44.056560 (Thread-2): finished collecting timing info
2021-04-14 11:46:44.056669 (Thread-1): finished collecting timing info
2021-04-14 11:46:44.082183 (Thread-2): Opening a new connection, currently in state init
2021-04-14 11:46:44.088451 (Thread-1): Opening a new connection, currently in state closed
2021-04-14 11:46:44.091650 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-04-14 11:46:44.094002 (Thread-2): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-04-14 11:46:45.009257 (Thread-2): Writing runtime SQL for node "model.dbt_poc.customers"
2021-04-14 11:46:45.009509 (Thread-2): On model.dbt_poc.customers: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "db_bigq_profile", "target_name": "dev", "node_id": "model.dbt_poc.customers"} */


  create or replace table `poc-dbt-310711`.`dbt_poc_ds`.`customers`
  
  
  OPTIONS()
  as (
    with customers as (

    select
        id as customer_id,
        first_name,
        last_name

    from `dbt-tutorial`.jaffle_shop.customers

),

orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from `dbt-tutorial`.jaffle_shop.orders

),

customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final
  );
    
2021-04-14 11:46:45.011695 (Thread-1): Writing runtime SQL for node "model.dbt_poc.my_first_dbt_model"
2021-04-14 11:46:45.011961 (Thread-1): On model.dbt_poc.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "db_bigq_profile", "target_name": "dev", "node_id": "model.dbt_poc.my_first_dbt_model"} */


  create or replace table `poc-dbt-310711`.`dbt_poc_ds`.`my_first_dbt_model`
  
  
  OPTIONS()
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
    
2021-04-14 11:46:47.246879 (Thread-1): finished collecting timing info
2021-04-14 11:46:47.247287 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ada53eb5-1747-4d0c-b7bf-d5caa7733553', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedb38e8790>]}
2021-04-14 11:46:47.247643 (Thread-1): 17:16:47 | 1 of 3 OK created table model dbt_poc_ds.my_first_dbt_model.......... [CREATE TABLE (2.0 rows, 0.0 Bytes processed) in 3.20s]
2021-04-14 11:46:47.247778 (Thread-1): Finished running node model.dbt_poc.my_first_dbt_model
2021-04-14 11:46:47.248224 (Thread-4): Began running node model.dbt_poc.my_second_dbt_model
2021-04-14 11:46:47.248457 (Thread-4): 17:16:47 | 3 of 3 START view model dbt_poc_ds.my_second_dbt_model............... [RUN]
2021-04-14 11:46:47.248712 (Thread-4): Acquiring new bigquery connection "model.dbt_poc.my_second_dbt_model".
2021-04-14 11:46:47.248807 (Thread-4): Compiling model.dbt_poc.my_second_dbt_model
2021-04-14 11:46:47.251073 (Thread-4): Writing injected SQL for node "model.dbt_poc.my_second_dbt_model"
2021-04-14 11:46:47.251333 (Thread-4): finished collecting timing info
2021-04-14 11:46:47.257953 (Thread-4): unclosed <socket.socket fd=5, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.7', 44358), raddr=('172.217.167.138', 443)>
2021-04-14 11:46:47.258084 (Thread-4): unclosed <socket.socket fd=6, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.7', 54412), raddr=('142.250.67.42', 443)>
2021-04-14 11:46:47.258162 (Thread-4): unclosed <socket.socket fd=8, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.7', 54416), raddr=('142.250.67.42', 443)>
2021-04-14 11:46:47.258244 (Thread-4): unclosed <socket.socket fd=7, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.7', 44362), raddr=('172.217.167.138', 443)>
2021-04-14 11:46:47.266337 (Thread-4): Writing runtime SQL for node "model.dbt_poc.my_second_dbt_model"
2021-04-14 11:46:47.266544 (Thread-4): Opening a new connection, currently in state init
2021-04-14 11:46:47.269577 (Thread-4): On model.dbt_poc.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "db_bigq_profile", "target_name": "dev", "node_id": "model.dbt_poc.my_second_dbt_model"} */


  create or replace view `poc-dbt-310711`.`dbt_poc_ds`.`my_second_dbt_model`
  OPTIONS()
  as -- Use the `ref` function to select from other models

select *
from `poc-dbt-310711`.`dbt_poc_ds`.`my_first_dbt_model`
where id = 1;


2021-04-14 11:46:47.870066 (Thread-2): finished collecting timing info
2021-04-14 11:46:47.870469 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ada53eb5-1747-4d0c-b7bf-d5caa7733553', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedb39307c0>]}
2021-04-14 11:46:47.870783 (Thread-2): 17:16:47 | 2 of 3 OK created table model dbt_poc_ds.customers................... [CREATE TABLE (100.0 rows, 4.3 KB processed) in 3.82s]
2021-04-14 11:46:47.870902 (Thread-2): Finished running node model.dbt_poc.customers
2021-04-14 11:46:49.032973 (Thread-4): finished collecting timing info
2021-04-14 11:46:49.033360 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ada53eb5-1747-4d0c-b7bf-d5caa7733553', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedb3828310>]}
2021-04-14 11:46:49.033659 (Thread-4): 17:16:49 | 3 of 3 OK created view model dbt_poc_ds.my_second_dbt_model.......... [OK in 1.78s]
2021-04-14 11:46:49.033775 (Thread-4): Finished running node model.dbt_poc.my_second_dbt_model
2021-04-14 11:46:49.034821 (MainThread): Acquiring new bigquery connection "master".
2021-04-14 11:46:49.035170 (MainThread): 17:16:49 | 
2021-04-14 11:46:49.035295 (MainThread): 17:16:49 | Finished running 2 table models, 1 view model in 6.91s.
2021-04-14 11:46:49.035387 (MainThread): Connection 'master' was properly closed.
2021-04-14 11:46:49.035464 (MainThread): Connection 'model.dbt_poc.my_first_dbt_model' was properly closed.
2021-04-14 11:46:49.035540 (MainThread): Connection 'model.dbt_poc.customers' was properly closed.
2021-04-14 11:46:49.035606 (MainThread): Connection 'model.dbt_poc.my_second_dbt_model' was properly closed.
2021-04-14 11:46:49.040392 (MainThread): 
2021-04-14 11:46:49.040533 (MainThread): Completed successfully
2021-04-14 11:46:49.040655 (MainThread): 
Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
2021-04-14 11:46:49.040824 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedb386f190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedb39426d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedb60fbf40>]}
2021-04-14 11:46:49.041017 (MainThread): Flushing usage events
2021-04-14 11:47:59.690838 (MainThread): Running with dbt=0.19.1
2021-04-14 11:47:59.823609 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/home/msonowal/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-04-14 11:47:59.823969 (MainThread): Tracking: tracking
2021-04-14 11:47:59.829653 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4979b86820>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f49782c4fa0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4979b89820>]}
2021-04-14 11:47:59.835052 (MainThread): Partial parsing not enabled
2021-04-14 11:47:59.835561 (MainThread): Parsing macros/etc.sql
2021-04-14 11:47:59.837241 (MainThread): Parsing macros/adapters.sql
2021-04-14 11:47:59.849080 (MainThread): Parsing macros/catalog.sql
2021-04-14 11:47:59.852443 (MainThread): Parsing macros/materializations/seed.sql
2021-04-14 11:47:59.854175 (MainThread): Parsing macros/materializations/copy.sql
2021-04-14 11:47:59.857064 (MainThread): Parsing macros/materializations/table.sql
2021-04-14 11:47:59.863505 (MainThread): Parsing macros/materializations/incremental.sql
2021-04-14 11:47:59.871603 (MainThread): Parsing macros/materializations/view.sql
2021-04-14 11:47:59.873386 (MainThread): Parsing macros/materializations/snapshot.sql
2021-04-14 11:47:59.874902 (MainThread): Parsing macros/core.sql
2021-04-14 11:47:59.877359 (MainThread): Parsing macros/adapters/common.sql
2021-04-14 11:47:59.902470 (MainThread): Parsing macros/etc/is_incremental.sql
2021-04-14 11:47:59.903489 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-04-14 11:47:59.904701 (MainThread): Parsing macros/etc/query.sql
2021-04-14 11:47:59.905331 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-04-14 11:47:59.905889 (MainThread): Parsing macros/etc/datetime.sql
2021-04-14 11:47:59.911435 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-04-14 11:47:59.912452 (MainThread): Parsing macros/materializations/helpers.sql
2021-04-14 11:47:59.917862 (MainThread): Parsing macros/materializations/common/merge.sql
2021-04-14 11:47:59.926391 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-04-14 11:47:59.939359 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-04-14 11:47:59.943372 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-04-14 11:47:59.944507 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-04-14 11:47:59.947655 (MainThread): Parsing macros/materializations/view/view.sql
2021-04-14 11:47:59.951531 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-04-14 11:47:59.952574 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-04-14 11:47:59.971278 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-04-14 11:47:59.983136 (MainThread): Parsing macros/materializations/table/table.sql
2021-04-14 11:47:59.987336 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-04-14 11:47:59.989012 (MainThread): Parsing macros/schema_tests/unique.sql
2021-04-14 11:47:59.990052 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-04-14 11:47:59.990985 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-04-14 11:47:59.995136 (MainThread): Partial parsing not enabled
2021-04-14 11:48:00.010173 (MainThread): Acquiring new bigquery connection "model.dbt_poc.customers".
2021-04-14 11:48:00.015656 (MainThread): Acquiring new bigquery connection "model.dbt_poc.my_second_dbt_model".
2021-04-14 11:48:00.017660 (MainThread): Acquiring new bigquery connection "model.dbt_poc.my_first_dbt_model".
2021-04-14 11:48:00.056527 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '92dfa0da-6ce8-4fe7-ab9c-e6d25fc4b1fd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f49772b9ac0>]}
2021-04-14 11:48:00.059260 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '92dfa0da-6ce8-4fe7-ab9c-e6d25fc4b1fd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4979ae4700>]}
2021-04-14 11:48:00.059371 (MainThread): Found 3 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-04-14 11:48:00.059804 (MainThread): 
2021-04-14 11:48:00.059960 (MainThread): Acquiring new bigquery connection "master".
2021-04-14 11:48:00.060542 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_poc-dbt-310711".
2021-04-14 11:48:00.060718 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-04-14 11:48:01.140694 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_poc-dbt-310711_dbt_poc_ds".
2021-04-14 11:48:01.140979 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-04-14 11:48:01.147045 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-04-14 11:48:02.088231 (MainThread): 17:18:02 | Concurrency: 4 threads (target='dev')
2021-04-14 11:48:02.088414 (MainThread): 17:18:02 | 
2021-04-14 11:48:02.090562 (Thread-1): Began running node model.dbt_poc.my_first_dbt_model
2021-04-14 11:48:02.090833 (Thread-1): 17:18:02 | 1 of 3 START table model dbt_poc_ds.my_first_dbt_model............... [RUN]
2021-04-14 11:48:02.091008 (Thread-2): Began running node model.dbt_poc.customers
2021-04-14 11:48:02.091290 (Thread-1): Acquiring new bigquery connection "model.dbt_poc.my_first_dbt_model".
2021-04-14 11:48:02.091488 (Thread-2): 17:18:02 | 2 of 3 START table model dbt_poc_ds.customers........................ [RUN]
2021-04-14 11:48:02.091617 (Thread-1): Compiling model.dbt_poc.my_first_dbt_model
2021-04-14 11:48:02.091908 (Thread-2): Acquiring new bigquery connection "model.dbt_poc.customers".
2021-04-14 11:48:02.094345 (Thread-1): Writing injected SQL for node "model.dbt_poc.my_first_dbt_model"
2021-04-14 11:48:02.094505 (Thread-2): Compiling model.dbt_poc.customers
2021-04-14 11:48:02.096139 (Thread-2): Writing injected SQL for node "model.dbt_poc.customers"
2021-04-14 11:48:02.096425 (Thread-1): finished collecting timing info
2021-04-14 11:48:02.096564 (Thread-2): finished collecting timing info
2021-04-14 11:48:02.123032 (Thread-1): Opening a new connection, currently in state closed
2021-04-14 11:48:02.126749 (Thread-2): Opening a new connection, currently in state init
2021-04-14 11:48:02.130245 (Thread-2): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-04-14 11:48:02.132340 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-04-14 11:48:02.701421 (Thread-2): Writing runtime SQL for node "model.dbt_poc.customers"
2021-04-14 11:48:02.701650 (Thread-2): On model.dbt_poc.customers: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "db_bigq_profile", "target_name": "dev", "node_id": "model.dbt_poc.customers"} */


  create or replace table `poc-dbt-310711`.`dbt_poc_ds`.`customers`
  
  
  OPTIONS()
  as (
    with customers as (

    select
        id as customer_id,
        first_name,
        last_name

    from `dbt-tutorial`.jaffle_shop.customers

),

orders as (

    select
        id as order_id,
        user_id as customer_id,
        order_date,
        status

    from `dbt-tutorial`.jaffle_shop.orders

),

customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final
  );
    
2021-04-14 11:48:03.024863 (Thread-1): Writing runtime SQL for node "model.dbt_poc.my_first_dbt_model"
2021-04-14 11:48:03.025188 (Thread-1): On model.dbt_poc.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "db_bigq_profile", "target_name": "dev", "node_id": "model.dbt_poc.my_first_dbt_model"} */


  create or replace table `poc-dbt-310711`.`dbt_poc_ds`.`my_first_dbt_model`
  
  
  OPTIONS()
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
    
2021-04-14 11:48:05.409606 (Thread-2): finished collecting timing info
2021-04-14 11:48:05.410000 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '92dfa0da-6ce8-4fe7-ab9c-e6d25fc4b1fd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f49773b32b0>]}
2021-04-14 11:48:05.410304 (Thread-2): 17:18:05 | 2 of 3 OK created table model dbt_poc_ds.customers................... [CREATE TABLE (100.0 rows, 4.3 KB processed) in 3.32s]
2021-04-14 11:48:05.410428 (Thread-2): Finished running node model.dbt_poc.customers
2021-04-14 11:48:05.767393 (Thread-1): finished collecting timing info
2021-04-14 11:48:05.767755 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '92dfa0da-6ce8-4fe7-ab9c-e6d25fc4b1fd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f497734f0a0>]}
2021-04-14 11:48:05.768048 (Thread-1): 17:18:05 | 1 of 3 OK created table model dbt_poc_ds.my_first_dbt_model.......... [CREATE TABLE (2.0 rows, 0.0 Bytes processed) in 3.68s]
2021-04-14 11:48:05.768167 (Thread-1): Finished running node model.dbt_poc.my_first_dbt_model
2021-04-14 11:48:05.768623 (Thread-4): Began running node model.dbt_poc.my_second_dbt_model
2021-04-14 11:48:05.768882 (Thread-4): 17:18:05 | 3 of 3 START table model dbt_poc_ds.my_second_dbt_model.............. [RUN]
2021-04-14 11:48:05.769508 (Thread-4): Acquiring new bigquery connection "model.dbt_poc.my_second_dbt_model".
2021-04-14 11:48:05.769654 (Thread-4): Compiling model.dbt_poc.my_second_dbt_model
2021-04-14 11:48:05.772269 (Thread-4): Writing injected SQL for node "model.dbt_poc.my_second_dbt_model"
2021-04-14 11:48:05.772551 (Thread-4): finished collecting timing info
2021-04-14 11:48:05.774001 (Thread-4): Opening a new connection, currently in state init
2021-04-14 11:48:05.779046 (Thread-4): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-04-14 11:48:05.867338 (Thread-4): unclosed <socket.socket fd=5, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.7', 48862), raddr=('142.250.182.74', 443)>
2021-04-14 11:48:05.867505 (Thread-4): unclosed <socket.socket fd=6, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.7', 54440), raddr=('142.250.67.42', 443)>
2021-04-14 11:48:05.867603 (Thread-4): unclosed <socket.socket fd=8, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.7', 54444), raddr=('142.250.67.42', 443)>
2021-04-14 11:48:05.867705 (Thread-4): unclosed <socket.socket fd=7, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.7', 48866), raddr=('142.250.182.74', 443)>
2021-04-14 11:48:06.758517 (Thread-4): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-04-14 11:48:07.082382 (Thread-4): Writing runtime SQL for node "model.dbt_poc.my_second_dbt_model"
2021-04-14 11:48:07.082747 (Thread-4): On model.dbt_poc.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "db_bigq_profile", "target_name": "dev", "node_id": "model.dbt_poc.my_second_dbt_model"} */


  create or replace table `poc-dbt-310711`.`dbt_poc_ds`.`my_second_dbt_model`
  
  
  OPTIONS()
  as (
    -- Use the `ref` function to select from other models

select *
from `poc-dbt-310711`.`dbt_poc_ds`.`my_first_dbt_model`
where id = 1
  );
    
2021-04-14 11:48:09.369069 (Thread-4): finished collecting timing info
2021-04-14 11:48:09.369456 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '92dfa0da-6ce8-4fe7-ab9c-e6d25fc4b1fd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f49741ec910>]}
2021-04-14 11:48:09.369752 (Thread-4): 17:18:09 | 3 of 3 OK created table model dbt_poc_ds.my_second_dbt_model......... [CREATE TABLE (1.0 rows, 8.0 Bytes processed) in 3.60s]
2021-04-14 11:48:09.369875 (Thread-4): Finished running node model.dbt_poc.my_second_dbt_model
2021-04-14 11:48:09.371072 (MainThread): Acquiring new bigquery connection "master".
2021-04-14 11:48:09.371424 (MainThread): 17:18:09 | 
2021-04-14 11:48:09.371550 (MainThread): 17:18:09 | Finished running 3 table models in 9.31s.
2021-04-14 11:48:09.371635 (MainThread): Connection 'master' was properly closed.
2021-04-14 11:48:09.371706 (MainThread): Connection 'model.dbt_poc.my_first_dbt_model' was properly closed.
2021-04-14 11:48:09.371767 (MainThread): Connection 'model.dbt_poc.customers' was properly closed.
2021-04-14 11:48:09.371822 (MainThread): Connection 'model.dbt_poc.my_second_dbt_model' was properly closed.
2021-04-14 11:48:09.376011 (MainThread): 
2021-04-14 11:48:09.376134 (MainThread): Completed successfully
2021-04-14 11:48:09.376233 (MainThread): 
Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
2021-04-14 11:48:09.376401 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f49772ff0a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4977373b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4979b4fa00>]}
2021-04-14 11:48:09.376597 (MainThread): Flushing usage events
2021-04-14 11:54:40.027328 (MainThread): Running with dbt=0.19.1
2021-04-14 11:54:40.161704 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/home/msonowal/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-04-14 11:54:40.162104 (MainThread): Tracking: tracking
2021-04-14 11:54:40.167897 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f821d7ddbe0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f821f197130>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f821d7f8970>]}
2021-04-14 11:54:40.173619 (MainThread): Partial parsing not enabled
2021-04-14 11:54:40.174157 (MainThread): Parsing macros/etc.sql
2021-04-14 11:54:40.175919 (MainThread): Parsing macros/adapters.sql
2021-04-14 11:54:40.187987 (MainThread): Parsing macros/catalog.sql
2021-04-14 11:54:40.191420 (MainThread): Parsing macros/materializations/seed.sql
2021-04-14 11:54:40.193183 (MainThread): Parsing macros/materializations/copy.sql
2021-04-14 11:54:40.196163 (MainThread): Parsing macros/materializations/table.sql
2021-04-14 11:54:40.202759 (MainThread): Parsing macros/materializations/incremental.sql
2021-04-14 11:54:40.211089 (MainThread): Parsing macros/materializations/view.sql
2021-04-14 11:54:40.212915 (MainThread): Parsing macros/materializations/snapshot.sql
2021-04-14 11:54:40.214467 (MainThread): Parsing macros/core.sql
2021-04-14 11:54:40.216978 (MainThread): Parsing macros/adapters/common.sql
2021-04-14 11:54:40.243102 (MainThread): Parsing macros/etc/is_incremental.sql
2021-04-14 11:54:40.244140 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-04-14 11:54:40.245402 (MainThread): Parsing macros/etc/query.sql
2021-04-14 11:54:40.246057 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-04-14 11:54:40.246627 (MainThread): Parsing macros/etc/datetime.sql
2021-04-14 11:54:40.252456 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-04-14 11:54:40.253511 (MainThread): Parsing macros/materializations/helpers.sql
2021-04-14 11:54:40.259109 (MainThread): Parsing macros/materializations/common/merge.sql
2021-04-14 11:54:40.267964 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-04-14 11:54:40.281345 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-04-14 11:54:40.285492 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-04-14 11:54:40.286682 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-04-14 11:54:40.289907 (MainThread): Parsing macros/materializations/view/view.sql
2021-04-14 11:54:40.293951 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-04-14 11:54:40.295033 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-04-14 11:54:40.313871 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-04-14 11:54:40.325432 (MainThread): Parsing macros/materializations/table/table.sql
2021-04-14 11:54:40.329735 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-04-14 11:54:40.331450 (MainThread): Parsing macros/schema_tests/unique.sql
2021-04-14 11:54:40.332512 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-04-14 11:54:40.333441 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-04-14 11:54:40.337689 (MainThread): Partial parsing not enabled
2021-04-14 11:54:40.352373 (MainThread): Acquiring new bigquery connection "model.dbt_poc.stg_customers".
2021-04-14 11:54:40.357898 (MainThread): Acquiring new bigquery connection "model.dbt_poc.stg_orders".
2021-04-14 11:54:40.359515 (MainThread): Acquiring new bigquery connection "model.dbt_poc.customers".
2021-04-14 11:54:40.361774 (MainThread): Acquiring new bigquery connection "model.dbt_poc.my_second_dbt_model".
2021-04-14 11:54:40.363846 (MainThread): Acquiring new bigquery connection "model.dbt_poc.my_first_dbt_model".
2021-04-14 11:54:40.400834 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f821afe77c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f821aff1a00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f821af9cbb0>]}
2021-04-14 11:54:40.400993 (MainThread): Flushing usage events
2021-04-14 11:54:41.374028 (MainThread): Connection 'model.dbt_poc.my_first_dbt_model' was properly closed.
2021-04-14 11:54:41.374430 (MainThread): Encountered an error:
2021-04-14 11:54:41.374557 (MainThread): Compilation Error in model customers (models/customers.sql)
  Model 'model.dbt_poc.customers' (models/customers.sql) depends on a node named 'stg_customers.sql' which was not found
2021-04-14 11:54:41.375565 (MainThread): Traceback (most recent call last):
  File "/home/msonowal/dbt-env/lib/python3.8/site-packages/dbt/main.py", line 125, in main
    results, succeeded = handle_and_check(args)
  File "/home/msonowal/dbt-env/lib/python3.8/site-packages/dbt/main.py", line 203, in handle_and_check
    task, res = run_from_args(parsed)
  File "/home/msonowal/dbt-env/lib/python3.8/site-packages/dbt/main.py", line 256, in run_from_args
    results = task.run()
  File "/home/msonowal/dbt-env/lib/python3.8/site-packages/dbt/task/runnable.py", line 406, in run
    self._runtime_initialize()
  File "/home/msonowal/dbt-env/lib/python3.8/site-packages/dbt/task/runnable.py", line 122, in _runtime_initialize
    super()._runtime_initialize()
  File "/home/msonowal/dbt-env/lib/python3.8/site-packages/dbt/task/runnable.py", line 79, in _runtime_initialize
    self.load_manifest()
  File "/home/msonowal/dbt-env/lib/python3.8/site-packages/dbt/task/runnable.py", line 66, in load_manifest
    self.manifest = get_full_manifest(self.config)
  File "/home/msonowal/dbt-env/lib/python3.8/site-packages/dbt/perf_utils.py", line 28, in get_full_manifest
    return load_manifest(
  File "/home/msonowal/dbt-env/lib/python3.8/site-packages/dbt/parser/manifest.py", line 862, in load_manifest
    return ManifestLoader.load_all(config, macro_manifest, macro_hook)
  File "/home/msonowal/dbt-env/lib/python3.8/site-packages/dbt/parser/manifest.py", line 444, in load_all
    manifest = loader.create_manifest()
  File "/home/msonowal/dbt-env/lib/python3.8/site-packages/dbt/parser/manifest.py", line 422, in create_manifest
    self.process_manifest(manifest)
  File "/home/msonowal/dbt-env/lib/python3.8/site-packages/dbt/parser/manifest.py", line 388, in process_manifest
    process_refs(manifest, project_name)
  File "/home/msonowal/dbt-env/lib/python3.8/site-packages/dbt/parser/manifest.py", line 758, in process_refs
    _process_refs_for_node(manifest, current_project, node)
  File "/home/msonowal/dbt-env/lib/python3.8/site-packages/dbt/parser/manifest.py", line 740, in _process_refs_for_node
    invalid_ref_fail_unless_test(
  File "/home/msonowal/dbt-env/lib/python3.8/site-packages/dbt/parser/manifest.py", line 483, in invalid_ref_fail_unless_test
    ref_target_not_found(
  File "/home/msonowal/dbt-env/lib/python3.8/site-packages/dbt/exceptions.py", line 566, in ref_target_not_found
    raise_compiler_error(msg, model)
  File "/home/msonowal/dbt-env/lib/python3.8/site-packages/dbt/exceptions.py", line 435, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error in model customers (models/customers.sql)
  Model 'model.dbt_poc.customers' (models/customers.sql) depends on a node named 'stg_customers.sql' which was not found

2021-04-14 11:55:17.013960 (MainThread): Running with dbt=0.19.1
2021-04-14 11:55:17.147973 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/home/msonowal/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-04-14 11:55:17.148348 (MainThread): Tracking: tracking
2021-04-14 11:55:17.154050 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f99ef082760>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f99ed780cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f99ef085820>]}
2021-04-14 11:55:17.159468 (MainThread): Partial parsing not enabled
2021-04-14 11:55:17.159987 (MainThread): Parsing macros/etc.sql
2021-04-14 11:55:17.161667 (MainThread): Parsing macros/adapters.sql
2021-04-14 11:55:17.173456 (MainThread): Parsing macros/catalog.sql
2021-04-14 11:55:17.176903 (MainThread): Parsing macros/materializations/seed.sql
2021-04-14 11:55:17.178613 (MainThread): Parsing macros/materializations/copy.sql
2021-04-14 11:55:17.181499 (MainThread): Parsing macros/materializations/table.sql
2021-04-14 11:55:17.187987 (MainThread): Parsing macros/materializations/incremental.sql
2021-04-14 11:55:17.196197 (MainThread): Parsing macros/materializations/view.sql
2021-04-14 11:55:17.197986 (MainThread): Parsing macros/materializations/snapshot.sql
2021-04-14 11:55:17.199517 (MainThread): Parsing macros/core.sql
2021-04-14 11:55:17.201987 (MainThread): Parsing macros/adapters/common.sql
2021-04-14 11:55:17.227729 (MainThread): Parsing macros/etc/is_incremental.sql
2021-04-14 11:55:17.228742 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-04-14 11:55:17.229969 (MainThread): Parsing macros/etc/query.sql
2021-04-14 11:55:17.230620 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-04-14 11:55:17.231198 (MainThread): Parsing macros/etc/datetime.sql
2021-04-14 11:55:17.236865 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-04-14 11:55:17.237897 (MainThread): Parsing macros/materializations/helpers.sql
2021-04-14 11:55:17.243396 (MainThread): Parsing macros/materializations/common/merge.sql
2021-04-14 11:55:17.252045 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-04-14 11:55:17.265177 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-04-14 11:55:17.269282 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-04-14 11:55:17.270447 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-04-14 11:55:17.273637 (MainThread): Parsing macros/materializations/view/view.sql
2021-04-14 11:55:17.277657 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-04-14 11:55:17.278729 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-04-14 11:55:17.297760 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-04-14 11:55:17.309423 (MainThread): Parsing macros/materializations/table/table.sql
2021-04-14 11:55:17.313769 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-04-14 11:55:17.315477 (MainThread): Parsing macros/schema_tests/unique.sql
2021-04-14 11:55:17.316527 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-04-14 11:55:17.317474 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-04-14 11:55:17.321652 (MainThread): Partial parsing not enabled
2021-04-14 11:55:17.335924 (MainThread): Acquiring new bigquery connection "model.dbt_poc.stg_customers".
2021-04-14 11:55:17.341367 (MainThread): Acquiring new bigquery connection "model.dbt_poc.stg_orders".
2021-04-14 11:55:17.342950 (MainThread): Acquiring new bigquery connection "model.dbt_poc.customers".
2021-04-14 11:55:17.345218 (MainThread): Acquiring new bigquery connection "model.dbt_poc.my_second_dbt_model".
2021-04-14 11:55:17.347310 (MainThread): Acquiring new bigquery connection "model.dbt_poc.my_first_dbt_model".
2021-04-14 11:55:17.388789 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '83f9568f-2c02-4897-b497-76f3e9f4e6a3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f99ec80fb50>]}
2021-04-14 11:55:17.391202 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '83f9568f-2c02-4897-b497-76f3e9f4e6a3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f99ec8f1160>]}
2021-04-14 11:55:17.391316 (MainThread): Found 5 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-04-14 11:55:17.391816 (MainThread): 
2021-04-14 11:55:17.391976 (MainThread): Acquiring new bigquery connection "master".
2021-04-14 11:55:17.392649 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_poc-dbt-310711".
2021-04-14 11:55:17.392830 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-04-14 11:55:18.523351 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_poc-dbt-310711_dbt_poc_ds".
2021-04-14 11:55:18.523573 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-04-14 11:55:18.529525 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-04-14 11:55:19.562881 (MainThread): 17:25:19 | Concurrency: 4 threads (target='dev')
2021-04-14 11:55:19.563050 (MainThread): 17:25:19 | 
2021-04-14 11:55:19.564933 (Thread-1): Began running node model.dbt_poc.my_first_dbt_model
2021-04-14 11:55:19.565142 (Thread-2): Began running node model.dbt_poc.stg_customers
2021-04-14 11:55:19.565412 (Thread-1): 17:25:19 | 1 of 5 START table model dbt_poc_ds.my_first_dbt_model............... [RUN]
2021-04-14 11:55:19.565534 (Thread-3): Began running node model.dbt_poc.stg_orders
2021-04-14 11:55:19.565792 (Thread-2): 17:25:19 | 2 of 5 START table model dbt_poc_ds.stg_customers.................... [RUN]
2021-04-14 11:55:19.566169 (Thread-1): Acquiring new bigquery connection "model.dbt_poc.my_first_dbt_model".
2021-04-14 11:55:19.566355 (Thread-3): 17:25:19 | 3 of 5 START table model dbt_poc_ds.stg_orders....................... [RUN]
2021-04-14 11:55:19.566666 (Thread-2): Acquiring new bigquery connection "model.dbt_poc.stg_customers".
2021-04-14 11:55:19.566782 (Thread-1): Compiling model.dbt_poc.my_first_dbt_model
2021-04-14 11:55:19.567075 (Thread-3): Acquiring new bigquery connection "model.dbt_poc.stg_orders".
2021-04-14 11:55:19.567188 (Thread-2): Compiling model.dbt_poc.stg_customers
2021-04-14 11:55:19.569657 (Thread-1): Writing injected SQL for node "model.dbt_poc.my_first_dbt_model"
2021-04-14 11:55:19.569818 (Thread-3): Compiling model.dbt_poc.stg_orders
2021-04-14 11:55:19.571082 (Thread-2): Writing injected SQL for node "model.dbt_poc.stg_customers"
2021-04-14 11:55:19.572284 (Thread-3): Writing injected SQL for node "model.dbt_poc.stg_orders"
2021-04-14 11:55:19.572636 (Thread-1): finished collecting timing info
2021-04-14 11:55:19.583033 (Thread-2): finished collecting timing info
2021-04-14 11:55:19.583166 (Thread-3): finished collecting timing info
2021-04-14 11:55:19.598610 (Thread-1): Opening a new connection, currently in state closed
2021-04-14 11:55:19.613032 (Thread-2): Writing runtime SQL for node "model.dbt_poc.stg_customers"
2021-04-14 11:55:19.614138 (Thread-3): unclosed <socket.socket fd=5, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.7', 37758), raddr=('172.217.163.170', 443)>
2021-04-14 11:55:19.614565 (Thread-2): Opening a new connection, currently in state init
2021-04-14 11:55:19.614745 (Thread-3): unclosed <socket.socket fd=6, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.7', 54598), raddr=('142.250.67.42', 443)>
2021-04-14 11:55:19.614881 (Thread-3): unclosed <socket.socket fd=8, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.7', 54602), raddr=('142.250.67.42', 443)>
2021-04-14 11:55:19.615008 (Thread-3): unclosed <socket.socket fd=7, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.7', 37762), raddr=('172.217.163.170', 443)>
2021-04-14 11:55:19.616727 (Thread-3): Writing runtime SQL for node "model.dbt_poc.stg_orders"
2021-04-14 11:55:19.616935 (Thread-3): Opening a new connection, currently in state init
2021-04-14 11:55:19.617733 (Thread-2): On model.dbt_poc.stg_customers: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "db_bigq_profile", "target_name": "dev", "node_id": "model.dbt_poc.stg_customers"} */


  create or replace table `poc-dbt-310711`.`dbt_poc_ds`.`stg_customers`
  
  
  OPTIONS()
  as (
    select
    id as customer_id,
    first_name,
    last_name

from `dbt-tutorial`.jaffle_shop.customers
  );
    
2021-04-14 11:55:19.621938 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-04-14 11:55:19.622596 (Thread-3): On model.dbt_poc.stg_orders: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "db_bigq_profile", "target_name": "dev", "node_id": "model.dbt_poc.stg_orders"} */


  create or replace table `poc-dbt-310711`.`dbt_poc_ds`.`stg_orders`
  
  
  OPTIONS()
  as (
    select
    id as order_id,
    user_id as customer_id,
    order_date,
    status

from `dbt-tutorial`.jaffle_shop.orders
  );
    
2021-04-14 11:55:20.564456 (Thread-1): Writing runtime SQL for node "model.dbt_poc.my_first_dbt_model"
2021-04-14 11:55:20.564809 (Thread-1): On model.dbt_poc.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "db_bigq_profile", "target_name": "dev", "node_id": "model.dbt_poc.my_first_dbt_model"} */


  create or replace table `poc-dbt-310711`.`dbt_poc_ds`.`my_first_dbt_model`
  
  
  OPTIONS()
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
    
2021-04-14 11:55:22.636730 (Thread-3): finished collecting timing info
2021-04-14 11:55:22.637141 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '83f9568f-2c02-4897-b497-76f3e9f4e6a3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f99e8ef1fa0>]}
2021-04-14 11:55:22.637449 (Thread-3): 17:25:22 | 3 of 5 OK created table model dbt_poc_ds.stg_orders.................. [CREATE TABLE (99.0 rows, 3.3 KB processed) in 3.07s]
2021-04-14 11:55:22.637570 (Thread-3): Finished running node model.dbt_poc.stg_orders
2021-04-14 11:55:22.663141 (Thread-2): finished collecting timing info
2021-04-14 11:55:22.663455 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '83f9568f-2c02-4897-b497-76f3e9f4e6a3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f99ec930880>]}
2021-04-14 11:55:22.663722 (Thread-2): 17:25:22 | 2 of 5 OK created table model dbt_poc_ds.stg_customers............... [CREATE TABLE (100.0 rows, 1.9 KB processed) in 3.10s]
2021-04-14 11:55:22.663838 (Thread-2): Finished running node model.dbt_poc.stg_customers
2021-04-14 11:55:22.664284 (Thread-4): Began running node model.dbt_poc.customers
2021-04-14 11:55:22.664616 (Thread-4): 17:25:22 | 4 of 5 START table model dbt_poc_ds.customers........................ [RUN]
2021-04-14 11:55:22.664951 (Thread-4): Acquiring new bigquery connection "model.dbt_poc.customers".
2021-04-14 11:55:22.665051 (Thread-4): Compiling model.dbt_poc.customers
2021-04-14 11:55:22.667962 (Thread-4): Writing injected SQL for node "model.dbt_poc.customers"
2021-04-14 11:55:22.668194 (Thread-4): finished collecting timing info
2021-04-14 11:55:22.669400 (Thread-4): Opening a new connection, currently in state init
2021-04-14 11:55:22.674170 (Thread-4): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-04-14 11:55:23.083597 (Thread-1): finished collecting timing info
2021-04-14 11:55:23.083989 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '83f9568f-2c02-4897-b497-76f3e9f4e6a3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f99e8ee2850>]}
2021-04-14 11:55:23.084288 (Thread-1): 17:25:23 | 1 of 5 OK created table model dbt_poc_ds.my_first_dbt_model.......... [CREATE TABLE (2.0 rows, 0.0 Bytes processed) in 3.52s]
2021-04-14 11:55:23.084412 (Thread-1): Finished running node model.dbt_poc.my_first_dbt_model
2021-04-14 11:55:23.084743 (Thread-2): Began running node model.dbt_poc.my_second_dbt_model
2021-04-14 11:55:23.084961 (Thread-2): 17:25:23 | 5 of 5 START table model dbt_poc_ds.my_second_dbt_model.............. [RUN]
2021-04-14 11:55:23.085199 (Thread-2): Acquiring new bigquery connection "model.dbt_poc.my_second_dbt_model".
2021-04-14 11:55:23.085292 (Thread-2): Compiling model.dbt_poc.my_second_dbt_model
2021-04-14 11:55:23.087713 (Thread-2): Writing injected SQL for node "model.dbt_poc.my_second_dbt_model"
2021-04-14 11:55:23.087975 (Thread-2): finished collecting timing info
2021-04-14 11:55:23.089358 (Thread-2): Opening a new connection, currently in state closed
2021-04-14 11:55:23.095293 (Thread-2): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-04-14 11:55:23.596720 (Thread-4): Writing runtime SQL for node "model.dbt_poc.customers"
2021-04-14 11:55:23.597068 (Thread-4): On model.dbt_poc.customers: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "db_bigq_profile", "target_name": "dev", "node_id": "model.dbt_poc.customers"} */


  create or replace table `poc-dbt-310711`.`dbt_poc_ds`.`customers`
  
  
  OPTIONS()
  as (
    with customers as (

    select * from `poc-dbt-310711`.`dbt_poc_ds`.`stg_customers`

),

orders as (

    select * from `poc-dbt-310711`.`dbt_poc_ds`.`stg_orders`

),

customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final
  );
    
2021-04-14 11:55:24.008745 (Thread-2): Writing runtime SQL for node "model.dbt_poc.my_second_dbt_model"
2021-04-14 11:55:24.009065 (Thread-2): On model.dbt_poc.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "db_bigq_profile", "target_name": "dev", "node_id": "model.dbt_poc.my_second_dbt_model"} */


  create or replace table `poc-dbt-310711`.`dbt_poc_ds`.`my_second_dbt_model`
  
  
  OPTIONS()
  as (
    -- Use the `ref` function to select from other models

select *
from `poc-dbt-310711`.`dbt_poc_ds`.`my_first_dbt_model`
where id = 1
  );
    
2021-04-14 11:55:26.299860 (Thread-2): finished collecting timing info
2021-04-14 11:55:26.300255 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '83f9568f-2c02-4897-b497-76f3e9f4e6a3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f99e8ee2850>]}
2021-04-14 11:55:26.300555 (Thread-2): 17:25:26 | 5 of 5 OK created table model dbt_poc_ds.my_second_dbt_model......... [CREATE TABLE (1.0 rows, 8.0 Bytes processed) in 3.22s]
2021-04-14 11:55:26.300705 (Thread-2): Finished running node model.dbt_poc.my_second_dbt_model
2021-04-14 11:55:26.373824 (Thread-4): finished collecting timing info
2021-04-14 11:55:26.374165 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '83f9568f-2c02-4897-b497-76f3e9f4e6a3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f99ec930820>]}
2021-04-14 11:55:26.374449 (Thread-4): 17:25:26 | 4 of 5 OK created table model dbt_poc_ds.customers................... [CREATE TABLE (100.0 rows, 4.3 KB processed) in 3.71s]
2021-04-14 11:55:26.374568 (Thread-4): Finished running node model.dbt_poc.customers
2021-04-14 11:55:26.375584 (MainThread): Acquiring new bigquery connection "master".
2021-04-14 11:55:26.375869 (MainThread): 17:25:26 | 
2021-04-14 11:55:26.375976 (MainThread): 17:25:26 | Finished running 5 table models in 8.98s.
2021-04-14 11:55:26.376062 (MainThread): Connection 'master' was properly closed.
2021-04-14 11:55:26.376123 (MainThread): Connection 'model.dbt_poc.my_first_dbt_model' was properly closed.
2021-04-14 11:55:26.376180 (MainThread): Connection 'model.dbt_poc.my_second_dbt_model' was properly closed.
2021-04-14 11:55:26.376236 (MainThread): Connection 'model.dbt_poc.stg_orders' was properly closed.
2021-04-14 11:55:26.376292 (MainThread): Connection 'model.dbt_poc.customers' was properly closed.
2021-04-14 11:55:26.380390 (MainThread): 
2021-04-14 11:55:26.380486 (MainThread): Completed successfully
2021-04-14 11:55:26.380570 (MainThread): 
Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
2021-04-14 11:55:26.380684 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f99ef043cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f99ec828c40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f99ec84ee50>]}
2021-04-14 11:55:26.380814 (MainThread): Flushing usage events
2021-04-14 11:56:25.399295 (MainThread): Running with dbt=0.19.1
2021-04-14 11:56:25.534666 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/home/msonowal/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-04-14 11:56:25.535066 (MainThread): Tracking: tracking
2021-04-14 11:56:25.540838 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4185be4e80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f41875af130>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4185c0d9a0>]}
2021-04-14 11:56:25.546411 (MainThread): Partial parsing not enabled
2021-04-14 11:56:25.546941 (MainThread): Parsing macros/etc.sql
2021-04-14 11:56:25.548667 (MainThread): Parsing macros/adapters.sql
2021-04-14 11:56:25.560778 (MainThread): Parsing macros/catalog.sql
2021-04-14 11:56:25.564261 (MainThread): Parsing macros/materializations/seed.sql
2021-04-14 11:56:25.566055 (MainThread): Parsing macros/materializations/copy.sql
2021-04-14 11:56:25.569031 (MainThread): Parsing macros/materializations/table.sql
2021-04-14 11:56:25.575644 (MainThread): Parsing macros/materializations/incremental.sql
2021-04-14 11:56:25.583975 (MainThread): Parsing macros/materializations/view.sql
2021-04-14 11:56:25.585796 (MainThread): Parsing macros/materializations/snapshot.sql
2021-04-14 11:56:25.587352 (MainThread): Parsing macros/core.sql
2021-04-14 11:56:25.589826 (MainThread): Parsing macros/adapters/common.sql
2021-04-14 11:56:25.616221 (MainThread): Parsing macros/etc/is_incremental.sql
2021-04-14 11:56:25.617259 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-04-14 11:56:25.618529 (MainThread): Parsing macros/etc/query.sql
2021-04-14 11:56:25.619192 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-04-14 11:56:25.619771 (MainThread): Parsing macros/etc/datetime.sql
2021-04-14 11:56:25.625495 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-04-14 11:56:25.626541 (MainThread): Parsing macros/materializations/helpers.sql
2021-04-14 11:56:25.632136 (MainThread): Parsing macros/materializations/common/merge.sql
2021-04-14 11:56:25.640895 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-04-14 11:56:25.654259 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-04-14 11:56:25.658414 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-04-14 11:56:25.659597 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-04-14 11:56:25.662828 (MainThread): Parsing macros/materializations/view/view.sql
2021-04-14 11:56:25.666912 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-04-14 11:56:25.668008 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-04-14 11:56:25.687398 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-04-14 11:56:25.699249 (MainThread): Parsing macros/materializations/table/table.sql
2021-04-14 11:56:25.703609 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-04-14 11:56:25.705334 (MainThread): Parsing macros/schema_tests/unique.sql
2021-04-14 11:56:25.706408 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-04-14 11:56:25.707371 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-04-14 11:56:25.711674 (MainThread): Partial parsing not enabled
2021-04-14 11:56:25.726429 (MainThread): Acquiring new bigquery connection "model.dbt_poc.stg_customers".
2021-04-14 11:56:25.732071 (MainThread): Acquiring new bigquery connection "model.dbt_poc.stg_orders".
2021-04-14 11:56:25.733680 (MainThread): Acquiring new bigquery connection "model.dbt_poc.customers".
2021-04-14 11:56:25.735998 (MainThread): Acquiring new bigquery connection "model.dbt_poc.my_second_dbt_model".
2021-04-14 11:56:25.738121 (MainThread): Acquiring new bigquery connection "model.dbt_poc.my_first_dbt_model".
2021-04-14 11:56:25.780390 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ca332d8e-ff78-4a15-9e4d-67019a9b9c39', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f41833a01f0>]}
2021-04-14 11:56:25.782754 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ca332d8e-ff78-4a15-9e4d-67019a9b9c39', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4183411970>]}
2021-04-14 11:56:25.782870 (MainThread): Found 5 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-04-14 11:56:25.783377 (MainThread): 
2021-04-14 11:56:25.783531 (MainThread): Acquiring new bigquery connection "master".
2021-04-14 11:56:25.784219 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_poc-dbt-310711".
2021-04-14 11:56:25.784401 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-04-14 11:56:26.711474 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_poc-dbt-310711_dbt_poc_ds".
2021-04-14 11:56:26.711691 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-04-14 11:56:26.717272 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-04-14 11:56:27.683265 (MainThread): 17:26:27 | Concurrency: 4 threads (target='dev')
2021-04-14 11:56:27.683442 (MainThread): 17:26:27 | 
2021-04-14 11:56:27.685657 (Thread-1): Began running node model.dbt_poc.my_first_dbt_model
2021-04-14 11:56:27.685837 (Thread-2): Began running node model.dbt_poc.stg_customers
2021-04-14 11:56:27.686061 (Thread-1): 17:26:27 | 1 of 5 START table model dbt_poc_ds.my_first_dbt_model............... [RUN]
2021-04-14 11:56:27.686181 (Thread-3): Began running node model.dbt_poc.stg_orders
2021-04-14 11:56:27.686428 (Thread-2): 17:26:27 | 2 of 5 START table model dbt_poc_ds.stg_customers.................... [RUN]
2021-04-14 11:56:27.686696 (Thread-1): Acquiring new bigquery connection "model.dbt_poc.my_first_dbt_model".
2021-04-14 11:56:27.686930 (Thread-3): 17:26:27 | 3 of 5 START table model dbt_poc_ds.stg_orders....................... [RUN]
2021-04-14 11:56:27.687238 (Thread-2): Acquiring new bigquery connection "model.dbt_poc.stg_customers".
2021-04-14 11:56:27.687344 (Thread-1): Compiling model.dbt_poc.my_first_dbt_model
2021-04-14 11:56:27.687629 (Thread-3): Acquiring new bigquery connection "model.dbt_poc.stg_orders".
2021-04-14 11:56:27.687723 (Thread-2): Compiling model.dbt_poc.stg_customers
2021-04-14 11:56:27.690117 (Thread-1): Writing injected SQL for node "model.dbt_poc.my_first_dbt_model"
2021-04-14 11:56:27.690275 (Thread-3): Compiling model.dbt_poc.stg_orders
2021-04-14 11:56:27.691423 (Thread-2): Writing injected SQL for node "model.dbt_poc.stg_customers"
2021-04-14 11:56:27.692712 (Thread-3): Writing injected SQL for node "model.dbt_poc.stg_orders"
2021-04-14 11:56:27.693014 (Thread-1): finished collecting timing info
2021-04-14 11:56:27.698320 (Thread-2): finished collecting timing info
2021-04-14 11:56:27.719725 (Thread-3): finished collecting timing info
2021-04-14 11:56:27.730393 (Thread-2): Opening a new connection, currently in state init
2021-04-14 11:56:27.730867 (Thread-1): Opening a new connection, currently in state closed
2021-04-14 11:56:27.731018 (Thread-3): unclosed <socket.socket fd=5, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.7', 37794), raddr=('172.217.163.170', 443)>
2021-04-14 11:56:27.731439 (Thread-3): unclosed <socket.socket fd=6, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.7', 54634), raddr=('142.250.67.42', 443)>
2021-04-14 11:56:27.731543 (Thread-3): unclosed <socket.socket fd=8, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.7', 54638), raddr=('142.250.67.42', 443)>
2021-04-14 11:56:27.731636 (Thread-3): unclosed <socket.socket fd=7, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.7', 37798), raddr=('172.217.163.170', 443)>
2021-04-14 11:56:27.736241 (Thread-3): Opening a new connection, currently in state init
2021-04-14 11:56:27.736647 (Thread-2): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-04-14 11:56:27.738140 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-04-14 11:56:27.741490 (Thread-3): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-04-14 11:56:28.686583 (Thread-1): Writing runtime SQL for node "model.dbt_poc.my_first_dbt_model"
2021-04-14 11:56:28.687475 (Thread-3): Writing runtime SQL for node "model.dbt_poc.stg_orders"
2021-04-14 11:56:28.688180 (Thread-2): Writing runtime SQL for node "model.dbt_poc.stg_customers"
2021-04-14 11:56:28.688384 (Thread-1): On model.dbt_poc.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "db_bigq_profile", "target_name": "dev", "node_id": "model.dbt_poc.my_first_dbt_model"} */


  create or replace table `poc-dbt-310711`.`dbt_poc_ds`.`my_first_dbt_model`
  
  
  OPTIONS()
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
    
2021-04-14 11:56:28.689449 (Thread-3): On model.dbt_poc.stg_orders: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "db_bigq_profile", "target_name": "dev", "node_id": "model.dbt_poc.stg_orders"} */


  create or replace table `poc-dbt-310711`.`dbt_poc_ds`.`stg_orders`
  
  
  OPTIONS()
  as (
    select
    id as order_id,
    user_id as customer_id,
    order_date,
    status

from `dbt-tutorial`.jaffle_shop.orders
  );
    
2021-04-14 11:56:28.689675 (Thread-2): On model.dbt_poc.stg_customers: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "db_bigq_profile", "target_name": "dev", "node_id": "model.dbt_poc.stg_customers"} */


  create or replace table `poc-dbt-310711`.`dbt_poc_ds`.`stg_customers`
  
  
  OPTIONS()
  as (
    select
    id as customer_id,
    first_name,
    last_name

from `dbt-tutorial`.jaffle_shop.customers
  );
    
2021-04-14 11:56:30.989379 (Thread-2): finished collecting timing info
2021-04-14 11:56:30.989697 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ca332d8e-ff78-4a15-9e4d-67019a9b9c39', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4180269400>]}
2021-04-14 11:56:30.989941 (Thread-2): 17:26:30 | 2 of 5 OK created table model dbt_poc_ds.stg_customers............... [CREATE TABLE (100.0 rows, 1.9 KB processed) in 3.30s]
2021-04-14 11:56:30.990042 (Thread-2): Finished running node model.dbt_poc.stg_customers
2021-04-14 11:56:31.123548 (Thread-3): finished collecting timing info
2021-04-14 11:56:31.123919 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ca332d8e-ff78-4a15-9e4d-67019a9b9c39', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4183444490>]}
2021-04-14 11:56:31.124207 (Thread-3): 17:26:31 | 3 of 5 OK created table model dbt_poc_ds.stg_orders.................. [CREATE TABLE (99.0 rows, 3.3 KB processed) in 3.44s]
2021-04-14 11:56:31.124326 (Thread-3): Finished running node model.dbt_poc.stg_orders
2021-04-14 11:56:31.124747 (Thread-4): Began running node model.dbt_poc.customers
2021-04-14 11:56:31.124976 (Thread-4): 17:26:31 | 4 of 5 START table model dbt_poc_ds.customers........................ [RUN]
2021-04-14 11:56:31.125237 (Thread-4): Acquiring new bigquery connection "model.dbt_poc.customers".
2021-04-14 11:56:31.125334 (Thread-4): Compiling model.dbt_poc.customers
2021-04-14 11:56:31.127838 (Thread-4): Writing injected SQL for node "model.dbt_poc.customers"
2021-04-14 11:56:31.128051 (Thread-4): finished collecting timing info
2021-04-14 11:56:31.129313 (Thread-4): Opening a new connection, currently in state init
2021-04-14 11:56:31.133969 (Thread-4): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-04-14 11:56:31.166767 (Thread-1): finished collecting timing info
2021-04-14 11:56:31.167141 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ca332d8e-ff78-4a15-9e4d-67019a9b9c39', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f41802695b0>]}
2021-04-14 11:56:31.167435 (Thread-1): 17:26:31 | 1 of 5 OK created table model dbt_poc_ds.my_first_dbt_model.......... [CREATE TABLE (2.0 rows, 0.0 Bytes processed) in 3.48s]
2021-04-14 11:56:31.167601 (Thread-1): Finished running node model.dbt_poc.my_first_dbt_model
2021-04-14 11:56:31.167977 (Thread-3): Began running node model.dbt_poc.my_second_dbt_model
2021-04-14 11:56:31.168201 (Thread-3): 17:26:31 | 5 of 5 START table model dbt_poc_ds.my_second_dbt_model.............. [RUN]
2021-04-14 11:56:31.168528 (Thread-3): Acquiring new bigquery connection "model.dbt_poc.my_second_dbt_model".
2021-04-14 11:56:31.168622 (Thread-3): Compiling model.dbt_poc.my_second_dbt_model
2021-04-14 11:56:31.170858 (Thread-3): Writing injected SQL for node "model.dbt_poc.my_second_dbt_model"
2021-04-14 11:56:31.171151 (Thread-3): finished collecting timing info
2021-04-14 11:56:31.172420 (Thread-3): Opening a new connection, currently in state closed
2021-04-14 11:56:31.177126 (Thread-3): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-04-14 11:56:32.032655 (Thread-4): Writing runtime SQL for node "model.dbt_poc.customers"
2021-04-14 11:56:32.033002 (Thread-4): On model.dbt_poc.customers: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "db_bigq_profile", "target_name": "dev", "node_id": "model.dbt_poc.customers"} */


  create or replace table `poc-dbt-310711`.`dbt_poc_ds`.`customers`
  
  
  OPTIONS()
  as (
    with customers as (

    select * from `poc-dbt-310711`.`dbt_poc_ds`.`stg_customers`

),

orders as (

    select * from `poc-dbt-310711`.`dbt_poc_ds`.`stg_orders`

),

customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders,

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final
  );
    
2021-04-14 11:56:32.114091 (Thread-3): Writing runtime SQL for node "model.dbt_poc.my_second_dbt_model"
2021-04-14 11:56:32.114421 (Thread-3): On model.dbt_poc.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "db_bigq_profile", "target_name": "dev", "node_id": "model.dbt_poc.my_second_dbt_model"} */


  create or replace table `poc-dbt-310711`.`dbt_poc_ds`.`my_second_dbt_model`
  
  
  OPTIONS()
  as (
    -- Use the `ref` function to select from other models

select *
from `poc-dbt-310711`.`dbt_poc_ds`.`my_first_dbt_model`
where id = 1
  );
    
2021-04-14 11:56:34.563648 (Thread-3): finished collecting timing info
2021-04-14 11:56:34.564032 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ca332d8e-ff78-4a15-9e4d-67019a9b9c39', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f41834b9d60>]}
2021-04-14 11:56:34.564334 (Thread-3): 17:26:34 | 5 of 5 OK created table model dbt_poc_ds.my_second_dbt_model......... [CREATE TABLE (1.0 rows, 8.0 Bytes processed) in 3.40s]
2021-04-14 11:56:34.564457 (Thread-3): Finished running node model.dbt_poc.my_second_dbt_model
2021-04-14 11:56:34.835195 (Thread-4): finished collecting timing info
2021-04-14 11:56:34.835531 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ca332d8e-ff78-4a15-9e4d-67019a9b9c39', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4180269a00>]}
2021-04-14 11:56:34.835801 (Thread-4): 17:26:34 | 4 of 5 OK created table model dbt_poc_ds.customers................... [CREATE TABLE (100.0 rows, 4.3 KB processed) in 3.71s]
2021-04-14 11:56:34.835918 (Thread-4): Finished running node model.dbt_poc.customers
2021-04-14 11:56:34.836915 (MainThread): Acquiring new bigquery connection "master".
2021-04-14 11:56:34.837200 (MainThread): 17:26:34 | 
2021-04-14 11:56:34.837307 (MainThread): 17:26:34 | Finished running 5 table models in 9.05s.
2021-04-14 11:56:34.837392 (MainThread): Connection 'master' was properly closed.
2021-04-14 11:56:34.837456 (MainThread): Connection 'model.dbt_poc.my_first_dbt_model' was properly closed.
2021-04-14 11:56:34.837511 (MainThread): Connection 'model.dbt_poc.stg_customers' was properly closed.
2021-04-14 11:56:34.837566 (MainThread): Connection 'model.dbt_poc.my_second_dbt_model' was properly closed.
2021-04-14 11:56:34.837619 (MainThread): Connection 'model.dbt_poc.customers' was properly closed.
2021-04-14 11:56:34.841605 (MainThread): 
2021-04-14 11:56:34.841700 (MainThread): Completed successfully
2021-04-14 11:56:34.841783 (MainThread): 
Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
2021-04-14 11:56:34.841899 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f418341f700>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4183354e80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4183354a90>]}
2021-04-14 11:56:34.842032 (MainThread): Flushing usage events
2021-04-14 11:56:48.508293 (MainThread): Running with dbt=0.19.1
2021-04-14 11:56:48.641621 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/home/msonowal/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-04-14 11:56:48.641995 (MainThread): Tracking: tracking
2021-04-14 11:56:48.647718 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f50334d5ee0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5031be6d30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f50334d4880>]}
2021-04-14 11:56:48.653273 (MainThread): Partial parsing not enabled
2021-04-14 11:56:48.653799 (MainThread): Parsing macros/etc.sql
2021-04-14 11:56:48.655545 (MainThread): Parsing macros/adapters.sql
2021-04-14 11:56:48.667602 (MainThread): Parsing macros/catalog.sql
2021-04-14 11:56:48.670990 (MainThread): Parsing macros/materializations/seed.sql
2021-04-14 11:56:48.672739 (MainThread): Parsing macros/materializations/copy.sql
2021-04-14 11:56:48.675679 (MainThread): Parsing macros/materializations/table.sql
2021-04-14 11:56:48.682282 (MainThread): Parsing macros/materializations/incremental.sql
2021-04-14 11:56:48.690474 (MainThread): Parsing macros/materializations/view.sql
2021-04-14 11:56:48.692276 (MainThread): Parsing macros/materializations/snapshot.sql
2021-04-14 11:56:48.693812 (MainThread): Parsing macros/core.sql
2021-04-14 11:56:48.696315 (MainThread): Parsing macros/adapters/common.sql
2021-04-14 11:56:48.722333 (MainThread): Parsing macros/etc/is_incremental.sql
2021-04-14 11:56:48.723389 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-04-14 11:56:48.724649 (MainThread): Parsing macros/etc/query.sql
2021-04-14 11:56:48.725299 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-04-14 11:56:48.725867 (MainThread): Parsing macros/etc/datetime.sql
2021-04-14 11:56:48.731589 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-04-14 11:56:48.732626 (MainThread): Parsing macros/materializations/helpers.sql
2021-04-14 11:56:48.738188 (MainThread): Parsing macros/materializations/common/merge.sql
2021-04-14 11:56:48.746923 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-04-14 11:56:48.760286 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-04-14 11:56:48.764429 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-04-14 11:56:48.765600 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-04-14 11:56:48.768854 (MainThread): Parsing macros/materializations/view/view.sql
2021-04-14 11:56:48.772912 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-04-14 11:56:48.773988 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-04-14 11:56:48.793169 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-04-14 11:56:48.805036 (MainThread): Parsing macros/materializations/table/table.sql
2021-04-14 11:56:48.809402 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-04-14 11:56:48.811125 (MainThread): Parsing macros/schema_tests/unique.sql
2021-04-14 11:56:48.812193 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-04-14 11:56:48.813143 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-04-14 11:56:48.817425 (MainThread): Partial parsing not enabled
2021-04-14 11:56:48.832232 (MainThread): Acquiring new bigquery connection "model.dbt_poc.stg_customers".
2021-04-14 11:56:48.837753 (MainThread): Acquiring new bigquery connection "model.dbt_poc.stg_orders".
2021-04-14 11:56:48.839367 (MainThread): Acquiring new bigquery connection "model.dbt_poc.customers".
2021-04-14 11:56:48.841649 (MainThread): Acquiring new bigquery connection "model.dbt_poc.my_second_dbt_model".
2021-04-14 11:56:48.843744 (MainThread): Acquiring new bigquery connection "model.dbt_poc.my_first_dbt_model".
2021-04-14 11:56:48.884566 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '7a4adfb1-c905-44c9-8e49-b45a5c01c901', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5030c74e20>]}
2021-04-14 11:56:48.886873 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '7a4adfb1-c905-44c9-8e49-b45a5c01c901', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5030c90070>]}
2021-04-14 11:56:48.886999 (MainThread): Found 5 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-04-14 11:56:48.887484 (MainThread): 
2021-04-14 11:56:48.887633 (MainThread): Acquiring new bigquery connection "master".
2021-04-14 11:56:48.888428 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_poc-dbt-310711".
2021-04-14 11:56:48.888682 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-04-14 11:56:49.847972 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_poc-dbt-310711_dbt_poc_ds".
2021-04-14 11:56:49.848197 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-04-14 11:56:49.854254 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-04-14 11:56:50.761917 (MainThread): 17:26:50 | Concurrency: 4 threads (target='dev')
2021-04-14 11:56:50.762107 (MainThread): 17:26:50 | 
2021-04-14 11:56:50.764312 (Thread-1): Began running node model.dbt_poc.my_first_dbt_model
2021-04-14 11:56:50.764507 (Thread-2): Began running node model.dbt_poc.stg_customers
2021-04-14 11:56:50.764758 (Thread-1): 17:26:50 | 1 of 5 START table model dbt_poc_ds.my_first_dbt_model............... [RUN]
2021-04-14 11:56:50.764910 (Thread-3): Began running node model.dbt_poc.stg_orders
2021-04-14 11:56:50.765147 (Thread-2): 17:26:50 | 2 of 5 START table model dbt_poc_ds.stg_customers.................... [RUN]
2021-04-14 11:56:50.765474 (Thread-1): Acquiring new bigquery connection "model.dbt_poc.my_first_dbt_model".
2021-04-14 11:56:50.765692 (Thread-3): 17:26:50 | 3 of 5 START table model dbt_poc_ds.stg_orders....................... [RUN]
2021-04-14 11:56:50.766042 (Thread-2): Acquiring new bigquery connection "model.dbt_poc.stg_customers".
2021-04-14 11:56:50.766212 (Thread-1): Compiling model.dbt_poc.my_first_dbt_model
2021-04-14 11:56:50.766531 (Thread-3): Acquiring new bigquery connection "model.dbt_poc.stg_orders".
2021-04-14 11:56:50.766646 (Thread-2): Compiling model.dbt_poc.stg_customers
2021-04-14 11:56:50.769110 (Thread-1): Writing injected SQL for node "model.dbt_poc.my_first_dbt_model"
2021-04-14 11:56:50.769274 (Thread-3): Compiling model.dbt_poc.stg_orders
2021-04-14 11:56:50.770570 (Thread-2): Writing injected SQL for node "model.dbt_poc.stg_customers"
2021-04-14 11:56:50.771878 (Thread-3): Writing injected SQL for node "model.dbt_poc.stg_orders"
2021-04-14 11:56:50.772163 (Thread-1): finished collecting timing info
2021-04-14 11:56:50.772281 (Thread-2): finished collecting timing info
2021-04-14 11:56:50.787746 (Thread-3): finished collecting timing info
2021-04-14 11:56:50.797311 (Thread-1): Opening a new connection, currently in state closed
2021-04-14 11:56:50.802544 (Thread-3): unclosed <socket.socket fd=5, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.7', 37826), raddr=('172.217.163.170', 443)>
2021-04-14 11:56:50.808929 (Thread-2): Opening a new connection, currently in state init
2021-04-14 11:56:50.809188 (Thread-3): unclosed <socket.socket fd=6, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.7', 54666), raddr=('142.250.67.42', 443)>
2021-04-14 11:56:50.809346 (Thread-3): unclosed <socket.socket fd=8, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.7', 54670), raddr=('142.250.67.42', 443)>
2021-04-14 11:56:50.809437 (Thread-3): unclosed <socket.socket fd=7, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.7', 37830), raddr=('172.217.163.170', 443)>
2021-04-14 11:56:50.814335 (Thread-3): Opening a new connection, currently in state init
2021-04-14 11:56:50.814807 (Thread-2): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-04-14 11:56:50.815308 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-04-14 11:56:50.820203 (Thread-3): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-04-14 11:56:51.726486 (Thread-3): Writing runtime SQL for node "model.dbt_poc.stg_orders"
2021-04-14 11:56:51.727008 (Thread-3): On model.dbt_poc.stg_orders: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "db_bigq_profile", "target_name": "dev", "node_id": "model.dbt_poc.stg_orders"} */


  create or replace table `poc-dbt-310711`.`dbt_poc_ds`.`stg_orders`
  
  
  OPTIONS()
  as (
    select
    id as order_id,
    user_id as customer_id,
    order_date,
    status

from `dbt-tutorial`.jaffle_shop.orders
  );
    
2021-04-14 11:56:51.760236 (Thread-2): Writing runtime SQL for node "model.dbt_poc.stg_customers"
2021-04-14 11:56:51.760522 (Thread-2): On model.dbt_poc.stg_customers: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "db_bigq_profile", "target_name": "dev", "node_id": "model.dbt_poc.stg_customers"} */


  create or replace table `poc-dbt-310711`.`dbt_poc_ds`.`stg_customers`
  
  
  OPTIONS()
  as (
    select
    id as customer_id,
    first_name,
    last_name

from `dbt-tutorial`.jaffle_shop.customers
  );
    
2021-04-14 11:56:51.765788 (Thread-1): Writing runtime SQL for node "model.dbt_poc.my_first_dbt_model"
2021-04-14 11:56:51.766049 (Thread-1): On model.dbt_poc.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "db_bigq_profile", "target_name": "dev", "node_id": "model.dbt_poc.my_first_dbt_model"} */


  create or replace table `poc-dbt-310711`.`dbt_poc_ds`.`my_first_dbt_model`
  
  
  OPTIONS()
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
    
2021-04-14 11:56:54.307360 (Thread-3): finished collecting timing info
2021-04-14 11:56:54.307765 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7a4adfb1-c905-44c9-8e49-b45a5c01c901', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5030d44400>]}
2021-04-14 11:56:54.308004 (Thread-3): 17:26:54 | 3 of 5 OK created table model dbt_poc_ds.stg_orders.................. [CREATE TABLE (99.0 rows, 3.3 KB processed) in 3.54s]
2021-04-14 11:56:54.308071 (Thread-3): Finished running node model.dbt_poc.stg_orders
2021-04-14 11:56:54.404942 (Thread-2): finished collecting timing info
2021-04-14 11:56:54.405294 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7a4adfb1-c905-44c9-8e49-b45a5c01c901', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5030c041c0>]}
2021-04-14 11:56:54.405582 (Thread-2): 17:26:54 | 2 of 5 OK created table model dbt_poc_ds.stg_customers............... [CREATE TABLE (100.0 rows, 1.9 KB processed) in 3.64s]
2021-04-14 11:56:54.405705 (Thread-2): Finished running node model.dbt_poc.stg_customers
2021-04-14 11:56:54.406164 (Thread-4): Began running node model.dbt_poc.customers
2021-04-14 11:56:54.406518 (Thread-4): 17:26:54 | 4 of 5 START table model dbt_poc_ds.customers........................ [RUN]
2021-04-14 11:56:54.406849 (Thread-4): Acquiring new bigquery connection "model.dbt_poc.customers".
2021-04-14 11:56:54.406952 (Thread-4): Compiling model.dbt_poc.customers
2021-04-14 11:56:54.409667 (Thread-4): Writing injected SQL for node "model.dbt_poc.customers"
2021-04-14 11:56:54.410701 (Thread-1): finished collecting timing info
2021-04-14 11:56:54.410966 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7a4adfb1-c905-44c9-8e49-b45a5c01c901', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f503028b6a0>]}
2021-04-14 11:56:54.411199 (Thread-1): 17:26:54 | 1 of 5 OK created table model dbt_poc_ds.my_first_dbt_model.......... [CREATE TABLE (2.0 rows, 0.0 Bytes processed) in 3.65s]
2021-04-14 11:56:54.411295 (Thread-1): Finished running node model.dbt_poc.my_first_dbt_model
2021-04-14 11:56:54.411565 (Thread-4): finished collecting timing info
2021-04-14 11:56:54.413356 (Thread-4): Opening a new connection, currently in state init
2021-04-14 11:56:54.413475 (Thread-2): Began running node model.dbt_poc.my_second_dbt_model
2021-04-14 11:56:54.413787 (Thread-2): 17:26:54 | 5 of 5 START table model dbt_poc_ds.my_second_dbt_model.............. [RUN]
2021-04-14 11:56:54.414126 (Thread-2): Acquiring new bigquery connection "model.dbt_poc.my_second_dbt_model".
2021-04-14 11:56:54.414208 (Thread-2): Compiling model.dbt_poc.my_second_dbt_model
2021-04-14 11:56:54.416183 (Thread-2): Writing injected SQL for node "model.dbt_poc.my_second_dbt_model"
2021-04-14 11:56:54.416403 (Thread-2): finished collecting timing info
2021-04-14 11:56:54.417476 (Thread-2): Opening a new connection, currently in state closed
2021-04-14 11:56:54.418130 (Thread-4): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-04-14 11:56:54.422184 (Thread-2): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-04-14 11:56:55.357662 (Thread-4): Writing runtime SQL for node "model.dbt_poc.customers"
2021-04-14 11:56:55.358013 (Thread-4): On model.dbt_poc.customers: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "db_bigq_profile", "target_name": "dev", "node_id": "model.dbt_poc.customers"} */


  create or replace table `poc-dbt-310711`.`dbt_poc_ds`.`customers`
  
  
  OPTIONS()
  as (
    with customers as (

    select * from `poc-dbt-310711`.`dbt_poc_ds`.`stg_customers`

),

orders as (

    select * from `poc-dbt-310711`.`dbt_poc_ds`.`stg_orders`

),

customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders,

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final
  );
    
2021-04-14 11:56:55.370939 (Thread-2): Writing runtime SQL for node "model.dbt_poc.my_second_dbt_model"
2021-04-14 11:56:55.371269 (Thread-2): On model.dbt_poc.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "db_bigq_profile", "target_name": "dev", "node_id": "model.dbt_poc.my_second_dbt_model"} */


  create or replace table `poc-dbt-310711`.`dbt_poc_ds`.`my_second_dbt_model`
  
  
  OPTIONS()
  as (
    -- Use the `ref` function to select from other models

select *
from `poc-dbt-310711`.`dbt_poc_ds`.`my_first_dbt_model`
where id = 1
  );
    
2021-04-14 11:56:56.073952 (Thread-4): Retry attempt 1 of 1 after error: BadRequest('GET https://bigquery.googleapis.com/bigquery/v2/projects/poc-dbt-310711/queries/bf013455-bb3c-420e-a76d-5b96a7a3fdaa?maxResults=0&location=US&prettyPrint=false: Syntax error: Unexpected keyword GROUP at [32:5]')
2021-04-14 11:56:57.615311 (Thread-2): finished collecting timing info
2021-04-14 11:56:57.615713 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7a4adfb1-c905-44c9-8e49-b45a5c01c901', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5030381a30>]}
2021-04-14 11:56:57.616012 (Thread-2): 17:26:57 | 5 of 5 OK created table model dbt_poc_ds.my_second_dbt_model......... [CREATE TABLE (1.0 rows, 8.0 Bytes processed) in 3.20s]
2021-04-14 11:56:57.616133 (Thread-2): Finished running node model.dbt_poc.my_second_dbt_model
2021-04-14 11:56:57.774867 (Thread-4): finished collecting timing info
2021-04-14 11:56:57.775194 (Thread-4): Database Error in model customers (models/customers.sql)
  Syntax error: Unexpected keyword GROUP at [32:5]
  compiled SQL at target/run/dbt_poc/models/customers.sql
Traceback (most recent call last):
  File "/home/msonowal/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 149, in exception_handler
    yield
  File "/home/msonowal/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/home/msonowal/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/msonowal/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 327, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/home/msonowal/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 520, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/home/msonowal/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1146, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/home/msonowal/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/job/base.py", line 631, in result
    return super(_AsyncJob, self).result(timeout=timeout, **kwargs)
  File "/home/msonowal/dbt-env/lib/python3.8/site-packages/google/api_core/future/polling.py", line 129, in result
    self._blocking_poll(timeout=timeout, **kwargs)
  File "/home/msonowal/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1042, in _blocking_poll
    super(QueryJob, self)._blocking_poll(timeout=timeout, **kwargs)
  File "/home/msonowal/dbt-env/lib/python3.8/site-packages/google/api_core/future/polling.py", line 107, in _blocking_poll
    retry_(self._done_or_raise)(**kwargs)
  File "/home/msonowal/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/home/msonowal/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/msonowal/dbt-env/lib/python3.8/site-packages/google/api_core/future/polling.py", line 85, in _done_or_raise
    if not self.done(**kwargs):
  File "/home/msonowal/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1022, in done
    self._query_results = self._client._get_query_results(
  File "/home/msonowal/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 1557, in _get_query_results
    resource = self._call_api(
  File "/home/msonowal/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 636, in _call_api
    return call()
  File "/home/msonowal/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/home/msonowal/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/msonowal/dbt-env/lib/python3.8/site-packages/google/cloud/_http.py", line 438, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.BadRequest: 400 GET https://bigquery.googleapis.com/bigquery/v2/projects/poc-dbt-310711/queries/30ca2603-d507-4044-a4f0-387ffd42cf7a?maxResults=0&location=US&prettyPrint=false: Syntax error: Unexpected keyword GROUP at [32:5]

(job ID: 30ca2603-d507-4044-a4f0-387ffd42cf7a)

                                                         -----Query Job SQL Follows-----                                                         

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "db_bigq_profile", "target_name": "dev", "node_id": "model.dbt_poc.customers"} */
   2:
   3:
   4:  create or replace table `poc-dbt-310711`.`dbt_poc_ds`.`customers`
   5:  
   6:  
   7:  OPTIONS()
   8:  as (
   9:    with customers as (
  10:
  11:    select * from `poc-dbt-310711`.`dbt_poc_ds`.`stg_customers`
  12:
  13:),
  14:
  15:orders as (
  16:
  17:    select * from `poc-dbt-310711`.`dbt_poc_ds`.`stg_orders`
  18:
  19:),
  20:
  21:customer_orders as (
  22:
  23:    select
  24:        customer_id,
  25:
  26:        min(order_date) as first_order_date,
  27:        max(order_date) as most_recent_order_date,
  28:        count(order_id) as number_of_orders
  29:
  30:    from orders,
  31:
  32:    group by 1
  33:
  34:),
  35:
  36:
  37:final as (
  38:
  39:    select
  40:        customers.customer_id,
  41:        customers.first_name,
  42:        customers.last_name,
  43:        customer_orders.first_order_date,
  44:        customer_orders.most_recent_order_date,
  45:        coalesce(customer_orders.number_of_orders, 0) as number_of_orders
  46:
  47:    from customers
  48:
  49:    left join customer_orders using (customer_id)
  50:
  51:)
  52:
  53:select * from final
  54:  );
  55:    
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/msonowal/dbt-env/lib/python3.8/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/home/msonowal/dbt-env/lib/python3.8/site-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/home/msonowal/dbt-env/lib/python3.8/site-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/home/msonowal/dbt-env/lib/python3.8/site-packages/dbt/task/run.py", line 248, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/home/msonowal/dbt-env/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/msonowal/dbt-env/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/home/msonowal/dbt-env/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/msonowal/dbt-env/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 128, in macro
  File "/home/msonowal/dbt-env/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/msonowal/dbt-env/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/msonowal/dbt-env/lib/python3.8/site-packages/dbt/clients/jinja.py", line 332, in __call__
    return self.call_macro(*args, **kwargs)
  File "/home/msonowal/dbt-env/lib/python3.8/site-packages/dbt/clients/jinja.py", line 259, in call_macro
    return macro(*args, **kwargs)
  File "/home/msonowal/dbt-env/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/home/msonowal/dbt-env/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/home/msonowal/dbt-env/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/home/msonowal/dbt-env/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/home/msonowal/dbt-env/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 227, in execute
    return self.connections.execute(
  File "/home/msonowal/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 338, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/home/msonowal/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 329, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/home/msonowal/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/home/msonowal/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 153, in exception_handler
    self.handle_error(e, message)
  File "/home/msonowal/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 141, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in model customers (models/customers.sql)
  Syntax error: Unexpected keyword GROUP at [32:5]
  compiled SQL at target/run/dbt_poc/models/customers.sql
2021-04-14 11:56:57.778484 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7a4adfb1-c905-44c9-8e49-b45a5c01c901', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5030c71490>]}
2021-04-14 11:56:57.778774 (Thread-4): 17:26:57 | 4 of 5 ERROR creating table model dbt_poc_ds.customers............... [ERROR in 3.37s]
2021-04-14 11:56:57.778900 (Thread-4): Finished running node model.dbt_poc.customers
2021-04-14 11:56:57.780025 (MainThread): Acquiring new bigquery connection "master".
2021-04-14 11:56:57.780309 (MainThread): 17:26:57 | 
2021-04-14 11:56:57.780417 (MainThread): 17:26:57 | Finished running 5 table models in 8.89s.
2021-04-14 11:56:57.780502 (MainThread): Connection 'master' was properly closed.
2021-04-14 11:56:57.780562 (MainThread): Connection 'model.dbt_poc.my_first_dbt_model' was properly closed.
2021-04-14 11:56:57.780617 (MainThread): Connection 'model.dbt_poc.my_second_dbt_model' was properly closed.
2021-04-14 11:56:57.780672 (MainThread): Connection 'model.dbt_poc.stg_orders' was properly closed.
2021-04-14 11:56:57.780727 (MainThread): Connection 'model.dbt_poc.customers' was properly closed.
2021-04-14 11:56:57.785214 (MainThread): 
2021-04-14 11:56:57.785353 (MainThread): Completed with 1 error and 0 warnings:
2021-04-14 11:56:57.785466 (MainThread): 
2021-04-14 11:56:57.785568 (MainThread): Database Error in model customers (models/customers.sql)
2021-04-14 11:56:57.785661 (MainThread):   Syntax error: Unexpected keyword GROUP at [32:5]
2021-04-14 11:56:57.785744 (MainThread):   compiled SQL at target/run/dbt_poc/models/customers.sql
2021-04-14 11:56:57.785847 (MainThread): 
Done. PASS=4 WARN=0 ERROR=1 SKIP=0 TOTAL=5
2021-04-14 11:56:57.786000 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5030c28940>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5030cdda00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5030c82ee0>]}
2021-04-14 11:56:57.786186 (MainThread): Flushing usage events
2021-04-14 11:57:32.263109 (MainThread): Running with dbt=0.19.1
2021-04-14 11:57:32.395292 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/home/msonowal/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-04-14 11:57:32.395703 (MainThread): Tracking: tracking
2021-04-14 11:57:32.401503 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5ae7e95040>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5ae65b3d60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5ae7eb88b0>]}
2021-04-14 11:57:32.407019 (MainThread): Partial parsing not enabled
2021-04-14 11:57:32.407602 (MainThread): Parsing macros/etc.sql
2021-04-14 11:57:32.409383 (MainThread): Parsing macros/adapters.sql
2021-04-14 11:57:32.421348 (MainThread): Parsing macros/catalog.sql
2021-04-14 11:57:32.424804 (MainThread): Parsing macros/materializations/seed.sql
2021-04-14 11:57:32.426605 (MainThread): Parsing macros/materializations/copy.sql
2021-04-14 11:57:32.429569 (MainThread): Parsing macros/materializations/table.sql
2021-04-14 11:57:32.435870 (MainThread): Parsing macros/materializations/incremental.sql
2021-04-14 11:57:32.443850 (MainThread): Parsing macros/materializations/view.sql
2021-04-14 11:57:32.445680 (MainThread): Parsing macros/materializations/snapshot.sql
2021-04-14 11:57:32.447309 (MainThread): Parsing macros/core.sql
2021-04-14 11:57:32.449837 (MainThread): Parsing macros/adapters/common.sql
2021-04-14 11:57:32.475278 (MainThread): Parsing macros/etc/is_incremental.sql
2021-04-14 11:57:32.476344 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-04-14 11:57:32.477622 (MainThread): Parsing macros/etc/query.sql
2021-04-14 11:57:32.478301 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-04-14 11:57:32.478858 (MainThread): Parsing macros/etc/datetime.sql
2021-04-14 11:57:32.484380 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-04-14 11:57:32.485416 (MainThread): Parsing macros/materializations/helpers.sql
2021-04-14 11:57:32.490752 (MainThread): Parsing macros/materializations/common/merge.sql
2021-04-14 11:57:32.499310 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-04-14 11:57:32.512205 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-04-14 11:57:32.516241 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-04-14 11:57:32.517404 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-04-14 11:57:32.520571 (MainThread): Parsing macros/materializations/view/view.sql
2021-04-14 11:57:32.524575 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-04-14 11:57:32.525647 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-04-14 11:57:32.544044 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-04-14 11:57:32.555395 (MainThread): Parsing macros/materializations/table/table.sql
2021-04-14 11:57:32.559582 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-04-14 11:57:32.561247 (MainThread): Parsing macros/schema_tests/unique.sql
2021-04-14 11:57:32.562274 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-04-14 11:57:32.563194 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-04-14 11:57:32.567323 (MainThread): Partial parsing not enabled
2021-04-14 11:57:32.581638 (MainThread): Acquiring new bigquery connection "model.dbt_poc.stg_customers".
2021-04-14 11:57:32.587112 (MainThread): Acquiring new bigquery connection "model.dbt_poc.stg_orders".
2021-04-14 11:57:32.588682 (MainThread): Acquiring new bigquery connection "model.dbt_poc.customers".
2021-04-14 11:57:32.590916 (MainThread): Acquiring new bigquery connection "model.dbt_poc.my_second_dbt_model".
2021-04-14 11:57:32.592990 (MainThread): Acquiring new bigquery connection "model.dbt_poc.my_first_dbt_model".
2021-04-14 11:57:32.633316 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a03786f0-3e63-494c-87fb-d5e863c126e4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5ae5645910>]}
2021-04-14 11:57:32.635611 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a03786f0-3e63-494c-87fb-d5e863c126e4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5ae565d070>]}
2021-04-14 11:57:32.635728 (MainThread): Found 5 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-04-14 11:57:32.636211 (MainThread): 
2021-04-14 11:57:32.636366 (MainThread): Acquiring new bigquery connection "master".
2021-04-14 11:57:32.637144 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_poc-dbt-310711".
2021-04-14 11:57:32.637397 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-04-14 11:57:33.650572 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_poc-dbt-310711_dbt_poc_ds".
2021-04-14 11:57:33.650834 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-04-14 11:57:33.656876 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-04-14 11:57:34.684343 (MainThread): 17:27:34 | Concurrency: 4 threads (target='dev')
2021-04-14 11:57:34.684528 (MainThread): 17:27:34 | 
2021-04-14 11:57:34.686757 (Thread-1): Began running node model.dbt_poc.my_first_dbt_model
2021-04-14 11:57:34.686936 (Thread-2): Began running node model.dbt_poc.stg_customers
2021-04-14 11:57:34.687193 (Thread-1): 17:27:34 | 1 of 5 START table model dbt_poc_ds.my_first_dbt_model............... [RUN]
2021-04-14 11:57:34.687322 (Thread-3): Began running node model.dbt_poc.stg_orders
2021-04-14 11:57:34.687590 (Thread-2): 17:27:34 | 2 of 5 START table model dbt_poc_ds.stg_customers.................... [RUN]
2021-04-14 11:57:34.687993 (Thread-1): Acquiring new bigquery connection "model.dbt_poc.my_first_dbt_model".
2021-04-14 11:57:34.688177 (Thread-3): 17:27:34 | 3 of 5 START table model dbt_poc_ds.stg_orders....................... [RUN]
2021-04-14 11:57:34.688494 (Thread-2): Acquiring new bigquery connection "model.dbt_poc.stg_customers".
2021-04-14 11:57:34.688653 (Thread-1): Compiling model.dbt_poc.my_first_dbt_model
2021-04-14 11:57:34.688936 (Thread-3): Acquiring new bigquery connection "model.dbt_poc.stg_orders".
2021-04-14 11:57:34.689096 (Thread-2): Compiling model.dbt_poc.stg_customers
2021-04-14 11:57:34.691594 (Thread-1): Writing injected SQL for node "model.dbt_poc.my_first_dbt_model"
2021-04-14 11:57:34.691716 (Thread-3): Compiling model.dbt_poc.stg_orders
2021-04-14 11:57:34.692685 (Thread-2): Writing injected SQL for node "model.dbt_poc.stg_customers"
2021-04-14 11:57:34.693950 (Thread-3): Writing injected SQL for node "model.dbt_poc.stg_orders"
2021-04-14 11:57:34.694260 (Thread-1): finished collecting timing info
2021-04-14 11:57:34.699462 (Thread-2): finished collecting timing info
2021-04-14 11:57:34.721750 (Thread-1): Opening a new connection, currently in state closed
2021-04-14 11:57:34.724416 (Thread-2): Opening a new connection, currently in state init
2021-04-14 11:57:34.724731 (Thread-3): finished collecting timing info
2021-04-14 11:57:34.726126 (Thread-3): Opening a new connection, currently in state init
2021-04-14 11:57:34.729814 (Thread-2): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-04-14 11:57:34.730123 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-04-14 11:57:34.730763 (Thread-1): unclosed <socket.socket fd=5, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.7', 37860), raddr=('172.217.163.170', 443)>
2021-04-14 11:57:34.730866 (Thread-1): unclosed <socket.socket fd=6, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.7', 54700), raddr=('142.250.67.42', 443)>
2021-04-14 11:57:34.731028 (Thread-1): unclosed <socket.socket fd=8, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.7', 54704), raddr=('142.250.67.42', 443)>
2021-04-14 11:57:34.731670 (Thread-1): unclosed <socket.socket fd=7, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.7', 37864), raddr=('172.217.163.170', 443)>
2021-04-14 11:57:34.732196 (Thread-3): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-04-14 11:57:35.655523 (Thread-1): Writing runtime SQL for node "model.dbt_poc.my_first_dbt_model"
2021-04-14 11:57:35.655850 (Thread-1): On model.dbt_poc.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "db_bigq_profile", "target_name": "dev", "node_id": "model.dbt_poc.my_first_dbt_model"} */


  create or replace table `poc-dbt-310711`.`dbt_poc_ds`.`my_first_dbt_model`
  
  
  OPTIONS()
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
    
2021-04-14 11:57:35.668969 (Thread-2): Writing runtime SQL for node "model.dbt_poc.stg_customers"
2021-04-14 11:57:35.669238 (Thread-2): On model.dbt_poc.stg_customers: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "db_bigq_profile", "target_name": "dev", "node_id": "model.dbt_poc.stg_customers"} */


  create or replace table `poc-dbt-310711`.`dbt_poc_ds`.`stg_customers`
  
  
  OPTIONS()
  as (
    select
    id as customer_id,
    first_name,
    last_name

from `dbt-tutorial`.jaffle_shop.customers
  );
    
2021-04-14 11:57:35.751155 (Thread-3): Writing runtime SQL for node "model.dbt_poc.stg_orders"
2021-04-14 11:57:35.751458 (Thread-3): On model.dbt_poc.stg_orders: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "db_bigq_profile", "target_name": "dev", "node_id": "model.dbt_poc.stg_orders"} */


  create or replace table `poc-dbt-310711`.`dbt_poc_ds`.`stg_orders`
  
  
  OPTIONS()
  as (
    select
    id as order_id,
    user_id as customer_id,
    order_date,
    status

from `dbt-tutorial`.jaffle_shop.orders
  );
    
2021-04-14 11:57:37.852434 (Thread-1): finished collecting timing info
2021-04-14 11:57:37.854895 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a03786f0-3e63-494c-87fb-d5e863c126e4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5ae5712b20>]}
2021-04-14 11:57:37.855331 (Thread-1): 17:27:37 | 1 of 5 OK created table model dbt_poc_ds.my_first_dbt_model.......... [CREATE TABLE (2.0 rows, 0.0 Bytes processed) in 3.17s]
2021-04-14 11:57:37.855477 (Thread-1): Finished running node model.dbt_poc.my_first_dbt_model
2021-04-14 11:57:37.855888 (Thread-4): Began running node model.dbt_poc.my_second_dbt_model
2021-04-14 11:57:37.856076 (Thread-4): 17:27:37 | 4 of 5 START table model dbt_poc_ds.my_second_dbt_model.............. [RUN]
2021-04-14 11:57:37.856299 (Thread-4): Acquiring new bigquery connection "model.dbt_poc.my_second_dbt_model".
2021-04-14 11:57:37.856381 (Thread-4): Compiling model.dbt_poc.my_second_dbt_model
2021-04-14 11:57:37.858213 (Thread-4): Writing injected SQL for node "model.dbt_poc.my_second_dbt_model"
2021-04-14 11:57:37.858440 (Thread-4): finished collecting timing info
2021-04-14 11:57:37.859794 (Thread-4): Opening a new connection, currently in state init
2021-04-14 11:57:37.865186 (Thread-4): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-04-14 11:57:38.073341 (Thread-2): finished collecting timing info
2021-04-14 11:57:38.073720 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a03786f0-3e63-494c-87fb-d5e863c126e4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5ae5712400>]}
2021-04-14 11:57:38.074013 (Thread-2): 17:27:38 | 2 of 5 OK created table model dbt_poc_ds.stg_customers............... [CREATE TABLE (100.0 rows, 1.9 KB processed) in 3.39s]
2021-04-14 11:57:38.074138 (Thread-2): Finished running node model.dbt_poc.stg_customers
2021-04-14 11:57:38.247169 (Thread-3): finished collecting timing info
2021-04-14 11:57:38.247549 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a03786f0-3e63-494c-87fb-d5e863c126e4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5ae5712f70>]}
2021-04-14 11:57:38.247848 (Thread-3): 17:27:38 | 3 of 5 OK created table model dbt_poc_ds.stg_orders.................. [CREATE TABLE (99.0 rows, 3.3 KB processed) in 3.56s]
2021-04-14 11:57:38.247972 (Thread-3): Finished running node model.dbt_poc.stg_orders
2021-04-14 11:57:38.248349 (Thread-1): Began running node model.dbt_poc.customers
2021-04-14 11:57:38.248584 (Thread-1): 17:27:38 | 5 of 5 START table model dbt_poc_ds.customers........................ [RUN]
2021-04-14 11:57:38.248829 (Thread-1): Acquiring new bigquery connection "model.dbt_poc.customers".
2021-04-14 11:57:38.248925 (Thread-1): Compiling model.dbt_poc.customers
2021-04-14 11:57:38.251462 (Thread-1): Writing injected SQL for node "model.dbt_poc.customers"
2021-04-14 11:57:38.251723 (Thread-1): finished collecting timing info
2021-04-14 11:57:38.253212 (Thread-1): Opening a new connection, currently in state closed
2021-04-14 11:57:38.259495 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-04-14 11:57:38.775596 (Thread-1): Writing runtime SQL for node "model.dbt_poc.customers"
2021-04-14 11:57:38.775932 (Thread-1): On model.dbt_poc.customers: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "db_bigq_profile", "target_name": "dev", "node_id": "model.dbt_poc.customers"} */


  create or replace table `poc-dbt-310711`.`dbt_poc_ds`.`customers`
  
  
  OPTIONS()
  as (
    with customers as (

    select * from `poc-dbt-310711`.`dbt_poc_ds`.`stg_customers`

),

orders as (

    select * from `poc-dbt-310711`.`dbt_poc_ds`.`stg_orders`

),

customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final
  );
    
2021-04-14 11:57:38.819234 (Thread-4): Writing runtime SQL for node "model.dbt_poc.my_second_dbt_model"
2021-04-14 11:57:38.819539 (Thread-4): On model.dbt_poc.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "db_bigq_profile", "target_name": "dev", "node_id": "model.dbt_poc.my_second_dbt_model"} */


  create or replace table `poc-dbt-310711`.`dbt_poc_ds`.`my_second_dbt_model`
  
  
  OPTIONS()
  as (
    -- Use the `ref` function to select from other models

select *
from `poc-dbt-310711`.`dbt_poc_ds`.`my_first_dbt_model`
where id = 1
  );
    
2021-04-14 11:57:41.070947 (Thread-4): finished collecting timing info
2021-04-14 11:57:41.071361 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a03786f0-3e63-494c-87fb-d5e863c126e4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5ae4541f70>]}
2021-04-14 11:57:41.071665 (Thread-4): 17:27:41 | 4 of 5 OK created table model dbt_poc_ds.my_second_dbt_model......... [CREATE TABLE (1.0 rows, 8.0 Bytes processed) in 3.22s]
2021-04-14 11:57:41.071798 (Thread-4): Finished running node model.dbt_poc.my_second_dbt_model
2021-04-14 11:57:41.682779 (Thread-1): finished collecting timing info
2021-04-14 11:57:41.683194 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a03786f0-3e63-494c-87fb-d5e863c126e4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5ae5604e80>]}
2021-04-14 11:57:41.683496 (Thread-1): 17:27:41 | 5 of 5 OK created table model dbt_poc_ds.customers................... [CREATE TABLE (100.0 rows, 4.3 KB processed) in 3.43s]
2021-04-14 11:57:41.683633 (Thread-1): Finished running node model.dbt_poc.customers
2021-04-14 11:57:41.684768 (MainThread): Acquiring new bigquery connection "master".
2021-04-14 11:57:41.685127 (MainThread): 17:27:41 | 
2021-04-14 11:57:41.685241 (MainThread): 17:27:41 | Finished running 5 table models in 9.05s.
2021-04-14 11:57:41.685331 (MainThread): Connection 'master' was properly closed.
2021-04-14 11:57:41.685393 (MainThread): Connection 'model.dbt_poc.customers' was properly closed.
2021-04-14 11:57:41.685451 (MainThread): Connection 'model.dbt_poc.stg_customers' was properly closed.
2021-04-14 11:57:41.685507 (MainThread): Connection 'model.dbt_poc.stg_orders' was properly closed.
2021-04-14 11:57:41.685562 (MainThread): Connection 'model.dbt_poc.my_second_dbt_model' was properly closed.
2021-04-14 11:57:41.689895 (MainThread): 
2021-04-14 11:57:41.690020 (MainThread): Completed successfully
2021-04-14 11:57:41.690126 (MainThread): 
Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
2021-04-14 11:57:41.690276 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5ae56bc7c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5ae55ed5e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5ae565f910>]}
2021-04-14 11:57:41.690491 (MainThread): Flushing usage events
2021-04-14 11:57:51.025381 (MainThread): Running with dbt=0.19.1
2021-04-14 11:57:51.160833 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=['customers'], partial_parse=None, profile=None, profiles_dir='/home/msonowal/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-04-14 11:57:51.161195 (MainThread): Tracking: tracking
2021-04-14 11:57:51.166779 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd8ead58820>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd8e94abdc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd8ead74910>]}
2021-04-14 11:57:51.172229 (MainThread): Partial parsing not enabled
2021-04-14 11:57:51.172753 (MainThread): Parsing macros/etc.sql
2021-04-14 11:57:51.174468 (MainThread): Parsing macros/adapters.sql
2021-04-14 11:57:51.186462 (MainThread): Parsing macros/catalog.sql
2021-04-14 11:57:51.189859 (MainThread): Parsing macros/materializations/seed.sql
2021-04-14 11:57:51.191629 (MainThread): Parsing macros/materializations/copy.sql
2021-04-14 11:57:51.194567 (MainThread): Parsing macros/materializations/table.sql
2021-04-14 11:57:51.201123 (MainThread): Parsing macros/materializations/incremental.sql
2021-04-14 11:57:51.209303 (MainThread): Parsing macros/materializations/view.sql
2021-04-14 11:57:51.211105 (MainThread): Parsing macros/materializations/snapshot.sql
2021-04-14 11:57:51.212630 (MainThread): Parsing macros/core.sql
2021-04-14 11:57:51.215104 (MainThread): Parsing macros/adapters/common.sql
2021-04-14 11:57:51.241063 (MainThread): Parsing macros/etc/is_incremental.sql
2021-04-14 11:57:51.242095 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-04-14 11:57:51.243347 (MainThread): Parsing macros/etc/query.sql
2021-04-14 11:57:51.243995 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-04-14 11:57:51.244567 (MainThread): Parsing macros/etc/datetime.sql
2021-04-14 11:57:51.250248 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-04-14 11:57:51.251293 (MainThread): Parsing macros/materializations/helpers.sql
2021-04-14 11:57:51.256850 (MainThread): Parsing macros/materializations/common/merge.sql
2021-04-14 11:57:51.265571 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-04-14 11:57:51.278864 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-04-14 11:57:51.282977 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-04-14 11:57:51.284126 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-04-14 11:57:51.287311 (MainThread): Parsing macros/materializations/view/view.sql
2021-04-14 11:57:51.291311 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-04-14 11:57:51.292374 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-04-14 11:57:51.311357 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-04-14 11:57:51.322920 (MainThread): Parsing macros/materializations/table/table.sql
2021-04-14 11:57:51.327236 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-04-14 11:57:51.328939 (MainThread): Parsing macros/schema_tests/unique.sql
2021-04-14 11:57:51.329998 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-04-14 11:57:51.330932 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-04-14 11:57:51.335122 (MainThread): Partial parsing not enabled
2021-04-14 11:57:51.349354 (MainThread): Acquiring new bigquery connection "model.dbt_poc.stg_customers".
2021-04-14 11:57:51.354770 (MainThread): Acquiring new bigquery connection "model.dbt_poc.stg_orders".
2021-04-14 11:57:51.356344 (MainThread): Acquiring new bigquery connection "model.dbt_poc.customers".
2021-04-14 11:57:51.358573 (MainThread): Acquiring new bigquery connection "model.dbt_poc.my_second_dbt_model".
2021-04-14 11:57:51.360615 (MainThread): Acquiring new bigquery connection "model.dbt_poc.my_first_dbt_model".
2021-04-14 11:57:51.400209 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e6718367-42b8-4948-a5d1-809c67e6275d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd8e853e2b0>]}
2021-04-14 11:57:51.402521 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e6718367-42b8-4948-a5d1-809c67e6275d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd8e85a4940>]}
2021-04-14 11:57:51.402634 (MainThread): Found 5 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-04-14 11:57:51.403068 (MainThread): 
2021-04-14 11:57:51.403222 (MainThread): Acquiring new bigquery connection "master".
2021-04-14 11:57:51.403906 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_poc-dbt-310711".
2021-04-14 11:57:51.404164 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-04-14 11:57:51.962061 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_poc-dbt-310711_dbt_poc_ds".
2021-04-14 11:57:51.962329 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-04-14 11:57:51.968344 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-04-14 11:57:52.932023 (MainThread): 17:27:52 | Concurrency: 4 threads (target='dev')
2021-04-14 11:57:52.932202 (MainThread): 17:27:52 | 
2021-04-14 11:57:52.934421 (Thread-1): Began running node model.dbt_poc.customers
2021-04-14 11:57:52.934695 (Thread-1): 17:27:52 | 1 of 1 START table model dbt_poc_ds.customers........................ [RUN]
2021-04-14 11:57:52.934978 (Thread-1): Acquiring new bigquery connection "model.dbt_poc.customers".
2021-04-14 11:57:52.935094 (Thread-1): Compiling model.dbt_poc.customers
2021-04-14 11:57:52.937835 (Thread-1): Writing injected SQL for node "model.dbt_poc.customers"
2021-04-14 11:57:52.938116 (Thread-1): finished collecting timing info
2021-04-14 11:57:52.952194 (Thread-1): Opening a new connection, currently in state closed
2021-04-14 11:57:52.955308 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-04-14 11:57:53.879837 (Thread-1): Writing runtime SQL for node "model.dbt_poc.customers"
2021-04-14 11:57:53.880067 (Thread-1): On model.dbt_poc.customers: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "db_bigq_profile", "target_name": "dev", "node_id": "model.dbt_poc.customers"} */


  create or replace table `poc-dbt-310711`.`dbt_poc_ds`.`customers`
  
  
  OPTIONS()
  as (
    with customers as (

    select * from `poc-dbt-310711`.`dbt_poc_ds`.`stg_customers`

),

orders as (

    select * from `poc-dbt-310711`.`dbt_poc_ds`.`stg_orders`

),

customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final
  );
    
2021-04-14 11:57:56.381977 (Thread-1): finished collecting timing info
2021-04-14 11:57:56.382373 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e6718367-42b8-4948-a5d1-809c67e6275d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd8e85e14c0>]}
2021-04-14 11:57:56.382681 (Thread-1): 17:27:56 | 1 of 1 OK created table model dbt_poc_ds.customers................... [CREATE TABLE (100.0 rows, 4.3 KB processed) in 3.45s]
2021-04-14 11:57:56.382817 (Thread-1): Finished running node model.dbt_poc.customers
2021-04-14 11:57:56.384047 (MainThread): Acquiring new bigquery connection "master".
2021-04-14 11:57:56.384459 (MainThread): 17:27:56 | 
2021-04-14 11:57:56.384621 (MainThread): 17:27:56 | Finished running 1 table model in 4.98s.
2021-04-14 11:57:56.384765 (MainThread): Connection 'master' was properly closed.
2021-04-14 11:57:56.384878 (MainThread): Connection 'model.dbt_poc.customers' was properly closed.
2021-04-14 11:57:56.389471 (MainThread): 
2021-04-14 11:57:56.389648 (MainThread): Completed successfully
2021-04-14 11:57:56.389807 (MainThread): 
Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
2021-04-14 11:57:56.390036 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd8e8611040>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd8e84f8dc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd8e84ef9d0>]}
2021-04-14 11:57:56.390299 (MainThread): Flushing usage events
2021-04-14 12:00:52.522415 (MainThread): Running with dbt=0.19.1
2021-04-14 12:00:52.658183 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, data=False, debug=False, defer=None, exclude=None, fail_fast=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/home/msonowal/.dbt', project_dir=None, record_timing_info=None, rpc_method='test', schema=False, selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='test', write_json=True)
2021-04-14 12:00:52.658556 (MainThread): Tracking: tracking
2021-04-14 12:00:52.664337 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc403466fa0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc401b64d00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc403468850>]}
2021-04-14 12:00:52.669876 (MainThread): Partial parsing not enabled
2021-04-14 12:00:52.670416 (MainThread): Parsing macros/etc.sql
2021-04-14 12:00:52.672208 (MainThread): Parsing macros/adapters.sql
2021-04-14 12:00:52.684061 (MainThread): Parsing macros/catalog.sql
2021-04-14 12:00:52.687536 (MainThread): Parsing macros/materializations/seed.sql
2021-04-14 12:00:52.689282 (MainThread): Parsing macros/materializations/copy.sql
2021-04-14 12:00:52.692201 (MainThread): Parsing macros/materializations/table.sql
2021-04-14 12:00:52.698692 (MainThread): Parsing macros/materializations/incremental.sql
2021-04-14 12:00:52.706897 (MainThread): Parsing macros/materializations/view.sql
2021-04-14 12:00:52.708695 (MainThread): Parsing macros/materializations/snapshot.sql
2021-04-14 12:00:52.710230 (MainThread): Parsing macros/core.sql
2021-04-14 12:00:52.712702 (MainThread): Parsing macros/adapters/common.sql
2021-04-14 12:00:52.738605 (MainThread): Parsing macros/etc/is_incremental.sql
2021-04-14 12:00:52.739651 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-04-14 12:00:52.740957 (MainThread): Parsing macros/etc/query.sql
2021-04-14 12:00:52.741615 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-04-14 12:00:52.742196 (MainThread): Parsing macros/etc/datetime.sql
2021-04-14 12:00:52.747843 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-04-14 12:00:52.748885 (MainThread): Parsing macros/materializations/helpers.sql
2021-04-14 12:00:52.754400 (MainThread): Parsing macros/materializations/common/merge.sql
2021-04-14 12:00:52.763231 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-04-14 12:00:52.776549 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-04-14 12:00:52.780641 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-04-14 12:00:52.781816 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-04-14 12:00:52.785070 (MainThread): Parsing macros/materializations/view/view.sql
2021-04-14 12:00:52.789154 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-04-14 12:00:52.790224 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-04-14 12:00:52.809710 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-04-14 12:00:52.821320 (MainThread): Parsing macros/materializations/table/table.sql
2021-04-14 12:00:52.825636 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-04-14 12:00:52.827334 (MainThread): Parsing macros/schema_tests/unique.sql
2021-04-14 12:00:52.828381 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-04-14 12:00:52.829313 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-04-14 12:00:52.833488 (MainThread): Partial parsing not enabled
2021-04-14 12:00:52.848005 (MainThread): Acquiring new bigquery connection "model.dbt_poc.stg_customers".
2021-04-14 12:00:52.853504 (MainThread): Acquiring new bigquery connection "model.dbt_poc.stg_orders".
2021-04-14 12:00:52.855085 (MainThread): Acquiring new bigquery connection "model.dbt_poc.customers".
2021-04-14 12:00:52.857326 (MainThread): Acquiring new bigquery connection "model.dbt_poc.my_second_dbt_model".
2021-04-14 12:00:52.859385 (MainThread): Acquiring new bigquery connection "model.dbt_poc.my_first_dbt_model".
2021-04-14 12:00:52.902695 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a7360485-f81a-491c-aaaf-1c524e6aaa38', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc400b9ea90>]}
2021-04-14 12:00:52.905135 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a7360485-f81a-491c-aaaf-1c524e6aaa38', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc400c7f850>]}
2021-04-14 12:00:52.905248 (MainThread): Found 5 models, 6 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-04-14 12:00:52.905819 (MainThread): 
2021-04-14 12:00:52.905982 (MainThread): Acquiring new bigquery connection "master".
2021-04-14 12:00:52.906939 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_poc-dbt-310711_dbt_poc_ds".
2021-04-14 12:00:52.907122 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2021-04-14 12:00:52.911998 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-04-14 12:00:53.623239 (MainThread): 17:30:53 | Concurrency: 4 threads (target='dev')
2021-04-14 12:00:53.623422 (MainThread): 17:30:53 | 
2021-04-14 12:00:53.625472 (Thread-1): Began running node test.dbt_poc.not_null_customers_customers_id
2021-04-14 12:00:53.625642 (Thread-1): 17:30:53 | 1 of 6 START test not_null_customers_customers_id.................... [RUN]
2021-04-14 12:00:53.625795 (Thread-2): Began running node test.dbt_poc.not_null_my_first_dbt_model_id
2021-04-14 12:00:53.626265 (Thread-1): Acquiring new bigquery connection "test.dbt_poc.not_null_customers_customers_id".
2021-04-14 12:00:53.626383 (Thread-3): Began running node test.dbt_poc.not_null_my_second_dbt_model_id
2021-04-14 12:00:53.626584 (Thread-4): Began running node test.dbt_poc.unique_customers_customers_id
2021-04-14 12:00:53.626729 (Thread-2): 17:30:53 | 2 of 6 START test not_null_my_first_dbt_model_id..................... [RUN]
2021-04-14 12:00:53.626913 (Thread-1): Compiling test.dbt_poc.not_null_customers_customers_id
2021-04-14 12:00:53.627113 (Thread-3): 17:30:53 | 3 of 6 START test not_null_my_second_dbt_model_id.................... [RUN]
2021-04-14 12:00:53.627313 (Thread-4): 17:30:53 | 4 of 6 START test unique_customers_customers_id...................... [RUN]
2021-04-14 12:00:53.627669 (Thread-2): Acquiring new bigquery connection "test.dbt_poc.not_null_my_first_dbt_model_id".
2021-04-14 12:00:53.634715 (Thread-1): Writing injected SQL for node "test.dbt_poc.not_null_customers_customers_id"
2021-04-14 12:00:53.635046 (Thread-3): Acquiring new bigquery connection "test.dbt_poc.not_null_my_second_dbt_model_id".
2021-04-14 12:00:53.635482 (Thread-4): Acquiring new bigquery connection "test.dbt_poc.unique_customers_customers_id".
2021-04-14 12:00:53.635640 (Thread-2): Compiling test.dbt_poc.not_null_my_first_dbt_model_id
2021-04-14 12:00:53.635871 (Thread-3): Compiling test.dbt_poc.not_null_my_second_dbt_model_id
2021-04-14 12:00:53.636019 (Thread-4): Compiling test.dbt_poc.unique_customers_customers_id
2021-04-14 12:00:53.636162 (Thread-1): finished collecting timing info
2021-04-14 12:00:53.639993 (Thread-2): Writing injected SQL for node "test.dbt_poc.not_null_my_first_dbt_model_id"
2021-04-14 12:00:53.643875 (Thread-3): Writing injected SQL for node "test.dbt_poc.not_null_my_second_dbt_model_id"
2021-04-14 12:00:53.649454 (Thread-4): Writing injected SQL for node "test.dbt_poc.unique_customers_customers_id"
2021-04-14 12:00:53.649576 (Thread-1): Opening a new connection, currently in state closed
2021-04-14 12:00:53.649962 (Thread-2): finished collecting timing info
2021-04-14 12:00:53.650072 (Thread-3): finished collecting timing info
2021-04-14 12:00:53.650252 (Thread-2): Opening a new connection, currently in state init
2021-04-14 12:00:53.650386 (Thread-4): finished collecting timing info
2021-04-14 12:00:53.650595 (Thread-3): Opening a new connection, currently in state init
2021-04-14 12:00:53.650751 (Thread-4): Opening a new connection, currently in state init
2021-04-14 12:00:53.655446 (Thread-1): On test.dbt_poc.not_null_customers_customers_id: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "db_bigq_profile", "target_name": "dev", "node_id": "test.dbt_poc.not_null_customers_customers_id"} */

    
    



select count(*) as validation_errors
from `poc-dbt-310711`.`dbt_poc_ds`.`customers`
where customers_id is null



2021-04-14 12:00:53.655568 (Thread-3): On test.dbt_poc.not_null_my_second_dbt_model_id: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "db_bigq_profile", "target_name": "dev", "node_id": "test.dbt_poc.not_null_my_second_dbt_model_id"} */

    
    



select count(*) as validation_errors
from `poc-dbt-310711`.`dbt_poc_ds`.`my_second_dbt_model`
where id is null



2021-04-14 12:00:53.656865 (Thread-4): On test.dbt_poc.unique_customers_customers_id: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "db_bigq_profile", "target_name": "dev", "node_id": "test.dbt_poc.unique_customers_customers_id"} */

    
    



select count(*) as validation_errors
from (

    select
        customers_id

    from `poc-dbt-310711`.`dbt_poc_ds`.`customers`
    where customers_id is not null
    group by customers_id
    having count(*) > 1

) validation_errors



2021-04-14 12:00:53.659788 (Thread-3): unclosed <socket.socket fd=5, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.7', 49234), raddr=('142.250.182.74', 443)>
2021-04-14 12:00:53.659916 (Thread-2): On test.dbt_poc.not_null_my_first_dbt_model_id: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "db_bigq_profile", "target_name": "dev", "node_id": "test.dbt_poc.not_null_my_first_dbt_model_id"} */

    
    



select count(*) as validation_errors
from `poc-dbt-310711`.`dbt_poc_ds`.`my_first_dbt_model`
where id is null



2021-04-14 12:00:53.660429 (Thread-3): unclosed <socket.socket fd=6, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.7', 54812), raddr=('142.250.67.42', 443)>
2021-04-14 12:00:55.013064 (Thread-4): Retry attempt 1 of 1 after error: BadRequest('GET https://bigquery.googleapis.com/bigquery/v2/projects/poc-dbt-310711/queries/c855d11b-07ce-43a5-b6ce-3891e422317c?maxResults=0&location=US&prettyPrint=false: Unrecognized name: customers_id; Did you mean customer_id? at [15:11]')
2021-04-14 12:00:55.019421 (Thread-1): Retry attempt 1 of 1 after error: BadRequest('GET https://bigquery.googleapis.com/bigquery/v2/projects/poc-dbt-310711/queries/42b11cf9-46b9-434b-abf2-1941349bf5b6?maxResults=0&location=US&prettyPrint=false: Unrecognized name: customers_id; Did you mean customer_id? at [10:7]')
2021-04-14 12:00:55.875874 (Thread-2): finished collecting timing info
2021-04-14 12:00:55.876289 (Thread-2): 17:30:55 | 2 of 6 FAIL 1 not_null_my_first_dbt_model_id......................... [FAIL 1 in 2.25s]
2021-04-14 12:00:55.876464 (Thread-2): Finished running node test.dbt_poc.not_null_my_first_dbt_model_id
2021-04-14 12:00:55.876588 (Thread-2): Began running node test.dbt_poc.unique_my_first_dbt_model_id
2021-04-14 12:00:55.876800 (Thread-2): 17:30:55 | 5 of 6 START test unique_my_first_dbt_model_id....................... [RUN]
2021-04-14 12:00:55.877038 (Thread-2): Acquiring new bigquery connection "test.dbt_poc.unique_my_first_dbt_model_id".
2021-04-14 12:00:55.877135 (Thread-2): Compiling test.dbt_poc.unique_my_first_dbt_model_id
2021-04-14 12:00:55.880744 (Thread-2): Writing injected SQL for node "test.dbt_poc.unique_my_first_dbt_model_id"
2021-04-14 12:00:55.880970 (Thread-2): finished collecting timing info
2021-04-14 12:00:55.881099 (Thread-2): Opening a new connection, currently in state closed
2021-04-14 12:00:55.886317 (Thread-2): On test.dbt_poc.unique_my_first_dbt_model_id: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "db_bigq_profile", "target_name": "dev", "node_id": "test.dbt_poc.unique_my_first_dbt_model_id"} */

    
    



select count(*) as validation_errors
from (

    select
        id

    from `poc-dbt-310711`.`dbt_poc_ds`.`my_first_dbt_model`
    where id is not null
    group by id
    having count(*) > 1

) validation_errors



2021-04-14 12:00:55.898636 (Thread-3): finished collecting timing info
2021-04-14 12:00:55.899149 (Thread-3): 17:30:55 | 3 of 6 PASS not_null_my_second_dbt_model_id.......................... [PASS in 2.26s]
2021-04-14 12:00:55.899337 (Thread-3): Finished running node test.dbt_poc.not_null_my_second_dbt_model_id
2021-04-14 12:00:55.899549 (Thread-3): Began running node test.dbt_poc.unique_my_second_dbt_model_id
2021-04-14 12:00:55.899839 (Thread-3): 17:30:55 | 6 of 6 START test unique_my_second_dbt_model_id...................... [RUN]
2021-04-14 12:00:55.900239 (Thread-3): Acquiring new bigquery connection "test.dbt_poc.unique_my_second_dbt_model_id".
2021-04-14 12:00:55.900401 (Thread-3): Compiling test.dbt_poc.unique_my_second_dbt_model_id
2021-04-14 12:00:55.904571 (Thread-3): Writing injected SQL for node "test.dbt_poc.unique_my_second_dbt_model_id"
2021-04-14 12:00:55.904855 (Thread-3): finished collecting timing info
2021-04-14 12:00:55.905049 (Thread-3): Opening a new connection, currently in state closed
2021-04-14 12:00:55.911279 (Thread-3): On test.dbt_poc.unique_my_second_dbt_model_id: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "db_bigq_profile", "target_name": "dev", "node_id": "test.dbt_poc.unique_my_second_dbt_model_id"} */

    
    



select count(*) as validation_errors
from (

    select
        id

    from `poc-dbt-310711`.`dbt_poc_ds`.`my_second_dbt_model`
    where id is not null
    group by id
    having count(*) > 1

) validation_errors



2021-04-14 12:00:56.492317 (Thread-4): finished collecting timing info
2021-04-14 12:00:56.492738 (Thread-4): Database Error in test unique_customers_customers_id (models/schema.yml)
  Unrecognized name: customers_id; Did you mean customer_id? at [15:11]
  compiled SQL at target/compiled/dbt_poc/models/schema.yml/schema_test/unique_customers_customers_id.sql
Traceback (most recent call last):
  File "/home/msonowal/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 149, in exception_handler
    yield
  File "/home/msonowal/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/home/msonowal/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/msonowal/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 327, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/home/msonowal/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 520, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/home/msonowal/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1146, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/home/msonowal/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/job/base.py", line 631, in result
    return super(_AsyncJob, self).result(timeout=timeout, **kwargs)
  File "/home/msonowal/dbt-env/lib/python3.8/site-packages/google/api_core/future/polling.py", line 129, in result
    self._blocking_poll(timeout=timeout, **kwargs)
  File "/home/msonowal/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1042, in _blocking_poll
    super(QueryJob, self)._blocking_poll(timeout=timeout, **kwargs)
  File "/home/msonowal/dbt-env/lib/python3.8/site-packages/google/api_core/future/polling.py", line 107, in _blocking_poll
    retry_(self._done_or_raise)(**kwargs)
  File "/home/msonowal/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/home/msonowal/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/msonowal/dbt-env/lib/python3.8/site-packages/google/api_core/future/polling.py", line 85, in _done_or_raise
    if not self.done(**kwargs):
  File "/home/msonowal/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1022, in done
    self._query_results = self._client._get_query_results(
  File "/home/msonowal/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 1557, in _get_query_results
    resource = self._call_api(
  File "/home/msonowal/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 636, in _call_api
    return call()
  File "/home/msonowal/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/home/msonowal/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/msonowal/dbt-env/lib/python3.8/site-packages/google/cloud/_http.py", line 438, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.BadRequest: 400 GET https://bigquery.googleapis.com/bigquery/v2/projects/poc-dbt-310711/queries/7712c05f-193d-46d8-9d0a-7cd569d829e9?maxResults=0&location=US&prettyPrint=false: Unrecognized name: customers_id; Did you mean customer_id? at [15:11]

(job ID: 7712c05f-193d-46d8-9d0a-7cd569d829e9)

                                                                  -----Query Job SQL Follows-----                                                                   

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "db_bigq_profile", "target_name": "dev", "node_id": "test.dbt_poc.unique_customers_customers_id"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from (
  10:
  11:    select
  12:        customers_id
  13:
  14:    from `poc-dbt-310711`.`dbt_poc_ds`.`customers`
  15:    where customers_id is not null
  16:    group by customers_id
  17:    having count(*) > 1
  18:
  19:) validation_errors
  20:
  21:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/msonowal/dbt-env/lib/python3.8/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/home/msonowal/dbt-env/lib/python3.8/site-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/home/msonowal/dbt-env/lib/python3.8/site-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/home/msonowal/dbt-env/lib/python3.8/site-packages/dbt/task/test.py", line 85, in execute
    failed_rows = self.execute_schema_test(test)
  File "/home/msonowal/dbt-env/lib/python3.8/site-packages/dbt/task/test.py", line 62, in execute_schema_test
    res, table = self.adapter.execute(
  File "/home/msonowal/dbt-env/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 227, in execute
    return self.connections.execute(
  File "/home/msonowal/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 338, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/home/msonowal/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 329, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/home/msonowal/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/home/msonowal/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 153, in exception_handler
    self.handle_error(e, message)
  File "/home/msonowal/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 141, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test unique_customers_customers_id (models/schema.yml)
  Unrecognized name: customers_id; Did you mean customer_id? at [15:11]
  compiled SQL at target/compiled/dbt_poc/models/schema.yml/schema_test/unique_customers_customers_id.sql
2021-04-14 12:00:56.494921 (Thread-4): 17:30:56 | 4 of 6 ERROR unique_customers_customers_id........................... [ERROR in 2.86s]
2021-04-14 12:00:56.495080 (Thread-4): Finished running node test.dbt_poc.unique_customers_customers_id
2021-04-14 12:00:56.765834 (Thread-1): finished collecting timing info
2021-04-14 12:00:56.766202 (Thread-1): Database Error in test not_null_customers_customers_id (models/schema.yml)
  Unrecognized name: customers_id; Did you mean customer_id? at [10:7]
  compiled SQL at target/compiled/dbt_poc/models/schema.yml/schema_test/not_null_customers_customers_id.sql
Traceback (most recent call last):
  File "/home/msonowal/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 149, in exception_handler
    yield
  File "/home/msonowal/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/home/msonowal/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/msonowal/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 327, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/home/msonowal/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 520, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/home/msonowal/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1146, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/home/msonowal/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/job/base.py", line 631, in result
    return super(_AsyncJob, self).result(timeout=timeout, **kwargs)
  File "/home/msonowal/dbt-env/lib/python3.8/site-packages/google/api_core/future/polling.py", line 129, in result
    self._blocking_poll(timeout=timeout, **kwargs)
  File "/home/msonowal/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1042, in _blocking_poll
    super(QueryJob, self)._blocking_poll(timeout=timeout, **kwargs)
  File "/home/msonowal/dbt-env/lib/python3.8/site-packages/google/api_core/future/polling.py", line 107, in _blocking_poll
    retry_(self._done_or_raise)(**kwargs)
  File "/home/msonowal/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/home/msonowal/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/msonowal/dbt-env/lib/python3.8/site-packages/google/api_core/future/polling.py", line 85, in _done_or_raise
    if not self.done(**kwargs):
  File "/home/msonowal/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1022, in done
    self._query_results = self._client._get_query_results(
  File "/home/msonowal/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 1557, in _get_query_results
    resource = self._call_api(
  File "/home/msonowal/dbt-env/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 636, in _call_api
    return call()
  File "/home/msonowal/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/home/msonowal/dbt-env/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/home/msonowal/dbt-env/lib/python3.8/site-packages/google/cloud/_http.py", line 438, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.BadRequest: 400 GET https://bigquery.googleapis.com/bigquery/v2/projects/poc-dbt-310711/queries/bd04a569-f92e-4b63-ac20-26578a446d5b?maxResults=0&location=US&prettyPrint=false: Unrecognized name: customers_id; Did you mean customer_id? at [10:7]

(job ID: bd04a569-f92e-4b63-ac20-26578a446d5b)

                                                                   -----Query Job SQL Follows-----                                                                    

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "db_bigq_profile", "target_name": "dev", "node_id": "test.dbt_poc.not_null_customers_customers_id"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `poc-dbt-310711`.`dbt_poc_ds`.`customers`
  10:where customers_id is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/msonowal/dbt-env/lib/python3.8/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/home/msonowal/dbt-env/lib/python3.8/site-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/home/msonowal/dbt-env/lib/python3.8/site-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/home/msonowal/dbt-env/lib/python3.8/site-packages/dbt/task/test.py", line 85, in execute
    failed_rows = self.execute_schema_test(test)
  File "/home/msonowal/dbt-env/lib/python3.8/site-packages/dbt/task/test.py", line 62, in execute_schema_test
    res, table = self.adapter.execute(
  File "/home/msonowal/dbt-env/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 227, in execute
    return self.connections.execute(
  File "/home/msonowal/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 338, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/home/msonowal/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 329, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/home/msonowal/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/home/msonowal/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 153, in exception_handler
    self.handle_error(e, message)
  File "/home/msonowal/dbt-env/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 141, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test not_null_customers_customers_id (models/schema.yml)
  Unrecognized name: customers_id; Did you mean customer_id? at [10:7]
  compiled SQL at target/compiled/dbt_poc/models/schema.yml/schema_test/not_null_customers_customers_id.sql
2021-04-14 12:00:56.766704 (Thread-1): 17:30:56 | 1 of 6 ERROR not_null_customers_customers_id......................... [ERROR in 3.14s]
2021-04-14 12:00:56.766819 (Thread-1): Finished running node test.dbt_poc.not_null_customers_customers_id
2021-04-14 12:00:58.009036 (Thread-2): finished collecting timing info
2021-04-14 12:00:58.009425 (Thread-2): 17:30:58 | 5 of 6 PASS unique_my_first_dbt_model_id............................. [PASS in 2.13s]
2021-04-14 12:00:58.009551 (Thread-2): Finished running node test.dbt_poc.unique_my_first_dbt_model_id
2021-04-14 12:00:58.642289 (Thread-3): finished collecting timing info
2021-04-14 12:00:58.642689 (Thread-3): 17:30:58 | 6 of 6 PASS unique_my_second_dbt_model_id............................ [PASS in 2.74s]
2021-04-14 12:00:58.642814 (Thread-3): Finished running node test.dbt_poc.unique_my_second_dbt_model_id
2021-04-14 12:00:58.644033 (MainThread): Acquiring new bigquery connection "master".
2021-04-14 12:00:58.644371 (MainThread): 17:30:58 | 
2021-04-14 12:00:58.644489 (MainThread): 17:30:58 | Finished running 6 tests in 5.74s.
2021-04-14 12:00:58.644577 (MainThread): Connection 'master' was properly closed.
2021-04-14 12:00:58.644643 (MainThread): Connection 'test.dbt_poc.not_null_customers_customers_id' was properly closed.
2021-04-14 12:00:58.644706 (MainThread): Connection 'test.dbt_poc.unique_my_first_dbt_model_id' was properly closed.
2021-04-14 12:00:58.644761 (MainThread): Connection 'test.dbt_poc.unique_my_second_dbt_model_id' was properly closed.
2021-04-14 12:00:58.644816 (MainThread): Connection 'test.dbt_poc.unique_customers_customers_id' was properly closed.
2021-04-14 12:00:58.649356 (MainThread): 
2021-04-14 12:00:58.649480 (MainThread): Completed with 3 errors and 0 warnings:
2021-04-14 12:00:58.649577 (MainThread): 
2021-04-14 12:00:58.649671 (MainThread): Failure in test not_null_my_first_dbt_model_id (models/example/schema.yml)
2021-04-14 12:00:58.649757 (MainThread):   Got 1 result, expected 0.
2021-04-14 12:00:58.649835 (MainThread): 
2021-04-14 12:00:58.649920 (MainThread):   compiled SQL at target/compiled/dbt_poc/models/example/schema.yml/schema_test/not_null_my_first_dbt_model_id.sql
2021-04-14 12:00:58.650006 (MainThread): 
2021-04-14 12:00:58.650094 (MainThread): Database Error in test unique_customers_customers_id (models/schema.yml)
2021-04-14 12:00:58.650180 (MainThread):   Unrecognized name: customers_id; Did you mean customer_id? at [15:11]
2021-04-14 12:00:58.650269 (MainThread):   compiled SQL at target/compiled/dbt_poc/models/schema.yml/schema_test/unique_customers_customers_id.sql
2021-04-14 12:00:58.650354 (MainThread): 
2021-04-14 12:00:58.650451 (MainThread): Database Error in test not_null_customers_customers_id (models/schema.yml)
2021-04-14 12:00:58.650536 (MainThread):   Unrecognized name: customers_id; Did you mean customer_id? at [10:7]
2021-04-14 12:00:58.650624 (MainThread):   compiled SQL at target/compiled/dbt_poc/models/schema.yml/schema_test/not_null_customers_customers_id.sql
2021-04-14 12:00:58.650728 (MainThread): 
Done. PASS=3 WARN=0 ERROR=3 SKIP=0 TOTAL=6
2021-04-14 12:00:58.650893 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc400b9ea60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc40342c190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc400d13280>]}
2021-04-14 12:00:58.651141 (MainThread): Flushing usage events
2021-04-14 12:01:13.610162 (MainThread): Running with dbt=0.19.1
2021-04-14 12:01:13.745451 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, data=False, debug=False, defer=None, exclude=None, fail_fast=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/home/msonowal/.dbt', project_dir=None, record_timing_info=None, rpc_method='test', schema=False, selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='test', write_json=True)
2021-04-14 12:01:13.745825 (MainThread): Tracking: tracking
2021-04-14 12:01:13.751586 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbe25e90a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbe2785f160>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbe25e9d9d0>]}
2021-04-14 12:01:13.757067 (MainThread): Partial parsing not enabled
2021-04-14 12:01:13.757610 (MainThread): Parsing macros/etc.sql
2021-04-14 12:01:13.759340 (MainThread): Parsing macros/adapters.sql
2021-04-14 12:01:13.771197 (MainThread): Parsing macros/catalog.sql
2021-04-14 12:01:13.774564 (MainThread): Parsing macros/materializations/seed.sql
2021-04-14 12:01:13.776307 (MainThread): Parsing macros/materializations/copy.sql
2021-04-14 12:01:13.779225 (MainThread): Parsing macros/materializations/table.sql
2021-04-14 12:01:13.785659 (MainThread): Parsing macros/materializations/incremental.sql
2021-04-14 12:01:13.793847 (MainThread): Parsing macros/materializations/view.sql
2021-04-14 12:01:13.795653 (MainThread): Parsing macros/materializations/snapshot.sql
2021-04-14 12:01:13.797181 (MainThread): Parsing macros/core.sql
2021-04-14 12:01:13.799682 (MainThread): Parsing macros/adapters/common.sql
2021-04-14 12:01:13.825710 (MainThread): Parsing macros/etc/is_incremental.sql
2021-04-14 12:01:13.826774 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-04-14 12:01:13.828039 (MainThread): Parsing macros/etc/query.sql
2021-04-14 12:01:13.828718 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-04-14 12:01:13.829284 (MainThread): Parsing macros/etc/datetime.sql
2021-04-14 12:01:13.834873 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-04-14 12:01:13.835918 (MainThread): Parsing macros/materializations/helpers.sql
2021-04-14 12:01:13.841426 (MainThread): Parsing macros/materializations/common/merge.sql
2021-04-14 12:01:13.849961 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-04-14 12:01:13.863076 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-04-14 12:01:13.867125 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-04-14 12:01:13.868294 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-04-14 12:01:13.871466 (MainThread): Parsing macros/materializations/view/view.sql
2021-04-14 12:01:13.875483 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-04-14 12:01:13.876554 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-04-14 12:01:13.895689 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-04-14 12:01:13.907361 (MainThread): Parsing macros/materializations/table/table.sql
2021-04-14 12:01:13.911677 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-04-14 12:01:13.913391 (MainThread): Parsing macros/schema_tests/unique.sql
2021-04-14 12:01:13.914467 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-04-14 12:01:13.915423 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-04-14 12:01:13.919668 (MainThread): Partial parsing not enabled
2021-04-14 12:01:13.934153 (MainThread): Acquiring new bigquery connection "model.dbt_poc.stg_customers".
2021-04-14 12:01:13.939700 (MainThread): Acquiring new bigquery connection "model.dbt_poc.stg_orders".
2021-04-14 12:01:13.941290 (MainThread): Acquiring new bigquery connection "model.dbt_poc.customers".
2021-04-14 12:01:13.943586 (MainThread): Acquiring new bigquery connection "model.dbt_poc.my_second_dbt_model".
2021-04-14 12:01:13.945673 (MainThread): Acquiring new bigquery connection "model.dbt_poc.my_first_dbt_model".
2021-04-14 12:01:13.989579 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '6e95ef0d-aa13-425d-a75a-2fb049ae9085', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbe235f4c10>]}
2021-04-14 12:01:13.992025 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '6e95ef0d-aa13-425d-a75a-2fb049ae9085', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbe236d39a0>]}
2021-04-14 12:01:13.992143 (MainThread): Found 5 models, 6 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-04-14 12:01:13.992707 (MainThread): 
2021-04-14 12:01:13.992863 (MainThread): Acquiring new bigquery connection "master".
2021-04-14 12:01:13.993769 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_poc-dbt-310711_dbt_poc_ds".
2021-04-14 12:01:13.993917 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2021-04-14 12:01:14.000345 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-04-14 12:01:15.071371 (MainThread): 17:31:15 | Concurrency: 4 threads (target='dev')
2021-04-14 12:01:15.071547 (MainThread): 17:31:15 | 
2021-04-14 12:01:15.073603 (Thread-1): Began running node test.dbt_poc.not_null_customers_customer_id
2021-04-14 12:01:15.073766 (Thread-2): Began running node test.dbt_poc.not_null_my_first_dbt_model_id
2021-04-14 12:01:15.073917 (Thread-1): 17:31:15 | 1 of 6 START test not_null_customers_customer_id..................... [RUN]
2021-04-14 12:01:15.074213 (Thread-3): Began running node test.dbt_poc.not_null_my_second_dbt_model_id
2021-04-14 12:01:15.074354 (Thread-4): Began running node test.dbt_poc.unique_customers_customer_id
2021-04-14 12:01:15.074516 (Thread-2): 17:31:15 | 2 of 6 START test not_null_my_first_dbt_model_id..................... [RUN]
2021-04-14 12:01:15.074828 (Thread-1): Acquiring new bigquery connection "test.dbt_poc.not_null_customers_customer_id".
2021-04-14 12:01:15.074941 (Thread-3): 17:31:15 | 3 of 6 START test not_null_my_second_dbt_model_id.................... [RUN]
2021-04-14 12:01:15.075121 (Thread-4): 17:31:15 | 4 of 6 START test unique_customers_customer_id....................... [RUN]
2021-04-14 12:01:15.075444 (Thread-2): Acquiring new bigquery connection "test.dbt_poc.not_null_my_first_dbt_model_id".
2021-04-14 12:01:15.075553 (Thread-1): Compiling test.dbt_poc.not_null_customers_customer_id
2021-04-14 12:01:15.075845 (Thread-3): Acquiring new bigquery connection "test.dbt_poc.not_null_my_second_dbt_model_id".
2021-04-14 12:01:15.076252 (Thread-4): Acquiring new bigquery connection "test.dbt_poc.unique_customers_customer_id".
2021-04-14 12:01:15.076370 (Thread-2): Compiling test.dbt_poc.not_null_my_first_dbt_model_id
2021-04-14 12:01:15.084153 (Thread-1): Writing injected SQL for node "test.dbt_poc.not_null_customers_customer_id"
2021-04-14 12:01:15.084261 (Thread-3): Compiling test.dbt_poc.not_null_my_second_dbt_model_id
2021-04-14 12:01:15.084409 (Thread-4): Compiling test.dbt_poc.unique_customers_customer_id
2021-04-14 12:01:15.087543 (Thread-2): Writing injected SQL for node "test.dbt_poc.not_null_my_first_dbt_model_id"
2021-04-14 12:01:15.090636 (Thread-3): Writing injected SQL for node "test.dbt_poc.not_null_my_second_dbt_model_id"
2021-04-14 12:01:15.095843 (Thread-1): finished collecting timing info
2021-04-14 12:01:15.097264 (Thread-4): Writing injected SQL for node "test.dbt_poc.unique_customers_customer_id"
2021-04-14 12:01:15.097615 (Thread-1): Opening a new connection, currently in state closed
2021-04-14 12:01:15.097851 (Thread-3): finished collecting timing info
2021-04-14 12:01:15.097963 (Thread-2): finished collecting timing info
2021-04-14 12:01:15.098204 (Thread-3): Opening a new connection, currently in state init
2021-04-14 12:01:15.098331 (Thread-4): finished collecting timing info
2021-04-14 12:01:15.098560 (Thread-2): Opening a new connection, currently in state init
2021-04-14 12:01:15.098789 (Thread-4): Opening a new connection, currently in state init
2021-04-14 12:01:15.104047 (Thread-4): On test.dbt_poc.unique_customers_customer_id: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "db_bigq_profile", "target_name": "dev", "node_id": "test.dbt_poc.unique_customers_customer_id"} */

    
    



select count(*) as validation_errors
from (

    select
        customer_id

    from `poc-dbt-310711`.`dbt_poc_ds`.`customers`
    where customer_id is not null
    group by customer_id
    having count(*) > 1

) validation_errors



2021-04-14 12:01:15.105302 (Thread-1): On test.dbt_poc.not_null_customers_customer_id: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "db_bigq_profile", "target_name": "dev", "node_id": "test.dbt_poc.not_null_customers_customer_id"} */

    
    



select count(*) as validation_errors
from `poc-dbt-310711`.`dbt_poc_ds`.`customers`
where customer_id is null



2021-04-14 12:01:15.105672 (Thread-2): On test.dbt_poc.not_null_my_first_dbt_model_id: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "db_bigq_profile", "target_name": "dev", "node_id": "test.dbt_poc.not_null_my_first_dbt_model_id"} */

    
    



select count(*) as validation_errors
from `poc-dbt-310711`.`dbt_poc_ds`.`my_first_dbt_model`
where id is null



2021-04-14 12:01:15.107130 (Thread-3): On test.dbt_poc.not_null_my_second_dbt_model_id: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "db_bigq_profile", "target_name": "dev", "node_id": "test.dbt_poc.not_null_my_second_dbt_model_id"} */

    
    



select count(*) as validation_errors
from `poc-dbt-310711`.`dbt_poc_ds`.`my_second_dbt_model`
where id is null



2021-04-14 12:01:15.109010 (Thread-2): unclosed <socket.socket fd=5, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.7', 49284), raddr=('142.250.182.74', 443)>
2021-04-14 12:01:15.109092 (Thread-2): unclosed <socket.socket fd=6, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.7', 54862), raddr=('142.250.67.42', 443)>
2021-04-14 12:01:16.917280 (Thread-3): finished collecting timing info
2021-04-14 12:01:16.917714 (Thread-3): 17:31:16 | 3 of 6 PASS not_null_my_second_dbt_model_id.......................... [PASS in 1.84s]
2021-04-14 12:01:16.917861 (Thread-3): Finished running node test.dbt_poc.not_null_my_second_dbt_model_id
2021-04-14 12:01:16.917998 (Thread-3): Began running node test.dbt_poc.unique_my_first_dbt_model_id
2021-04-14 12:01:16.918257 (Thread-3): 17:31:16 | 5 of 6 START test unique_my_first_dbt_model_id....................... [RUN]
2021-04-14 12:01:16.918492 (Thread-3): Acquiring new bigquery connection "test.dbt_poc.unique_my_first_dbt_model_id".
2021-04-14 12:01:16.918583 (Thread-3): Compiling test.dbt_poc.unique_my_first_dbt_model_id
2021-04-14 12:01:16.922655 (Thread-3): Writing injected SQL for node "test.dbt_poc.unique_my_first_dbt_model_id"
2021-04-14 12:01:16.922932 (Thread-3): finished collecting timing info
2021-04-14 12:01:16.923103 (Thread-3): Opening a new connection, currently in state closed
2021-04-14 12:01:16.928163 (Thread-3): On test.dbt_poc.unique_my_first_dbt_model_id: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "db_bigq_profile", "target_name": "dev", "node_id": "test.dbt_poc.unique_my_first_dbt_model_id"} */

    
    



select count(*) as validation_errors
from (

    select
        id

    from `poc-dbt-310711`.`dbt_poc_ds`.`my_first_dbt_model`
    where id is not null
    group by id
    having count(*) > 1

) validation_errors



2021-04-14 12:01:17.321391 (Thread-2): finished collecting timing info
2021-04-14 12:01:17.321823 (Thread-2): 17:31:17 | 2 of 6 FAIL 1 not_null_my_first_dbt_model_id......................... [FAIL 1 in 2.25s]
2021-04-14 12:01:17.321955 (Thread-2): Finished running node test.dbt_poc.not_null_my_first_dbt_model_id
2021-04-14 12:01:17.322086 (Thread-2): Began running node test.dbt_poc.unique_my_second_dbt_model_id
2021-04-14 12:01:17.322288 (Thread-2): 17:31:17 | 6 of 6 START test unique_my_second_dbt_model_id...................... [RUN]
2021-04-14 12:01:17.322529 (Thread-2): Acquiring new bigquery connection "test.dbt_poc.unique_my_second_dbt_model_id".
2021-04-14 12:01:17.322625 (Thread-2): Compiling test.dbt_poc.unique_my_second_dbt_model_id
2021-04-14 12:01:17.326145 (Thread-2): Writing injected SQL for node "test.dbt_poc.unique_my_second_dbt_model_id"
2021-04-14 12:01:17.326416 (Thread-2): finished collecting timing info
2021-04-14 12:01:17.326564 (Thread-2): Opening a new connection, currently in state closed
2021-04-14 12:01:17.332340 (Thread-2): On test.dbt_poc.unique_my_second_dbt_model_id: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "db_bigq_profile", "target_name": "dev", "node_id": "test.dbt_poc.unique_my_second_dbt_model_id"} */

    
    



select count(*) as validation_errors
from (

    select
        id

    from `poc-dbt-310711`.`dbt_poc_ds`.`my_second_dbt_model`
    where id is not null
    group by id
    having count(*) > 1

) validation_errors



2021-04-14 12:01:17.621146 (Thread-1): finished collecting timing info
2021-04-14 12:01:17.621567 (Thread-1): 17:31:17 | 1 of 6 PASS not_null_customers_customer_id........................... [PASS in 2.55s]
2021-04-14 12:01:17.621700 (Thread-1): Finished running node test.dbt_poc.not_null_customers_customer_id
2021-04-14 12:01:17.786869 (Thread-4): finished collecting timing info
2021-04-14 12:01:17.787243 (Thread-4): 17:31:17 | 4 of 6 PASS unique_customers_customer_id............................. [PASS in 2.71s]
2021-04-14 12:01:17.787368 (Thread-4): Finished running node test.dbt_poc.unique_customers_customer_id
2021-04-14 12:01:19.139313 (Thread-3): finished collecting timing info
2021-04-14 12:01:19.139806 (Thread-3): 17:31:19 | 5 of 6 PASS unique_my_first_dbt_model_id............................. [PASS in 2.22s]
2021-04-14 12:01:19.139997 (Thread-3): Finished running node test.dbt_poc.unique_my_first_dbt_model_id
2021-04-14 12:01:19.600008 (Thread-2): finished collecting timing info
2021-04-14 12:01:19.600372 (Thread-2): 17:31:19 | 6 of 6 PASS unique_my_second_dbt_model_id............................ [PASS in 2.28s]
2021-04-14 12:01:19.600497 (Thread-2): Finished running node test.dbt_poc.unique_my_second_dbt_model_id
2021-04-14 12:01:19.601466 (MainThread): Acquiring new bigquery connection "master".
2021-04-14 12:01:19.601719 (MainThread): 17:31:19 | 
2021-04-14 12:01:19.601822 (MainThread): 17:31:19 | Finished running 6 tests in 5.61s.
2021-04-14 12:01:19.601904 (MainThread): Connection 'master' was properly closed.
2021-04-14 12:01:19.601963 (MainThread): Connection 'test.dbt_poc.not_null_customers_customer_id' was properly closed.
2021-04-14 12:01:19.602019 (MainThread): Connection 'test.dbt_poc.unique_my_second_dbt_model_id' was properly closed.
2021-04-14 12:01:19.602073 (MainThread): Connection 'test.dbt_poc.unique_my_first_dbt_model_id' was properly closed.
2021-04-14 12:01:19.602132 (MainThread): Connection 'test.dbt_poc.unique_customers_customer_id' was properly closed.
2021-04-14 12:01:19.603462 (MainThread): unclosed <socket.socket fd=17, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.7', 49308), raddr=('142.250.182.74', 443)>
2021-04-14 12:01:19.603602 (MainThread): unclosed <socket.socket fd=18, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.7', 54886), raddr=('142.250.67.42', 443)>
2021-04-14 12:01:19.606706 (MainThread): 
2021-04-14 12:01:19.606822 (MainThread): Completed with 1 error and 0 warnings:
2021-04-14 12:01:19.606913 (MainThread): 
2021-04-14 12:01:19.607015 (MainThread): Failure in test not_null_my_first_dbt_model_id (models/example/schema.yml)
2021-04-14 12:01:19.607103 (MainThread):   Got 1 result, expected 0.
2021-04-14 12:01:19.607182 (MainThread): 
2021-04-14 12:01:19.607263 (MainThread):   compiled SQL at target/compiled/dbt_poc/models/example/schema.yml/schema_test/not_null_my_first_dbt_model_id.sql
2021-04-14 12:01:19.607359 (MainThread): 
Done. PASS=5 WARN=0 ERROR=1 SKIP=0 TOTAL=6
2021-04-14 12:01:19.607501 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbe23758910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbe23758430>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbe237589d0>]}
2021-04-14 12:01:19.607670 (MainThread): Flushing usage events
2021-04-14 12:01:35.973955 (MainThread): Running with dbt=0.19.1
2021-04-14 12:01:36.107048 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=True, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/home/msonowal/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-04-14 12:01:36.107418 (MainThread): Tracking: tracking
2021-04-14 12:01:36.113055 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcc69a65e80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcc681b6fa0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcc69a7e820>]}
2021-04-14 12:01:36.118490 (MainThread): Partial parsing not enabled
2021-04-14 12:01:36.119032 (MainThread): Parsing macros/etc.sql
2021-04-14 12:01:36.120741 (MainThread): Parsing macros/adapters.sql
2021-04-14 12:01:36.132368 (MainThread): Parsing macros/catalog.sql
2021-04-14 12:01:36.135780 (MainThread): Parsing macros/materializations/seed.sql
2021-04-14 12:01:36.137515 (MainThread): Parsing macros/materializations/copy.sql
2021-04-14 12:01:36.140414 (MainThread): Parsing macros/materializations/table.sql
2021-04-14 12:01:36.146910 (MainThread): Parsing macros/materializations/incremental.sql
2021-04-14 12:01:36.155039 (MainThread): Parsing macros/materializations/view.sql
2021-04-14 12:01:36.156802 (MainThread): Parsing macros/materializations/snapshot.sql
2021-04-14 12:01:36.158321 (MainThread): Parsing macros/core.sql
2021-04-14 12:01:36.160769 (MainThread): Parsing macros/adapters/common.sql
2021-04-14 12:01:36.186477 (MainThread): Parsing macros/etc/is_incremental.sql
2021-04-14 12:01:36.187494 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-04-14 12:01:36.188719 (MainThread): Parsing macros/etc/query.sql
2021-04-14 12:01:36.189360 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-04-14 12:01:36.189923 (MainThread): Parsing macros/etc/datetime.sql
2021-04-14 12:01:36.195616 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-04-14 12:01:36.196648 (MainThread): Parsing macros/materializations/helpers.sql
2021-04-14 12:01:36.202105 (MainThread): Parsing macros/materializations/common/merge.sql
2021-04-14 12:01:36.210735 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-04-14 12:01:36.223863 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-04-14 12:01:36.227939 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-04-14 12:01:36.229087 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-04-14 12:01:36.232249 (MainThread): Parsing macros/materializations/view/view.sql
2021-04-14 12:01:36.236259 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-04-14 12:01:36.237308 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-04-14 12:01:36.256752 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-04-14 12:01:36.268168 (MainThread): Parsing macros/materializations/table/table.sql
2021-04-14 12:01:36.272410 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-04-14 12:01:36.274087 (MainThread): Parsing macros/schema_tests/unique.sql
2021-04-14 12:01:36.275142 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-04-14 12:01:36.276067 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-04-14 12:01:36.280251 (MainThread): Partial parsing not enabled
2021-04-14 12:01:36.294649 (MainThread): Acquiring new bigquery connection "model.dbt_poc.stg_customers".
2021-04-14 12:01:36.300210 (MainThread): Acquiring new bigquery connection "model.dbt_poc.stg_orders".
2021-04-14 12:01:36.301785 (MainThread): Acquiring new bigquery connection "model.dbt_poc.customers".
2021-04-14 12:01:36.304022 (MainThread): Acquiring new bigquery connection "model.dbt_poc.my_second_dbt_model".
2021-04-14 12:01:36.306052 (MainThread): Acquiring new bigquery connection "model.dbt_poc.my_first_dbt_model".
2021-04-14 12:01:36.350174 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '59d5b4fc-4892-4bc2-a410-762aed14b2e7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcc671f1a60>]}
2021-04-14 12:01:36.352637 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '59d5b4fc-4892-4bc2-a410-762aed14b2e7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcc69a49cd0>]}
2021-04-14 12:01:36.352749 (MainThread): Found 5 models, 6 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-04-14 12:01:36.353283 (MainThread): 
2021-04-14 12:01:36.353429 (MainThread): Acquiring new bigquery connection "master".
2021-04-14 12:01:36.354234 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_poc-dbt-310711".
2021-04-14 12:01:36.354498 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-04-14 12:01:37.303794 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_poc-dbt-310711_dbt_poc_ds".
2021-04-14 12:01:37.303999 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-04-14 12:01:37.309966 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-04-14 12:01:38.229353 (MainThread): 17:31:38 | Concurrency: 4 threads (target='dev')
2021-04-14 12:01:38.229535 (MainThread): 17:31:38 | 
2021-04-14 12:01:38.231815 (Thread-1): Began running node model.dbt_poc.my_first_dbt_model
2021-04-14 12:01:38.232030 (Thread-2): Began running node model.dbt_poc.stg_customers
2021-04-14 12:01:38.232312 (Thread-1): 17:31:38 | 1 of 5 START table model dbt_poc_ds.my_first_dbt_model............... [RUN]
2021-04-14 12:01:38.232441 (Thread-3): Began running node model.dbt_poc.stg_orders
2021-04-14 12:01:38.232707 (Thread-2): 17:31:38 | 2 of 5 START table model dbt_poc_ds.stg_customers.................... [RUN]
2021-04-14 12:01:38.233059 (Thread-1): Acquiring new bigquery connection "model.dbt_poc.my_first_dbt_model".
2021-04-14 12:01:38.233245 (Thread-3): 17:31:38 | 3 of 5 START table model dbt_poc_ds.stg_orders....................... [RUN]
2021-04-14 12:01:38.233587 (Thread-2): Acquiring new bigquery connection "model.dbt_poc.stg_customers".
2021-04-14 12:01:38.233718 (Thread-1): Compiling model.dbt_poc.my_first_dbt_model
2021-04-14 12:01:38.234023 (Thread-3): Acquiring new bigquery connection "model.dbt_poc.stg_orders".
2021-04-14 12:01:38.234120 (Thread-2): Compiling model.dbt_poc.stg_customers
2021-04-14 12:01:38.236644 (Thread-1): Writing injected SQL for node "model.dbt_poc.my_first_dbt_model"
2021-04-14 12:01:38.236767 (Thread-3): Compiling model.dbt_poc.stg_orders
2021-04-14 12:01:38.237908 (Thread-2): Writing injected SQL for node "model.dbt_poc.stg_customers"
2021-04-14 12:01:38.239138 (Thread-3): Writing injected SQL for node "model.dbt_poc.stg_orders"
2021-04-14 12:01:38.239525 (Thread-1): finished collecting timing info
2021-04-14 12:01:38.244811 (Thread-2): finished collecting timing info
2021-04-14 12:01:38.256111 (Thread-1): Opening a new connection, currently in state closed
2021-04-14 12:01:38.256221 (Thread-3): finished collecting timing info
2021-04-14 12:01:38.256350 (Thread-2): unclosed <socket.socket fd=5, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.7', 49318), raddr=('142.250.182.74', 443)>
2021-04-14 12:01:38.257773 (Thread-3): Opening a new connection, currently in state init
2021-04-14 12:01:38.257963 (Thread-2): unclosed <socket.socket fd=6, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.7', 54896), raddr=('142.250.67.42', 443)>
2021-04-14 12:01:38.258087 (Thread-2): unclosed <socket.socket fd=8, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.7', 54900), raddr=('142.250.67.42', 443)>
2021-04-14 12:01:38.258171 (Thread-2): unclosed <socket.socket fd=7, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.7', 49322), raddr=('142.250.182.74', 443)>
2021-04-14 12:01:38.268885 (Thread-2): Opening a new connection, currently in state init
2021-04-14 12:01:38.269086 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-04-14 12:01:38.269714 (Thread-3): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-04-14 12:01:38.275920 (Thread-2): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-04-14 12:01:39.220116 (Thread-2): Writing runtime SQL for node "model.dbt_poc.stg_customers"
2021-04-14 12:01:39.220896 (Thread-1): Writing runtime SQL for node "model.dbt_poc.my_first_dbt_model"
2021-04-14 12:01:39.221149 (Thread-2): On model.dbt_poc.stg_customers: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "db_bigq_profile", "target_name": "dev", "node_id": "model.dbt_poc.stg_customers"} */


  create or replace table `poc-dbt-310711`.`dbt_poc_ds`.`stg_customers`
  
  
  OPTIONS()
  as (
    select
    id as customer_id,
    first_name,
    last_name

from `dbt-tutorial`.jaffle_shop.customers
  );
    
2021-04-14 12:01:39.221310 (Thread-1): On model.dbt_poc.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "db_bigq_profile", "target_name": "dev", "node_id": "model.dbt_poc.my_first_dbt_model"} */


  create or replace table `poc-dbt-310711`.`dbt_poc_ds`.`my_first_dbt_model`
  
  
  OPTIONS()
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
    
2021-04-14 12:01:39.224830 (Thread-3): Writing runtime SQL for node "model.dbt_poc.stg_orders"
2021-04-14 12:01:39.225092 (Thread-3): On model.dbt_poc.stg_orders: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "db_bigq_profile", "target_name": "dev", "node_id": "model.dbt_poc.stg_orders"} */


  create or replace table `poc-dbt-310711`.`dbt_poc_ds`.`stg_orders`
  
  
  OPTIONS()
  as (
    select
    id as order_id,
    user_id as customer_id,
    order_date,
    status

from `dbt-tutorial`.jaffle_shop.orders
  );
    
2021-04-14 12:01:41.840823 (Thread-1): finished collecting timing info
2021-04-14 12:01:41.841215 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '59d5b4fc-4892-4bc2-a410-762aed14b2e7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcc67244520>]}
2021-04-14 12:01:41.841518 (Thread-1): 17:31:41 | 1 of 5 OK created table model dbt_poc_ds.my_first_dbt_model.......... [CREATE TABLE (2.0 rows, 0.0 Bytes processed) in 3.61s]
2021-04-14 12:01:41.841648 (Thread-1): Finished running node model.dbt_poc.my_first_dbt_model
2021-04-14 12:01:41.842140 (Thread-4): Began running node model.dbt_poc.my_second_dbt_model
2021-04-14 12:01:41.842395 (Thread-4): 17:31:41 | 4 of 5 START table model dbt_poc_ds.my_second_dbt_model.............. [RUN]
2021-04-14 12:01:41.842670 (Thread-4): Acquiring new bigquery connection "model.dbt_poc.my_second_dbt_model".
2021-04-14 12:01:41.842770 (Thread-4): Compiling model.dbt_poc.my_second_dbt_model
2021-04-14 12:01:41.844880 (Thread-4): Writing injected SQL for node "model.dbt_poc.my_second_dbt_model"
2021-04-14 12:01:41.845153 (Thread-4): finished collecting timing info
2021-04-14 12:01:41.846672 (Thread-4): Opening a new connection, currently in state init
2021-04-14 12:01:41.852106 (Thread-4): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-04-14 12:01:41.883333 (Thread-3): finished collecting timing info
2021-04-14 12:01:41.883673 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '59d5b4fc-4892-4bc2-a410-762aed14b2e7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcc672b5df0>]}
2021-04-14 12:01:41.884024 (Thread-3): 17:31:41 | 3 of 5 OK created table model dbt_poc_ds.stg_orders.................. [CREATE TABLE (99.0 rows, 3.3 KB processed) in 3.65s]
2021-04-14 12:01:41.884179 (Thread-3): Finished running node model.dbt_poc.stg_orders
2021-04-14 12:01:42.025833 (Thread-2): finished collecting timing info
2021-04-14 12:01:42.026192 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '59d5b4fc-4892-4bc2-a410-762aed14b2e7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcc6725a340>]}
2021-04-14 12:01:42.026491 (Thread-2): 17:31:42 | 2 of 5 OK created table model dbt_poc_ds.stg_customers............... [CREATE TABLE (100.0 rows, 1.9 KB processed) in 3.79s]
2021-04-14 12:01:42.026611 (Thread-2): Finished running node model.dbt_poc.stg_customers
2021-04-14 12:01:42.027016 (Thread-1): Began running node model.dbt_poc.customers
2021-04-14 12:01:42.027222 (Thread-1): 17:31:42 | 5 of 5 START table model dbt_poc_ds.customers........................ [RUN]
2021-04-14 12:01:42.027453 (Thread-1): Acquiring new bigquery connection "model.dbt_poc.customers".
2021-04-14 12:01:42.027544 (Thread-1): Compiling model.dbt_poc.customers
2021-04-14 12:01:42.030383 (Thread-1): Writing injected SQL for node "model.dbt_poc.customers"
2021-04-14 12:01:42.030715 (Thread-1): finished collecting timing info
2021-04-14 12:01:42.032084 (Thread-1): Opening a new connection, currently in state closed
2021-04-14 12:01:42.036746 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-04-14 12:01:42.421285 (Thread-4): Writing runtime SQL for node "model.dbt_poc.my_second_dbt_model"
2021-04-14 12:01:42.421634 (Thread-4): On model.dbt_poc.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "db_bigq_profile", "target_name": "dev", "node_id": "model.dbt_poc.my_second_dbt_model"} */


  create or replace table `poc-dbt-310711`.`dbt_poc_ds`.`my_second_dbt_model`
  
  
  OPTIONS()
  as (
    -- Use the `ref` function to select from other models

select *
from `poc-dbt-310711`.`dbt_poc_ds`.`my_first_dbt_model`
where id = 1
  );
    
2021-04-14 12:01:42.939525 (Thread-1): Writing runtime SQL for node "model.dbt_poc.customers"
2021-04-14 12:01:42.939839 (Thread-1): On model.dbt_poc.customers: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "db_bigq_profile", "target_name": "dev", "node_id": "model.dbt_poc.customers"} */


  create or replace table `poc-dbt-310711`.`dbt_poc_ds`.`customers`
  
  
  OPTIONS()
  as (
    with customers as (

    select * from `poc-dbt-310711`.`dbt_poc_ds`.`stg_customers`

),

orders as (

    select * from `poc-dbt-310711`.`dbt_poc_ds`.`stg_orders`

),

customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final
  );
    
2021-04-14 12:01:45.032568 (Thread-4): finished collecting timing info
2021-04-14 12:01:45.032966 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '59d5b4fc-4892-4bc2-a410-762aed14b2e7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcc67244520>]}
2021-04-14 12:01:45.033261 (Thread-4): 17:31:45 | 4 of 5 OK created table model dbt_poc_ds.my_second_dbt_model......... [CREATE TABLE (1.0 rows, 8.0 Bytes processed) in 3.19s]
2021-04-14 12:01:45.033390 (Thread-4): Finished running node model.dbt_poc.my_second_dbt_model
2021-04-14 12:01:45.721493 (Thread-1): finished collecting timing info
2021-04-14 12:01:45.721872 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '59d5b4fc-4892-4bc2-a410-762aed14b2e7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcc672b54c0>]}
2021-04-14 12:01:45.722156 (Thread-1): 17:31:45 | 5 of 5 OK created table model dbt_poc_ds.customers................... [CREATE TABLE (100.0 rows, 4.3 KB processed) in 3.69s]
2021-04-14 12:01:45.722278 (Thread-1): Finished running node model.dbt_poc.customers
2021-04-14 12:01:45.723469 (MainThread): Acquiring new bigquery connection "master".
2021-04-14 12:01:45.723816 (MainThread): 17:31:45 | 
2021-04-14 12:01:45.723928 (MainThread): 17:31:45 | Finished running 5 table models in 9.37s.
2021-04-14 12:01:45.724017 (MainThread): Connection 'master' was properly closed.
2021-04-14 12:01:45.724078 (MainThread): Connection 'model.dbt_poc.customers' was properly closed.
2021-04-14 12:01:45.724137 (MainThread): Connection 'model.dbt_poc.stg_customers' was properly closed.
2021-04-14 12:01:45.724192 (MainThread): Connection 'model.dbt_poc.stg_orders' was properly closed.
2021-04-14 12:01:45.724247 (MainThread): Connection 'model.dbt_poc.my_second_dbt_model' was properly closed.
2021-04-14 12:01:45.728406 (MainThread): 
2021-04-14 12:01:45.728507 (MainThread): Completed successfully
2021-04-14 12:01:45.728589 (MainThread): 
Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
2021-04-14 12:01:45.728713 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcc672adf70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcc672e34f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcc6724d700>]}
2021-04-14 12:01:45.728854 (MainThread): Flushing usage events
2021-04-14 12:02:14.687015 (MainThread): Running with dbt=0.19.1
2021-04-14 12:02:14.822380 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, data=False, debug=False, defer=None, exclude=None, fail_fast=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/home/msonowal/.dbt', project_dir=None, record_timing_info=None, rpc_method='test', schema=False, selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='test', write_json=True)
2021-04-14 12:02:14.822780 (MainThread): Tracking: tracking
2021-04-14 12:02:14.828557 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb2312df1c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb22f9e9af0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb2312ee940>]}
2021-04-14 12:02:14.834622 (MainThread): Partial parsing not enabled
2021-04-14 12:02:14.835244 (MainThread): Parsing macros/etc.sql
2021-04-14 12:02:14.837036 (MainThread): Parsing macros/adapters.sql
2021-04-14 12:02:14.848907 (MainThread): Parsing macros/catalog.sql
2021-04-14 12:02:14.852278 (MainThread): Parsing macros/materializations/seed.sql
2021-04-14 12:02:14.853968 (MainThread): Parsing macros/materializations/copy.sql
2021-04-14 12:02:14.856821 (MainThread): Parsing macros/materializations/table.sql
2021-04-14 12:02:14.863493 (MainThread): Parsing macros/materializations/incremental.sql
2021-04-14 12:02:14.871526 (MainThread): Parsing macros/materializations/view.sql
2021-04-14 12:02:14.873309 (MainThread): Parsing macros/materializations/snapshot.sql
2021-04-14 12:02:14.874853 (MainThread): Parsing macros/core.sql
2021-04-14 12:02:14.877256 (MainThread): Parsing macros/adapters/common.sql
2021-04-14 12:02:14.903013 (MainThread): Parsing macros/etc/is_incremental.sql
2021-04-14 12:02:14.904049 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-04-14 12:02:14.905278 (MainThread): Parsing macros/etc/query.sql
2021-04-14 12:02:14.905911 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-04-14 12:02:14.906477 (MainThread): Parsing macros/etc/datetime.sql
2021-04-14 12:02:14.911955 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-04-14 12:02:14.912970 (MainThread): Parsing macros/materializations/helpers.sql
2021-04-14 12:02:14.918317 (MainThread): Parsing macros/materializations/common/merge.sql
2021-04-14 12:02:14.926741 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-04-14 12:02:14.939864 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-04-14 12:02:14.943883 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-04-14 12:02:14.945037 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-04-14 12:02:14.948182 (MainThread): Parsing macros/materializations/view/view.sql
2021-04-14 12:02:14.952101 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-04-14 12:02:14.953149 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-04-14 12:02:14.971844 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-04-14 12:02:14.983243 (MainThread): Parsing macros/materializations/table/table.sql
2021-04-14 12:02:14.987461 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-04-14 12:02:14.989118 (MainThread): Parsing macros/schema_tests/unique.sql
2021-04-14 12:02:14.990155 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-04-14 12:02:14.991080 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-04-14 12:02:14.995235 (MainThread): Partial parsing not enabled
2021-04-14 12:02:15.009719 (MainThread): Acquiring new bigquery connection "model.dbt_poc.stg_customers".
2021-04-14 12:02:15.015231 (MainThread): Acquiring new bigquery connection "model.dbt_poc.stg_orders".
2021-04-14 12:02:15.016829 (MainThread): Acquiring new bigquery connection "model.dbt_poc.customers".
2021-04-14 12:02:15.019142 (MainThread): Acquiring new bigquery connection "model.dbt_poc.my_second_dbt_model".
2021-04-14 12:02:15.021183 (MainThread): Acquiring new bigquery connection "model.dbt_poc.my_first_dbt_model".
2021-04-14 12:02:15.076265 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ce808117-7c51-478f-8349-833045febd39', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb22e96ffa0>]}
2021-04-14 12:02:15.079201 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ce808117-7c51-478f-8349-833045febd39', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb22eb039a0>]}
2021-04-14 12:02:15.079317 (MainThread): Found 5 models, 13 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-04-14 12:02:15.080033 (MainThread): 
2021-04-14 12:02:15.080193 (MainThread): Acquiring new bigquery connection "master".
2021-04-14 12:02:15.081480 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_poc-dbt-310711_dbt_poc_ds".
2021-04-14 12:02:15.081704 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2021-04-14 12:02:15.088148 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-04-14 12:02:15.988191 (MainThread): 17:32:15 | Concurrency: 4 threads (target='dev')
2021-04-14 12:02:15.988426 (MainThread): 17:32:15 | 
2021-04-14 12:02:15.991194 (Thread-1): Began running node test.dbt_poc.accepted_values_stg_orders_status__placed__shipped__completed__return_pending__returned
2021-04-14 12:02:15.991377 (Thread-2): Began running node test.dbt_poc.not_null_customers_customer_id
2021-04-14 12:02:15.991538 (Thread-1): 17:32:15 | 1 of 13 START test accepted_values_stg_orders_status__placed__shipped__completed__return_pending__returned [RUN]
2021-04-14 12:02:15.991661 (Thread-3): Began running node test.dbt_poc.not_null_my_first_dbt_model_id
2021-04-14 12:02:15.991856 (Thread-4): Began running node test.dbt_poc.not_null_my_second_dbt_model_id
2021-04-14 12:02:15.992038 (Thread-2): 17:32:15 | 2 of 13 START test not_null_customers_customer_id.................... [RUN]
2021-04-14 12:02:15.992407 (Thread-1): Acquiring new bigquery connection "test.dbt_poc.accepted_values_stg_orders_status__placed__shipped__completed__return_pending__returned".
2021-04-14 12:02:15.992547 (Thread-3): 17:32:15 | 3 of 13 START test not_null_my_first_dbt_model_id.................... [RUN]
2021-04-14 12:02:15.992745 (Thread-4): 17:32:15 | 4 of 13 START test not_null_my_second_dbt_model_id................... [RUN]
2021-04-14 12:02:15.993017 (Thread-2): Acquiring new bigquery connection "test.dbt_poc.not_null_customers_customer_id".
2021-04-14 12:02:15.993165 (Thread-1): Compiling test.dbt_poc.accepted_values_stg_orders_status__placed__shipped__completed__return_pending__returned
2021-04-14 12:02:15.993501 (Thread-3): Acquiring new bigquery connection "test.dbt_poc.not_null_my_first_dbt_model_id".
2021-04-14 12:02:15.993678 (Thread-2): Compiling test.dbt_poc.not_null_customers_customer_id
2021-04-14 12:02:15.993951 (Thread-4): Acquiring new bigquery connection "test.dbt_poc.not_null_my_second_dbt_model_id".
2021-04-14 12:02:16.003409 (Thread-3): Compiling test.dbt_poc.not_null_my_first_dbt_model_id
2021-04-14 12:02:16.003596 (Thread-1): unclosed <socket.socket fd=5, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.7', 49440), raddr=('142.250.182.74', 443)>
2021-04-14 12:02:16.009113 (Thread-2): Writing injected SQL for node "test.dbt_poc.not_null_customers_customer_id"
2021-04-14 12:02:16.009280 (Thread-4): Compiling test.dbt_poc.not_null_my_second_dbt_model_id
2021-04-14 12:02:16.011889 (Thread-3): Writing injected SQL for node "test.dbt_poc.not_null_my_first_dbt_model_id"
2021-04-14 12:02:16.012152 (Thread-1): unclosed <socket.socket fd=6, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.7', 55018), raddr=('142.250.67.42', 443)>
2021-04-14 12:02:16.016274 (Thread-4): Writing injected SQL for node "test.dbt_poc.not_null_my_second_dbt_model_id"
2021-04-14 12:02:16.016582 (Thread-2): finished collecting timing info
2021-04-14 12:02:16.016819 (Thread-3): finished collecting timing info
2021-04-14 12:02:16.018460 (Thread-1): Writing injected SQL for node "test.dbt_poc.accepted_values_stg_orders_status__placed__shipped__completed__return_pending__returned"
2021-04-14 12:02:16.018686 (Thread-2): Opening a new connection, currently in state init
2021-04-14 12:02:16.018843 (Thread-3): Opening a new connection, currently in state init
2021-04-14 12:02:16.019014 (Thread-4): finished collecting timing info
2021-04-14 12:02:16.019428 (Thread-1): finished collecting timing info
2021-04-14 12:02:16.019755 (Thread-4): Opening a new connection, currently in state init
2021-04-14 12:02:16.019919 (Thread-1): Opening a new connection, currently in state closed
2021-04-14 12:02:16.024768 (Thread-4): On test.dbt_poc.not_null_my_second_dbt_model_id: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "db_bigq_profile", "target_name": "dev", "node_id": "test.dbt_poc.not_null_my_second_dbt_model_id"} */

    
    



select count(*) as validation_errors
from `poc-dbt-310711`.`dbt_poc_ds`.`my_second_dbt_model`
where id is null



2021-04-14 12:02:16.024980 (Thread-1): On test.dbt_poc.accepted_values_stg_orders_status__placed__shipped__completed__return_pending__returned: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "db_bigq_profile", "target_name": "dev", "node_id": "test.dbt_poc.accepted_values_stg_orders_status__placed__shipped__completed__return_pending__returned"} */

    
    




with all_values as (

    select distinct
        status as value_field

    from `poc-dbt-310711`.`dbt_poc_ds`.`stg_orders`

),

validation_errors as (

    select
        value_field

    from all_values
    where value_field not in (
        'placed','shipped','completed','return_pending','returned'
    )
)

select count(*) as validation_errors
from validation_errors



2021-04-14 12:02:16.025172 (Thread-2): On test.dbt_poc.not_null_customers_customer_id: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "db_bigq_profile", "target_name": "dev", "node_id": "test.dbt_poc.not_null_customers_customer_id"} */

    
    



select count(*) as validation_errors
from `poc-dbt-310711`.`dbt_poc_ds`.`customers`
where customer_id is null



2021-04-14 12:02:16.026633 (Thread-3): On test.dbt_poc.not_null_my_first_dbt_model_id: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "db_bigq_profile", "target_name": "dev", "node_id": "test.dbt_poc.not_null_my_first_dbt_model_id"} */

    
    



select count(*) as validation_errors
from `poc-dbt-310711`.`dbt_poc_ds`.`my_first_dbt_model`
where id is null



2021-04-14 12:02:18.113504 (Thread-4): finished collecting timing info
2021-04-14 12:02:18.113870 (Thread-4): 17:32:18 | 4 of 13 PASS not_null_my_second_dbt_model_id......................... [PASS in 2.12s]
2021-04-14 12:02:18.114003 (Thread-4): Finished running node test.dbt_poc.not_null_my_second_dbt_model_id
2021-04-14 12:02:18.114132 (Thread-4): Began running node test.dbt_poc.not_null_stg_customers_customer_id
2021-04-14 12:02:18.114318 (Thread-4): 17:32:18 | 5 of 13 START test not_null_stg_customers_customer_id................ [RUN]
2021-04-14 12:02:18.114523 (Thread-4): Acquiring new bigquery connection "test.dbt_poc.not_null_stg_customers_customer_id".
2021-04-14 12:02:18.114603 (Thread-4): Compiling test.dbt_poc.not_null_stg_customers_customer_id
2021-04-14 12:02:18.118219 (Thread-4): Writing injected SQL for node "test.dbt_poc.not_null_stg_customers_customer_id"
2021-04-14 12:02:18.118455 (Thread-4): finished collecting timing info
2021-04-14 12:02:18.118582 (Thread-4): Opening a new connection, currently in state closed
2021-04-14 12:02:18.124211 (Thread-4): On test.dbt_poc.not_null_stg_customers_customer_id: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "db_bigq_profile", "target_name": "dev", "node_id": "test.dbt_poc.not_null_stg_customers_customer_id"} */

    
    



select count(*) as validation_errors
from `poc-dbt-310711`.`dbt_poc_ds`.`stg_customers`
where customer_id is null



2021-04-14 12:02:18.192141 (Thread-3): finished collecting timing info
2021-04-14 12:02:18.192535 (Thread-3): 17:32:18 | 3 of 13 FAIL 1 not_null_my_first_dbt_model_id........................ [FAIL 1 in 2.20s]
2021-04-14 12:02:18.192662 (Thread-3): Finished running node test.dbt_poc.not_null_my_first_dbt_model_id
2021-04-14 12:02:18.192778 (Thread-3): Began running node test.dbt_poc.not_null_stg_orders_customer_id
2021-04-14 12:02:18.192973 (Thread-3): 17:32:18 | 6 of 13 START test not_null_stg_orders_customer_id................... [RUN]
2021-04-14 12:02:18.193192 (Thread-3): Acquiring new bigquery connection "test.dbt_poc.not_null_stg_orders_customer_id".
2021-04-14 12:02:18.193280 (Thread-3): Compiling test.dbt_poc.not_null_stg_orders_customer_id
2021-04-14 12:02:18.196794 (Thread-3): Writing injected SQL for node "test.dbt_poc.not_null_stg_orders_customer_id"
2021-04-14 12:02:18.197021 (Thread-3): finished collecting timing info
2021-04-14 12:02:18.197147 (Thread-3): Opening a new connection, currently in state closed
2021-04-14 12:02:18.203135 (Thread-3): On test.dbt_poc.not_null_stg_orders_customer_id: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "db_bigq_profile", "target_name": "dev", "node_id": "test.dbt_poc.not_null_stg_orders_customer_id"} */

    
    



select count(*) as validation_errors
from `poc-dbt-310711`.`dbt_poc_ds`.`stg_orders`
where customer_id is null



2021-04-14 12:02:18.498395 (Thread-2): finished collecting timing info
2021-04-14 12:02:18.498814 (Thread-2): 17:32:18 | 2 of 13 PASS not_null_customers_customer_id.......................... [PASS in 2.51s]
2021-04-14 12:02:18.498944 (Thread-2): Finished running node test.dbt_poc.not_null_customers_customer_id
2021-04-14 12:02:18.499092 (Thread-2): Began running node test.dbt_poc.not_null_stg_orders_order_id
2021-04-14 12:02:18.499291 (Thread-2): 17:32:18 | 7 of 13 START test not_null_stg_orders_order_id...................... [RUN]
2021-04-14 12:02:18.499526 (Thread-2): Acquiring new bigquery connection "test.dbt_poc.not_null_stg_orders_order_id".
2021-04-14 12:02:18.499618 (Thread-2): Compiling test.dbt_poc.not_null_stg_orders_order_id
2021-04-14 12:02:18.503003 (Thread-2): Writing injected SQL for node "test.dbt_poc.not_null_stg_orders_order_id"
2021-04-14 12:02:18.503311 (Thread-2): finished collecting timing info
2021-04-14 12:02:18.503443 (Thread-2): Opening a new connection, currently in state closed
2021-04-14 12:02:18.508576 (Thread-2): On test.dbt_poc.not_null_stg_orders_order_id: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "db_bigq_profile", "target_name": "dev", "node_id": "test.dbt_poc.not_null_stg_orders_order_id"} */

    
    



select count(*) as validation_errors
from `poc-dbt-310711`.`dbt_poc_ds`.`stg_orders`
where order_id is null



2021-04-14 12:02:18.585876 (Thread-1): finished collecting timing info
2021-04-14 12:02:18.586273 (Thread-1): 17:32:18 | 1 of 13 PASS accepted_values_stg_orders_status__placed__shipped__completed__return_pending__returned [PASS in 2.59s]
2021-04-14 12:02:18.586405 (Thread-1): Finished running node test.dbt_poc.accepted_values_stg_orders_status__placed__shipped__completed__return_pending__returned
2021-04-14 12:02:18.586529 (Thread-1): Began running node test.dbt_poc.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_
2021-04-14 12:02:18.586735 (Thread-1): 17:32:18 | 8 of 13 START test relationships_stg_orders_customer_id__customer_id__ref_stg_customers_ [RUN]
2021-04-14 12:02:18.586980 (Thread-1): Acquiring new bigquery connection "test.dbt_poc.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_".
2021-04-14 12:02:18.587076 (Thread-1): Compiling test.dbt_poc.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_
2021-04-14 12:02:18.595991 (Thread-1): Writing injected SQL for node "test.dbt_poc.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_"
2021-04-14 12:02:18.596145 (Thread-1): finished collecting timing info
2021-04-14 12:02:18.596214 (Thread-1): Opening a new connection, currently in state closed
2021-04-14 12:02:18.599200 (Thread-1): On test.dbt_poc.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "db_bigq_profile", "target_name": "dev", "node_id": "test.dbt_poc.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_"} */

    
    




select count(*) as validation_errors
from (
    select customer_id as id from `poc-dbt-310711`.`dbt_poc_ds`.`stg_orders`
) as child
left join (
    select customer_id as id from `poc-dbt-310711`.`dbt_poc_ds`.`stg_customers`
) as parent on parent.id = child.id
where child.id is not null
  and parent.id is null



2021-04-14 12:02:20.091759 (Thread-3): finished collecting timing info
2021-04-14 12:02:20.092178 (Thread-3): 17:32:20 | 6 of 13 PASS not_null_stg_orders_customer_id......................... [PASS in 1.90s]
2021-04-14 12:02:20.092304 (Thread-3): Finished running node test.dbt_poc.not_null_stg_orders_customer_id
2021-04-14 12:02:20.092421 (Thread-3): Began running node test.dbt_poc.unique_customers_customer_id
2021-04-14 12:02:20.092617 (Thread-3): 17:32:20 | 9 of 13 START test unique_customers_customer_id...................... [RUN]
2021-04-14 12:02:20.092835 (Thread-3): Acquiring new bigquery connection "test.dbt_poc.unique_customers_customer_id".
2021-04-14 12:02:20.092923 (Thread-3): Compiling test.dbt_poc.unique_customers_customer_id
2021-04-14 12:02:20.100345 (Thread-3): Writing injected SQL for node "test.dbt_poc.unique_customers_customer_id"
2021-04-14 12:02:20.100615 (Thread-3): finished collecting timing info
2021-04-14 12:02:20.100742 (Thread-3): Opening a new connection, currently in state closed
2021-04-14 12:02:20.105425 (Thread-3): On test.dbt_poc.unique_customers_customer_id: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "db_bigq_profile", "target_name": "dev", "node_id": "test.dbt_poc.unique_customers_customer_id"} */

    
    



select count(*) as validation_errors
from (

    select
        customer_id

    from `poc-dbt-310711`.`dbt_poc_ds`.`customers`
    where customer_id is not null
    group by customer_id
    having count(*) > 1

) validation_errors



2021-04-14 12:02:20.487659 (Thread-4): finished collecting timing info
2021-04-14 12:02:20.488088 (Thread-4): 17:32:20 | 5 of 13 PASS not_null_stg_customers_customer_id...................... [PASS in 2.37s]
2021-04-14 12:02:20.488215 (Thread-4): Finished running node test.dbt_poc.not_null_stg_customers_customer_id
2021-04-14 12:02:20.488355 (Thread-4): Began running node test.dbt_poc.unique_my_first_dbt_model_id
2021-04-14 12:02:20.488580 (Thread-4): 17:32:20 | 10 of 13 START test unique_my_first_dbt_model_id..................... [RUN]
2021-04-14 12:02:20.488831 (Thread-4): Acquiring new bigquery connection "test.dbt_poc.unique_my_first_dbt_model_id".
2021-04-14 12:02:20.488928 (Thread-4): Compiling test.dbt_poc.unique_my_first_dbt_model_id
2021-04-14 12:02:20.492312 (Thread-4): Writing injected SQL for node "test.dbt_poc.unique_my_first_dbt_model_id"
2021-04-14 12:02:20.492590 (Thread-4): finished collecting timing info
2021-04-14 12:02:20.492734 (Thread-4): Opening a new connection, currently in state closed
2021-04-14 12:02:20.498604 (Thread-4): On test.dbt_poc.unique_my_first_dbt_model_id: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "db_bigq_profile", "target_name": "dev", "node_id": "test.dbt_poc.unique_my_first_dbt_model_id"} */

    
    



select count(*) as validation_errors
from (

    select
        id

    from `poc-dbt-310711`.`dbt_poc_ds`.`my_first_dbt_model`
    where id is not null
    group by id
    having count(*) > 1

) validation_errors



2021-04-14 12:02:20.787432 (Thread-2): finished collecting timing info
2021-04-14 12:02:20.787866 (Thread-2): 17:32:20 | 7 of 13 PASS not_null_stg_orders_order_id............................ [PASS in 2.29s]
2021-04-14 12:02:20.787992 (Thread-2): Finished running node test.dbt_poc.not_null_stg_orders_order_id
2021-04-14 12:02:20.788111 (Thread-2): Began running node test.dbt_poc.unique_my_second_dbt_model_id
2021-04-14 12:02:20.788307 (Thread-2): 17:32:20 | 11 of 13 START test unique_my_second_dbt_model_id.................... [RUN]
2021-04-14 12:02:20.788544 (Thread-2): Acquiring new bigquery connection "test.dbt_poc.unique_my_second_dbt_model_id".
2021-04-14 12:02:20.788633 (Thread-2): Compiling test.dbt_poc.unique_my_second_dbt_model_id
2021-04-14 12:02:20.792565 (Thread-2): unclosed <socket.socket fd=6, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.7', 49444), raddr=('142.250.182.74', 443)>
2021-04-14 12:02:20.792677 (Thread-2): unclosed <socket.socket fd=9, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.7', 49446), raddr=('142.250.182.74', 443)>
2021-04-14 12:02:20.792753 (Thread-2): unclosed <socket.socket fd=5, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.7', 49450), raddr=('142.250.182.74', 443)>
2021-04-14 12:02:20.792824 (Thread-2): unclosed <socket.socket fd=10, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.7', 49448), raddr=('142.250.182.74', 443)>
2021-04-14 12:02:20.792909 (Thread-2): unclosed <socket.socket fd=14, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.7', 55032), raddr=('142.250.67.42', 443)>
2021-04-14 12:02:20.792980 (Thread-2): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.7', 55030), raddr=('142.250.67.42', 443)>
2021-04-14 12:02:20.793049 (Thread-2): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.7', 55028), raddr=('142.250.67.42', 443)>
2021-04-14 12:02:20.793120 (Thread-2): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.7', 55034), raddr=('142.250.67.42', 443)>
2021-04-14 12:02:20.793192 (Thread-2): unclosed <socket.socket fd=15, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.7', 49460), raddr=('142.250.182.74', 443)>
2021-04-14 12:02:20.793275 (Thread-2): unclosed <socket.socket fd=16, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.7', 49462), raddr=('142.250.182.74', 443)>
2021-04-14 12:02:20.793346 (Thread-2): unclosed <socket.socket fd=17, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.7', 55040), raddr=('142.250.67.42', 443)>
2021-04-14 12:02:20.793425 (Thread-2): unclosed <socket.socket fd=18, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.7', 55042), raddr=('142.250.67.42', 443)>
2021-04-14 12:02:20.793505 (Thread-2): unclosed <socket.socket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.7', 49468), raddr=('142.250.182.74', 443)>
2021-04-14 12:02:20.793584 (Thread-2): unclosed <socket.socket fd=21, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.7', 55048), raddr=('142.250.67.42', 443)>
2021-04-14 12:02:20.793906 (Thread-2): Writing injected SQL for node "test.dbt_poc.unique_my_second_dbt_model_id"
2021-04-14 12:02:20.794123 (Thread-2): finished collecting timing info
2021-04-14 12:02:20.794224 (Thread-2): Opening a new connection, currently in state closed
2021-04-14 12:02:20.798896 (Thread-2): On test.dbt_poc.unique_my_second_dbt_model_id: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "db_bigq_profile", "target_name": "dev", "node_id": "test.dbt_poc.unique_my_second_dbt_model_id"} */

    
    



select count(*) as validation_errors
from (

    select
        id

    from `poc-dbt-310711`.`dbt_poc_ds`.`my_second_dbt_model`
    where id is not null
    group by id
    having count(*) > 1

) validation_errors



2021-04-14 12:02:21.153793 (Thread-1): finished collecting timing info
2021-04-14 12:02:21.154200 (Thread-1): 17:32:21 | 8 of 13 PASS relationships_stg_orders_customer_id__customer_id__ref_stg_customers_ [PASS in 2.57s]
2021-04-14 12:02:21.154327 (Thread-1): Finished running node test.dbt_poc.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_
2021-04-14 12:02:21.154449 (Thread-1): Began running node test.dbt_poc.unique_stg_customers_customer_id
2021-04-14 12:02:21.154643 (Thread-1): 17:32:21 | 12 of 13 START test unique_stg_customers_customer_id................. [RUN]
2021-04-14 12:02:21.154871 (Thread-1): Acquiring new bigquery connection "test.dbt_poc.unique_stg_customers_customer_id".
2021-04-14 12:02:21.154964 (Thread-1): Compiling test.dbt_poc.unique_stg_customers_customer_id
2021-04-14 12:02:21.158579 (Thread-1): Writing injected SQL for node "test.dbt_poc.unique_stg_customers_customer_id"
2021-04-14 12:02:21.158850 (Thread-1): finished collecting timing info
2021-04-14 12:02:21.158987 (Thread-1): Opening a new connection, currently in state closed
2021-04-14 12:02:21.164431 (Thread-1): On test.dbt_poc.unique_stg_customers_customer_id: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "db_bigq_profile", "target_name": "dev", "node_id": "test.dbt_poc.unique_stg_customers_customer_id"} */

    
    



select count(*) as validation_errors
from (

    select
        customer_id

    from `poc-dbt-310711`.`dbt_poc_ds`.`stg_customers`
    where customer_id is not null
    group by customer_id
    having count(*) > 1

) validation_errors



2021-04-14 12:02:22.385038 (Thread-3): finished collecting timing info
2021-04-14 12:02:22.385461 (Thread-3): 17:32:22 | 9 of 13 PASS unique_customers_customer_id............................ [PASS in 2.29s]
2021-04-14 12:02:22.385587 (Thread-3): Finished running node test.dbt_poc.unique_customers_customer_id
2021-04-14 12:02:22.385710 (Thread-3): Began running node test.dbt_poc.unique_stg_orders_order_id
2021-04-14 12:02:22.385909 (Thread-3): 17:32:22 | 13 of 13 START test unique_stg_orders_order_id....................... [RUN]
2021-04-14 12:02:22.386144 (Thread-3): Acquiring new bigquery connection "test.dbt_poc.unique_stg_orders_order_id".
2021-04-14 12:02:22.386233 (Thread-3): Compiling test.dbt_poc.unique_stg_orders_order_id
2021-04-14 12:02:22.389531 (Thread-3): Writing injected SQL for node "test.dbt_poc.unique_stg_orders_order_id"
2021-04-14 12:02:22.389757 (Thread-3): finished collecting timing info
2021-04-14 12:02:22.389883 (Thread-3): Opening a new connection, currently in state closed
2021-04-14 12:02:22.395976 (Thread-3): On test.dbt_poc.unique_stg_orders_order_id: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "db_bigq_profile", "target_name": "dev", "node_id": "test.dbt_poc.unique_stg_orders_order_id"} */

    
    



select count(*) as validation_errors
from (

    select
        order_id

    from `poc-dbt-310711`.`dbt_poc_ds`.`stg_orders`
    where order_id is not null
    group by order_id
    having count(*) > 1

) validation_errors



2021-04-14 12:02:22.645396 (Thread-4): finished collecting timing info
2021-04-14 12:02:22.645806 (Thread-4): 17:32:22 | 10 of 13 PASS unique_my_first_dbt_model_id........................... [PASS in 2.16s]
2021-04-14 12:02:22.645933 (Thread-4): Finished running node test.dbt_poc.unique_my_first_dbt_model_id
2021-04-14 12:02:23.980029 (Thread-1): finished collecting timing info
2021-04-14 12:02:23.980436 (Thread-1): 17:32:23 | 12 of 13 PASS unique_stg_customers_customer_id....................... [PASS in 2.83s]
2021-04-14 12:02:23.980566 (Thread-1): Finished running node test.dbt_poc.unique_stg_customers_customer_id
2021-04-14 12:02:24.083234 (Thread-2): finished collecting timing info
2021-04-14 12:02:24.083543 (Thread-2): 17:32:24 | 11 of 13 PASS unique_my_second_dbt_model_id.......................... [PASS in 3.30s]
2021-04-14 12:02:24.083663 (Thread-2): Finished running node test.dbt_poc.unique_my_second_dbt_model_id
2021-04-14 12:02:24.750551 (Thread-3): finished collecting timing info
2021-04-14 12:02:24.751013 (Thread-3): 17:32:24 | 13 of 13 PASS unique_stg_orders_order_id............................. [PASS in 2.36s]
2021-04-14 12:02:24.751156 (Thread-3): Finished running node test.dbt_poc.unique_stg_orders_order_id
2021-04-14 12:02:24.752360 (MainThread): Acquiring new bigquery connection "master".
2021-04-14 12:02:24.752682 (MainThread): 17:32:24 | 
2021-04-14 12:02:24.752788 (MainThread): 17:32:24 | Finished running 13 tests in 9.67s.
2021-04-14 12:02:24.752871 (MainThread): Connection 'master' was properly closed.
2021-04-14 12:02:24.752927 (MainThread): Connection 'test.dbt_poc.unique_stg_customers_customer_id' was properly closed.
2021-04-14 12:02:24.752980 (MainThread): Connection 'test.dbt_poc.unique_my_second_dbt_model_id' was properly closed.
2021-04-14 12:02:24.753031 (MainThread): Connection 'test.dbt_poc.unique_stg_orders_order_id' was properly closed.
2021-04-14 12:02:24.753082 (MainThread): Connection 'test.dbt_poc.unique_my_first_dbt_model_id' was properly closed.
2021-04-14 12:02:24.758304 (MainThread): 
2021-04-14 12:02:24.758421 (MainThread): Completed with 1 error and 0 warnings:
2021-04-14 12:02:24.758508 (MainThread): 
2021-04-14 12:02:24.758596 (MainThread): Failure in test not_null_my_first_dbt_model_id (models/example/schema.yml)
2021-04-14 12:02:24.758677 (MainThread):   Got 1 result, expected 0.
2021-04-14 12:02:24.758753 (MainThread): 
2021-04-14 12:02:24.758831 (MainThread):   compiled SQL at target/compiled/dbt_poc/models/example/schema.yml/schema_test/not_null_my_first_dbt_model_id.sql
2021-04-14 12:02:24.758938 (MainThread): 
Done. PASS=12 WARN=0 ERROR=1 SKIP=0 TOTAL=13
2021-04-14 12:02:24.759104 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb22e9fe910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb22e9a5940>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb22ea57550>]}
2021-04-14 12:02:24.759286 (MainThread): Flushing usage events
2021-04-14 12:03:59.998735 (MainThread): Running with dbt=0.19.1
2021-04-14 12:04:00.134506 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/home/msonowal/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-04-14 12:04:00.134882 (MainThread): Tracking: tracking
2021-04-14 12:04:00.140619 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6900169880>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f68fe8b7be0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f69001808e0>]}
2021-04-14 12:04:00.146125 (MainThread): Partial parsing not enabled
2021-04-14 12:04:00.146656 (MainThread): Parsing macros/etc.sql
2021-04-14 12:04:00.148383 (MainThread): Parsing macros/adapters.sql
2021-04-14 12:04:00.160267 (MainThread): Parsing macros/catalog.sql
2021-04-14 12:04:00.163635 (MainThread): Parsing macros/materializations/seed.sql
2021-04-14 12:04:00.165354 (MainThread): Parsing macros/materializations/copy.sql
2021-04-14 12:04:00.168204 (MainThread): Parsing macros/materializations/table.sql
2021-04-14 12:04:00.174644 (MainThread): Parsing macros/materializations/incremental.sql
2021-04-14 12:04:00.182665 (MainThread): Parsing macros/materializations/view.sql
2021-04-14 12:04:00.184516 (MainThread): Parsing macros/materializations/snapshot.sql
2021-04-14 12:04:00.186033 (MainThread): Parsing macros/core.sql
2021-04-14 12:04:00.188434 (MainThread): Parsing macros/adapters/common.sql
2021-04-14 12:04:00.214041 (MainThread): Parsing macros/etc/is_incremental.sql
2021-04-14 12:04:00.215067 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-04-14 12:04:00.216283 (MainThread): Parsing macros/etc/query.sql
2021-04-14 12:04:00.216942 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-04-14 12:04:00.217507 (MainThread): Parsing macros/etc/datetime.sql
2021-04-14 12:04:00.223115 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-04-14 12:04:00.224155 (MainThread): Parsing macros/materializations/helpers.sql
2021-04-14 12:04:00.229666 (MainThread): Parsing macros/materializations/common/merge.sql
2021-04-14 12:04:00.238269 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-04-14 12:04:00.251377 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-04-14 12:04:00.255534 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-04-14 12:04:00.256653 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-04-14 12:04:00.259754 (MainThread): Parsing macros/materializations/view/view.sql
2021-04-14 12:04:00.263674 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-04-14 12:04:00.264736 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-04-14 12:04:00.284646 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-04-14 12:04:00.296087 (MainThread): Parsing macros/materializations/table/table.sql
2021-04-14 12:04:00.300276 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-04-14 12:04:00.301946 (MainThread): Parsing macros/schema_tests/unique.sql
2021-04-14 12:04:00.302994 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-04-14 12:04:00.303928 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-04-14 12:04:00.308074 (MainThread): Partial parsing not enabled
2021-04-14 12:04:00.322741 (MainThread): Acquiring new bigquery connection "model.dbt_poc.stg_customers".
2021-04-14 12:04:00.328131 (MainThread): Acquiring new bigquery connection "model.dbt_poc.stg_orders".
2021-04-14 12:04:00.329690 (MainThread): Acquiring new bigquery connection "model.dbt_poc.customers".
2021-04-14 12:04:00.380346 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c170cec5-a08b-4a42-b8e6-edc8c32c638f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f68fd8f9b50>]}
2021-04-14 12:04:00.382856 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c170cec5-a08b-4a42-b8e6-edc8c32c638f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f69000db070>]}
2021-04-14 12:04:00.382990 (MainThread): Found 3 models, 9 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-04-14 12:04:00.383554 (MainThread): 
2021-04-14 12:04:00.383723 (MainThread): Acquiring new bigquery connection "master".
2021-04-14 12:04:00.384450 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_poc-dbt-310711".
2021-04-14 12:04:00.384702 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-04-14 12:04:00.949714 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_poc-dbt-310711_dbt_poc_ds".
2021-04-14 12:04:00.949968 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-04-14 12:04:00.955996 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-04-14 12:04:01.506987 (MainThread): 17:34:01 | Concurrency: 4 threads (target='dev')
2021-04-14 12:04:01.507155 (MainThread): 17:34:01 | 
2021-04-14 12:04:01.509299 (Thread-1): Began running node model.dbt_poc.stg_customers
2021-04-14 12:04:01.509486 (Thread-2): Began running node model.dbt_poc.stg_orders
2021-04-14 12:04:01.509731 (Thread-1): 17:34:01 | 1 of 3 START table model dbt_poc_ds.stg_customers.................... [RUN]
2021-04-14 12:04:01.509958 (Thread-2): 17:34:01 | 2 of 3 START table model dbt_poc_ds.stg_orders....................... [RUN]
2021-04-14 12:04:01.510265 (Thread-1): Acquiring new bigquery connection "model.dbt_poc.stg_customers".
2021-04-14 12:04:01.510388 (Thread-1): Compiling model.dbt_poc.stg_customers
2021-04-14 12:04:01.510619 (Thread-2): Acquiring new bigquery connection "model.dbt_poc.stg_orders".
2021-04-14 12:04:01.511975 (Thread-1): Writing injected SQL for node "model.dbt_poc.stg_customers"
2021-04-14 12:04:01.512127 (Thread-2): Compiling model.dbt_poc.stg_orders
2021-04-14 12:04:01.513309 (Thread-2): Writing injected SQL for node "model.dbt_poc.stg_orders"
2021-04-14 12:04:01.513561 (Thread-1): finished collecting timing info
2021-04-14 12:04:01.513704 (Thread-2): finished collecting timing info
2021-04-14 12:04:01.534014 (Thread-1): Opening a new connection, currently in state closed
2021-04-14 12:04:01.543248 (Thread-2): Opening a new connection, currently in state init
2021-04-14 12:04:01.546597 (Thread-2): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-04-14 12:04:01.549073 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-04-14 12:04:01.774433 (Thread-2): unclosed <socket.socket fd=5, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.7', 49504), raddr=('142.250.182.74', 443)>
2021-04-14 12:04:01.774638 (Thread-2): unclosed <socket.socket fd=6, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.7', 55082), raddr=('142.250.67.42', 443)>
2021-04-14 12:04:01.774773 (Thread-2): unclosed <socket.socket fd=8, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.7', 55086), raddr=('142.250.67.42', 443)>
2021-04-14 12:04:01.774895 (Thread-2): unclosed <socket.socket fd=7, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.7', 49508), raddr=('142.250.182.74', 443)>
2021-04-14 12:04:02.460234 (Thread-2): Writing runtime SQL for node "model.dbt_poc.stg_orders"
2021-04-14 12:04:02.460482 (Thread-2): On model.dbt_poc.stg_orders: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "db_bigq_profile", "target_name": "dev", "node_id": "model.dbt_poc.stg_orders"} */


  create or replace table `poc-dbt-310711`.`dbt_poc_ds`.`stg_orders`
  
  
  OPTIONS()
  as (
    select
    id as order_id,
    user_id as customer_id,
    order_date,
    status

from `dbt-tutorial`.jaffle_shop.orders
  );
    
2021-04-14 12:04:02.469731 (Thread-1): Writing runtime SQL for node "model.dbt_poc.stg_customers"
2021-04-14 12:04:02.469985 (Thread-1): On model.dbt_poc.stg_customers: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "db_bigq_profile", "target_name": "dev", "node_id": "model.dbt_poc.stg_customers"} */


  create or replace table `poc-dbt-310711`.`dbt_poc_ds`.`stg_customers`
  
  
  OPTIONS()
  as (
    select
    id as customer_id,
    first_name,
    last_name

from `dbt-tutorial`.jaffle_shop.customers
  );
    
2021-04-14 12:04:05.284907 (Thread-1): finished collecting timing info
2021-04-14 12:04:05.286044 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c170cec5-a08b-4a42-b8e6-edc8c32c638f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f68fda68b20>]}
2021-04-14 12:04:05.286409 (Thread-1): 17:34:05 | 1 of 3 OK created table model dbt_poc_ds.stg_customers............... [CREATE TABLE (100.0 rows, 1.9 KB processed) in 3.78s]
2021-04-14 12:04:05.287200 (Thread-2): finished collecting timing info
2021-04-14 12:04:05.287363 (Thread-1): Finished running node model.dbt_poc.stg_customers
2021-04-14 12:04:05.287678 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c170cec5-a08b-4a42-b8e6-edc8c32c638f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f68fd9b2c70>]}
2021-04-14 12:04:05.288029 (Thread-2): 17:34:05 | 2 of 3 OK created table model dbt_poc_ds.stg_orders.................. [CREATE TABLE (99.0 rows, 3.3 KB processed) in 3.78s]
2021-04-14 12:04:05.288352 (Thread-2): Finished running node model.dbt_poc.stg_orders
2021-04-14 12:04:05.288778 (Thread-4): Began running node model.dbt_poc.customers
2021-04-14 12:04:05.289205 (Thread-4): 17:34:05 | 3 of 3 START table model dbt_poc_ds.customers........................ [RUN]
2021-04-14 12:04:05.289518 (Thread-4): Acquiring new bigquery connection "model.dbt_poc.customers".
2021-04-14 12:04:05.289619 (Thread-4): Compiling model.dbt_poc.customers
2021-04-14 12:04:05.292546 (Thread-4): Writing injected SQL for node "model.dbt_poc.customers"
2021-04-14 12:04:05.292817 (Thread-4): finished collecting timing info
2021-04-14 12:04:05.294326 (Thread-4): Opening a new connection, currently in state init
2021-04-14 12:04:05.300683 (Thread-4): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-04-14 12:04:06.220624 (Thread-4): Writing runtime SQL for node "model.dbt_poc.customers"
2021-04-14 12:04:06.220985 (Thread-4): On model.dbt_poc.customers: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "db_bigq_profile", "target_name": "dev", "node_id": "model.dbt_poc.customers"} */


  create or replace table `poc-dbt-310711`.`dbt_poc_ds`.`customers`
  
  
  OPTIONS()
  as (
    with customers as (

    select * from `poc-dbt-310711`.`dbt_poc_ds`.`stg_customers`

),

orders as (

    select * from `poc-dbt-310711`.`dbt_poc_ds`.`stg_orders`

),

customer_orders as (

    select
        customer_id,

        min(order_date) as first_order_date,
        max(order_date) as most_recent_order_date,
        count(order_id) as number_of_orders

    from orders

    group by 1

),


final as (

    select
        customers.customer_id,
        customers.first_name,
        customers.last_name,
        customer_orders.first_order_date,
        customer_orders.most_recent_order_date,
        coalesce(customer_orders.number_of_orders, 0) as number_of_orders

    from customers

    left join customer_orders using (customer_id)

)

select * from final
  );
    
2021-04-14 12:04:10.354864 (Thread-4): finished collecting timing info
2021-04-14 12:04:10.355292 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c170cec5-a08b-4a42-b8e6-edc8c32c638f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f68fda68460>]}
2021-04-14 12:04:10.355592 (Thread-4): 17:34:10 | 3 of 3 OK created table model dbt_poc_ds.customers................... [CREATE TABLE (100.0 rows, 4.3 KB processed) in 5.07s]
2021-04-14 12:04:10.355714 (Thread-4): Finished running node model.dbt_poc.customers
2021-04-14 12:04:10.356871 (MainThread): Acquiring new bigquery connection "master".
2021-04-14 12:04:10.357243 (MainThread): 17:34:10 | 
2021-04-14 12:04:10.357366 (MainThread): 17:34:10 | Finished running 3 table models in 9.97s.
2021-04-14 12:04:10.357454 (MainThread): Connection 'master' was properly closed.
2021-04-14 12:04:10.357515 (MainThread): Connection 'model.dbt_poc.stg_customers' was properly closed.
2021-04-14 12:04:10.357576 (MainThread): Connection 'model.dbt_poc.stg_orders' was properly closed.
2021-04-14 12:04:10.357630 (MainThread): Connection 'model.dbt_poc.customers' was properly closed.
2021-04-14 12:04:10.361619 (MainThread): 
2021-04-14 12:04:10.361724 (MainThread): Completed successfully
2021-04-14 12:04:10.361818 (MainThread): 
Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
2021-04-14 12:04:10.361939 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f68fd903f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f69000e2d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f69000e23d0>]}
2021-04-14 12:04:10.362090 (MainThread): Flushing usage events
2021-04-14 12:04:43.677144 (MainThread): Running with dbt=0.19.1
2021-04-14 12:04:43.809413 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, data=False, debug=False, defer=None, exclude=None, fail_fast=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/home/msonowal/.dbt', project_dir=None, record_timing_info=None, rpc_method='test', schema=False, selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='test', write_json=True)
2021-04-14 12:04:43.809793 (MainThread): Tracking: tracking
2021-04-14 12:04:43.815543 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efcd4227040>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efcd2976d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efcd4229910>]}
2021-04-14 12:04:43.820989 (MainThread): Partial parsing not enabled
2021-04-14 12:04:43.821508 (MainThread): Parsing macros/etc.sql
2021-04-14 12:04:43.823192 (MainThread): Parsing macros/adapters.sql
2021-04-14 12:04:43.834721 (MainThread): Parsing macros/catalog.sql
2021-04-14 12:04:43.838165 (MainThread): Parsing macros/materializations/seed.sql
2021-04-14 12:04:43.839887 (MainThread): Parsing macros/materializations/copy.sql
2021-04-14 12:04:43.842719 (MainThread): Parsing macros/materializations/table.sql
2021-04-14 12:04:43.849180 (MainThread): Parsing macros/materializations/incremental.sql
2021-04-14 12:04:43.857216 (MainThread): Parsing macros/materializations/view.sql
2021-04-14 12:04:43.858973 (MainThread): Parsing macros/materializations/snapshot.sql
2021-04-14 12:04:43.860484 (MainThread): Parsing macros/core.sql
2021-04-14 12:04:43.862941 (MainThread): Parsing macros/adapters/common.sql
2021-04-14 12:04:43.888470 (MainThread): Parsing macros/etc/is_incremental.sql
2021-04-14 12:04:43.889491 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-04-14 12:04:43.890766 (MainThread): Parsing macros/etc/query.sql
2021-04-14 12:04:43.891421 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-04-14 12:04:43.891990 (MainThread): Parsing macros/etc/datetime.sql
2021-04-14 12:04:43.897648 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-04-14 12:04:43.898685 (MainThread): Parsing macros/materializations/helpers.sql
2021-04-14 12:04:43.904220 (MainThread): Parsing macros/materializations/common/merge.sql
2021-04-14 12:04:43.912908 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-04-14 12:04:43.925864 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-04-14 12:04:43.929926 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-04-14 12:04:43.931102 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-04-14 12:04:43.934247 (MainThread): Parsing macros/materializations/view/view.sql
2021-04-14 12:04:43.938225 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-04-14 12:04:43.939308 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-04-14 12:04:43.958403 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-04-14 12:04:43.969760 (MainThread): Parsing macros/materializations/table/table.sql
2021-04-14 12:04:43.974072 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-04-14 12:04:43.975787 (MainThread): Parsing macros/schema_tests/unique.sql
2021-04-14 12:04:43.976833 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-04-14 12:04:43.977757 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-04-14 12:04:43.981857 (MainThread): Partial parsing not enabled
2021-04-14 12:04:43.996548 (MainThread): Acquiring new bigquery connection "model.dbt_poc.stg_customers".
2021-04-14 12:04:44.002173 (MainThread): Acquiring new bigquery connection "model.dbt_poc.stg_orders".
2021-04-14 12:04:44.003814 (MainThread): Acquiring new bigquery connection "model.dbt_poc.customers".
2021-04-14 12:04:44.054964 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '09f0c101-1c68-4917-aee0-b900dbd3a5e9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efcd19b8b50>]}
2021-04-14 12:04:44.057458 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '09f0c101-1c68-4917-aee0-b900dbd3a5e9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efcd4199070>]}
2021-04-14 12:04:44.057582 (MainThread): Found 3 models, 9 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-04-14 12:04:44.058174 (MainThread): 
2021-04-14 12:04:44.058320 (MainThread): Acquiring new bigquery connection "master".
2021-04-14 12:04:44.059263 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_poc-dbt-310711_dbt_poc_ds".
2021-04-14 12:04:44.059417 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2021-04-14 12:04:44.065301 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-04-14 12:04:44.724861 (MainThread): 17:34:44 | Concurrency: 4 threads (target='dev')
2021-04-14 12:04:44.725037 (MainThread): 17:34:44 | 
2021-04-14 12:04:44.727102 (Thread-1): Began running node test.dbt_poc.accepted_values_stg_orders_status__placed__shipped__completed__return_pending__returned
2021-04-14 12:04:44.727440 (Thread-2): Began running node test.dbt_poc.not_null_customers_customer_id
2021-04-14 12:04:44.727593 (Thread-3): Began running node test.dbt_poc.not_null_stg_customers_customer_id
2021-04-14 12:04:44.727742 (Thread-1): 17:34:44 | 1 of 9 START test accepted_values_stg_orders_status__placed__shipped__completed__return_pending__returned [RUN]
2021-04-14 12:04:44.727890 (Thread-4): Began running node test.dbt_poc.not_null_stg_orders_customer_id
2021-04-14 12:04:44.728104 (Thread-2): 17:34:44 | 2 of 9 START test not_null_customers_customer_id..................... [RUN]
2021-04-14 12:04:44.728240 (Thread-3): 17:34:44 | 3 of 9 START test not_null_stg_customers_customer_id................. [RUN]
2021-04-14 12:04:44.728544 (Thread-1): Acquiring new bigquery connection "test.dbt_poc.accepted_values_stg_orders_status__placed__shipped__completed__return_pending__returned".
2021-04-14 12:04:44.728685 (Thread-4): 17:34:44 | 4 of 9 START test not_null_stg_orders_customer_id.................... [RUN]
2021-04-14 12:04:44.729004 (Thread-2): Acquiring new bigquery connection "test.dbt_poc.not_null_customers_customer_id".
2021-04-14 12:04:44.729260 (Thread-3): Acquiring new bigquery connection "test.dbt_poc.not_null_stg_customers_customer_id".
2021-04-14 12:04:44.729435 (Thread-1): Compiling test.dbt_poc.accepted_values_stg_orders_status__placed__shipped__completed__return_pending__returned
2021-04-14 12:04:44.729769 (Thread-4): Acquiring new bigquery connection "test.dbt_poc.not_null_stg_orders_customer_id".
2021-04-14 12:04:44.729877 (Thread-2): Compiling test.dbt_poc.not_null_customers_customer_id
2021-04-14 12:04:44.729975 (Thread-3): Compiling test.dbt_poc.not_null_stg_customers_customer_id
2021-04-14 12:04:44.740030 (Thread-1): Writing injected SQL for node "test.dbt_poc.accepted_values_stg_orders_status__placed__shipped__completed__return_pending__returned"
2021-04-14 12:04:44.740165 (Thread-4): Compiling test.dbt_poc.not_null_stg_orders_customer_id
2021-04-14 12:04:44.746513 (Thread-2): Writing injected SQL for node "test.dbt_poc.not_null_customers_customer_id"
2021-04-14 12:04:44.750127 (Thread-3): Writing injected SQL for node "test.dbt_poc.not_null_stg_customers_customer_id"
2021-04-14 12:04:44.753858 (Thread-4): Writing injected SQL for node "test.dbt_poc.not_null_stg_orders_customer_id"
2021-04-14 12:04:44.754105 (Thread-1): finished collecting timing info
2021-04-14 12:04:44.754281 (Thread-2): finished collecting timing info
2021-04-14 12:04:44.754507 (Thread-1): Opening a new connection, currently in state closed
2021-04-14 12:04:44.754617 (Thread-2): Opening a new connection, currently in state init
2021-04-14 12:04:44.754710 (Thread-3): finished collecting timing info
2021-04-14 12:04:44.754847 (Thread-4): finished collecting timing info
2021-04-14 12:04:44.755043 (Thread-3): Opening a new connection, currently in state init
2021-04-14 12:04:44.755325 (Thread-4): Opening a new connection, currently in state init
2021-04-14 12:04:44.759893 (Thread-2): On test.dbt_poc.not_null_customers_customer_id: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "db_bigq_profile", "target_name": "dev", "node_id": "test.dbt_poc.not_null_customers_customer_id"} */

    
    



select count(*) as validation_errors
from `poc-dbt-310711`.`dbt_poc_ds`.`customers`
where customer_id is null



2021-04-14 12:04:44.760462 (Thread-3): On test.dbt_poc.not_null_stg_customers_customer_id: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "db_bigq_profile", "target_name": "dev", "node_id": "test.dbt_poc.not_null_stg_customers_customer_id"} */

    
    



select count(*) as validation_errors
from `poc-dbt-310711`.`dbt_poc_ds`.`stg_customers`
where customer_id is null



2021-04-14 12:04:44.763197 (Thread-4): On test.dbt_poc.not_null_stg_orders_customer_id: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "db_bigq_profile", "target_name": "dev", "node_id": "test.dbt_poc.not_null_stg_orders_customer_id"} */

    
    



select count(*) as validation_errors
from `poc-dbt-310711`.`dbt_poc_ds`.`stg_orders`
where customer_id is null



2021-04-14 12:04:44.763349 (Thread-1): On test.dbt_poc.accepted_values_stg_orders_status__placed__shipped__completed__return_pending__returned: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "db_bigq_profile", "target_name": "dev", "node_id": "test.dbt_poc.accepted_values_stg_orders_status__placed__shipped__completed__return_pending__returned"} */

    
    




with all_values as (

    select distinct
        status as value_field

    from `poc-dbt-310711`.`dbt_poc_ds`.`stg_orders`

),

validation_errors as (

    select
        value_field

    from all_values
    where value_field not in (
        'placed','shipped','completed','return_pending','returned'
    )
)

select count(*) as validation_errors
from validation_errors



2021-04-14 12:04:44.764125 (Thread-4): unclosed <socket.socket fd=5, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.7', 49526), raddr=('142.250.182.74', 443)>
2021-04-14 12:04:44.764716 (Thread-4): unclosed <socket.socket fd=6, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.7', 55104), raddr=('142.250.67.42', 443)>
2021-04-14 12:04:46.828275 (Thread-1): finished collecting timing info
2021-04-14 12:04:46.828700 (Thread-1): 17:34:46 | 1 of 9 PASS accepted_values_stg_orders_status__placed__shipped__completed__return_pending__returned [PASS in 2.10s]
2021-04-14 12:04:46.828830 (Thread-1): Finished running node test.dbt_poc.accepted_values_stg_orders_status__placed__shipped__completed__return_pending__returned
2021-04-14 12:04:46.828950 (Thread-1): Began running node test.dbt_poc.not_null_stg_orders_order_id
2021-04-14 12:04:46.829068 (Thread-1): 17:34:46 | 5 of 9 START test not_null_stg_orders_order_id....................... [RUN]
2021-04-14 12:04:46.829664 (Thread-1): Acquiring new bigquery connection "test.dbt_poc.not_null_stg_orders_order_id".
2021-04-14 12:04:46.829825 (Thread-1): Compiling test.dbt_poc.not_null_stg_orders_order_id
2021-04-14 12:04:46.833526 (Thread-1): Writing injected SQL for node "test.dbt_poc.not_null_stg_orders_order_id"
2021-04-14 12:04:46.833825 (Thread-1): finished collecting timing info
2021-04-14 12:04:46.833962 (Thread-1): Opening a new connection, currently in state closed
2021-04-14 12:04:46.839841 (Thread-1): On test.dbt_poc.not_null_stg_orders_order_id: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "db_bigq_profile", "target_name": "dev", "node_id": "test.dbt_poc.not_null_stg_orders_order_id"} */

    
    



select count(*) as validation_errors
from `poc-dbt-310711`.`dbt_poc_ds`.`stg_orders`
where order_id is null



2021-04-14 12:04:46.962492 (Thread-4): finished collecting timing info
2021-04-14 12:04:46.962842 (Thread-4): 17:34:46 | 4 of 9 PASS not_null_stg_orders_customer_id.......................... [PASS in 2.23s]
2021-04-14 12:04:46.962960 (Thread-4): Finished running node test.dbt_poc.not_null_stg_orders_customer_id
2021-04-14 12:04:46.963096 (Thread-4): Began running node test.dbt_poc.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_
2021-04-14 12:04:46.963351 (Thread-4): 17:34:46 | 6 of 9 START test relationships_stg_orders_customer_id__customer_id__ref_stg_customers_ [RUN]
2021-04-14 12:04:46.963580 (Thread-4): Acquiring new bigquery connection "test.dbt_poc.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_".
2021-04-14 12:04:46.963670 (Thread-4): Compiling test.dbt_poc.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_
2021-04-14 12:04:46.971569 (Thread-4): Writing injected SQL for node "test.dbt_poc.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_"
2021-04-14 12:04:46.971799 (Thread-4): finished collecting timing info
2021-04-14 12:04:46.971902 (Thread-4): Opening a new connection, currently in state closed
2021-04-14 12:04:46.976309 (Thread-4): On test.dbt_poc.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "db_bigq_profile", "target_name": "dev", "node_id": "test.dbt_poc.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_"} */

    
    




select count(*) as validation_errors
from (
    select customer_id as id from `poc-dbt-310711`.`dbt_poc_ds`.`stg_orders`
) as child
left join (
    select customer_id as id from `poc-dbt-310711`.`dbt_poc_ds`.`stg_customers`
) as parent on parent.id = child.id
where child.id is not null
  and parent.id is null



2021-04-14 12:04:47.189966 (Thread-3): finished collecting timing info
2021-04-14 12:04:47.190357 (Thread-3): 17:34:47 | 3 of 9 PASS not_null_stg_customers_customer_id....................... [PASS in 2.46s]
2021-04-14 12:04:47.190481 (Thread-3): Finished running node test.dbt_poc.not_null_stg_customers_customer_id
2021-04-14 12:04:47.190597 (Thread-3): Began running node test.dbt_poc.unique_customers_customer_id
2021-04-14 12:04:47.190951 (Thread-3): 17:34:47 | 7 of 9 START test unique_customers_customer_id....................... [RUN]
2021-04-14 12:04:47.191345 (Thread-3): Acquiring new bigquery connection "test.dbt_poc.unique_customers_customer_id".
2021-04-14 12:04:47.191449 (Thread-3): Compiling test.dbt_poc.unique_customers_customer_id
2021-04-14 12:04:47.198327 (Thread-3): Writing injected SQL for node "test.dbt_poc.unique_customers_customer_id"
2021-04-14 12:04:47.198560 (Thread-3): finished collecting timing info
2021-04-14 12:04:47.198688 (Thread-3): Opening a new connection, currently in state closed
2021-04-14 12:04:47.203335 (Thread-3): On test.dbt_poc.unique_customers_customer_id: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "db_bigq_profile", "target_name": "dev", "node_id": "test.dbt_poc.unique_customers_customer_id"} */

    
    



select count(*) as validation_errors
from (

    select
        customer_id

    from `poc-dbt-310711`.`dbt_poc_ds`.`customers`
    where customer_id is not null
    group by customer_id
    having count(*) > 1

) validation_errors



2021-04-14 12:04:47.332391 (Thread-2): finished collecting timing info
2021-04-14 12:04:47.332769 (Thread-2): 17:34:47 | 2 of 9 PASS not_null_customers_customer_id........................... [PASS in 2.60s]
2021-04-14 12:04:47.332909 (Thread-2): Finished running node test.dbt_poc.not_null_customers_customer_id
2021-04-14 12:04:47.333026 (Thread-2): Began running node test.dbt_poc.unique_stg_customers_customer_id
2021-04-14 12:04:47.333244 (Thread-2): 17:34:47 | 8 of 9 START test unique_stg_customers_customer_id................... [RUN]
2021-04-14 12:04:47.333469 (Thread-2): Acquiring new bigquery connection "test.dbt_poc.unique_stg_customers_customer_id".
2021-04-14 12:04:47.333560 (Thread-2): Compiling test.dbt_poc.unique_stg_customers_customer_id
2021-04-14 12:04:47.337077 (Thread-2): Writing injected SQL for node "test.dbt_poc.unique_stg_customers_customer_id"
2021-04-14 12:04:47.337355 (Thread-2): finished collecting timing info
2021-04-14 12:04:47.337486 (Thread-2): Opening a new connection, currently in state closed
2021-04-14 12:04:47.343344 (Thread-2): On test.dbt_poc.unique_stg_customers_customer_id: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "db_bigq_profile", "target_name": "dev", "node_id": "test.dbt_poc.unique_stg_customers_customer_id"} */

    
    



select count(*) as validation_errors
from (

    select
        customer_id

    from `poc-dbt-310711`.`dbt_poc_ds`.`stg_customers`
    where customer_id is not null
    group by customer_id
    having count(*) > 1

) validation_errors



2021-04-14 12:04:48.987459 (Thread-1): finished collecting timing info
2021-04-14 12:04:48.987855 (Thread-1): 17:34:48 | 5 of 9 PASS not_null_stg_orders_order_id............................. [PASS in 2.16s]
2021-04-14 12:04:48.987979 (Thread-1): Finished running node test.dbt_poc.not_null_stg_orders_order_id
2021-04-14 12:04:48.988093 (Thread-1): Began running node test.dbt_poc.unique_stg_orders_order_id
2021-04-14 12:04:48.988332 (Thread-1): 17:34:48 | 9 of 9 START test unique_stg_orders_order_id......................... [RUN]
2021-04-14 12:04:48.988561 (Thread-1): Acquiring new bigquery connection "test.dbt_poc.unique_stg_orders_order_id".
2021-04-14 12:04:48.988654 (Thread-1): Compiling test.dbt_poc.unique_stg_orders_order_id
2021-04-14 12:04:48.992245 (Thread-1): Writing injected SQL for node "test.dbt_poc.unique_stg_orders_order_id"
2021-04-14 12:04:48.992507 (Thread-1): finished collecting timing info
2021-04-14 12:04:48.992650 (Thread-1): Opening a new connection, currently in state closed
2021-04-14 12:04:48.998510 (Thread-1): On test.dbt_poc.unique_stg_orders_order_id: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "db_bigq_profile", "target_name": "dev", "node_id": "test.dbt_poc.unique_stg_orders_order_id"} */

    
    



select count(*) as validation_errors
from (

    select
        order_id

    from `poc-dbt-310711`.`dbt_poc_ds`.`stg_orders`
    where order_id is not null
    group by order_id
    having count(*) > 1

) validation_errors



2021-04-14 12:04:49.423588 (Thread-2): finished collecting timing info
2021-04-14 12:04:49.423992 (Thread-2): 17:34:49 | 8 of 9 PASS unique_stg_customers_customer_id......................... [PASS in 2.09s]
2021-04-14 12:04:49.424116 (Thread-2): Finished running node test.dbt_poc.unique_stg_customers_customer_id
2021-04-14 12:04:49.539057 (Thread-4): finished collecting timing info
2021-04-14 12:04:49.539365 (Thread-4): 17:34:49 | 6 of 9 PASS relationships_stg_orders_customer_id__customer_id__ref_stg_customers_ [PASS in 2.58s]
2021-04-14 12:04:49.539480 (Thread-4): Finished running node test.dbt_poc.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_
2021-04-14 12:04:49.665869 (Thread-3): finished collecting timing info
2021-04-14 12:04:49.666181 (Thread-3): 17:34:49 | 7 of 9 PASS unique_customers_customer_id............................. [PASS in 2.48s]
2021-04-14 12:04:49.666299 (Thread-3): Finished running node test.dbt_poc.unique_customers_customer_id
2021-04-14 12:04:51.524472 (Thread-1): finished collecting timing info
2021-04-14 12:04:51.524876 (Thread-1): 17:34:51 | 9 of 9 PASS unique_stg_orders_order_id............................... [PASS in 2.54s]
2021-04-14 12:04:51.525003 (Thread-1): Finished running node test.dbt_poc.unique_stg_orders_order_id
2021-04-14 12:04:51.526014 (MainThread): Acquiring new bigquery connection "master".
2021-04-14 12:04:51.526277 (MainThread): 17:34:51 | 
2021-04-14 12:04:51.526392 (MainThread): 17:34:51 | Finished running 9 tests in 7.47s.
2021-04-14 12:04:51.526482 (MainThread): Connection 'master' was properly closed.
2021-04-14 12:04:51.526543 (MainThread): Connection 'test.dbt_poc.unique_stg_orders_order_id' was properly closed.
2021-04-14 12:04:51.526602 (MainThread): Connection 'test.dbt_poc.unique_stg_customers_customer_id' was properly closed.
2021-04-14 12:04:51.526656 (MainThread): Connection 'test.dbt_poc.unique_customers_customer_id' was properly closed.
2021-04-14 12:04:51.526711 (MainThread): Connection 'test.dbt_poc.relationships_stg_orders_customer_id__customer_id__ref_stg_customers_' was properly closed.
2021-04-14 12:04:51.531143 (MainThread): 
2021-04-14 12:04:51.531265 (MainThread): Completed successfully
2021-04-14 12:04:51.531375 (MainThread): 
Done. PASS=9 WARN=0 ERROR=0 SKIP=0 TOTAL=9
2021-04-14 12:04:51.531524 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efcd1a892e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efcd1accbe0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efcd1b27a90>]}
2021-04-14 12:04:51.531709 (MainThread): Flushing usage events
2021-04-14 12:05:31.011068 (MainThread): Running with dbt=0.19.1
2021-04-14 12:05:31.149896 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.generate.GenerateTask'>, compile=True, debug=False, defer=None, exclude=None, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/home/msonowal/.dbt', project_dir=None, record_timing_info=None, rpc_method='docs.generate', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='generate', write_json=True)
2021-04-14 12:05:31.150287 (MainThread): Tracking: tracking
2021-04-14 12:05:31.156063 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6cf5b53940>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6cf4292ee0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6cf5b59880>]}
2021-04-14 12:05:31.161839 (MainThread): Partial parsing not enabled
2021-04-14 12:05:31.162396 (MainThread): Parsing macros/etc.sql
2021-04-14 12:05:31.164216 (MainThread): Parsing macros/adapters.sql
2021-04-14 12:05:31.176199 (MainThread): Parsing macros/catalog.sql
2021-04-14 12:05:31.179637 (MainThread): Parsing macros/materializations/seed.sql
2021-04-14 12:05:31.181366 (MainThread): Parsing macros/materializations/copy.sql
2021-04-14 12:05:31.184309 (MainThread): Parsing macros/materializations/table.sql
2021-04-14 12:05:31.190907 (MainThread): Parsing macros/materializations/incremental.sql
2021-04-14 12:05:31.199135 (MainThread): Parsing macros/materializations/view.sql
2021-04-14 12:05:31.200941 (MainThread): Parsing macros/materializations/snapshot.sql
2021-04-14 12:05:31.202443 (MainThread): Parsing macros/core.sql
2021-04-14 12:05:31.204862 (MainThread): Parsing macros/adapters/common.sql
2021-04-14 12:05:31.230773 (MainThread): Parsing macros/etc/is_incremental.sql
2021-04-14 12:05:31.231810 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-04-14 12:05:31.233037 (MainThread): Parsing macros/etc/query.sql
2021-04-14 12:05:31.233674 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-04-14 12:05:31.234234 (MainThread): Parsing macros/etc/datetime.sql
2021-04-14 12:05:31.239793 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-04-14 12:05:31.240809 (MainThread): Parsing macros/materializations/helpers.sql
2021-04-14 12:05:31.246208 (MainThread): Parsing macros/materializations/common/merge.sql
2021-04-14 12:05:31.254688 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-04-14 12:05:31.267539 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-04-14 12:05:31.271468 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-04-14 12:05:31.272607 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-04-14 12:05:31.275691 (MainThread): Parsing macros/materializations/view/view.sql
2021-04-14 12:05:31.279626 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-04-14 12:05:31.280694 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-04-14 12:05:31.299756 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-04-14 12:05:31.311390 (MainThread): Parsing macros/materializations/table/table.sql
2021-04-14 12:05:31.315621 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-04-14 12:05:31.317297 (MainThread): Parsing macros/schema_tests/unique.sql
2021-04-14 12:05:31.318350 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-04-14 12:05:31.319278 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-04-14 12:05:31.323483 (MainThread): Partial parsing not enabled
2021-04-14 12:05:31.338247 (MainThread): Acquiring new bigquery connection "model.dbt_poc.stg_customers".
2021-04-14 12:05:31.343904 (MainThread): Acquiring new bigquery connection "model.dbt_poc.stg_orders".
2021-04-14 12:05:31.345536 (MainThread): Acquiring new bigquery connection "model.dbt_poc.customers".
2021-04-14 12:05:31.393930 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '36db33af-8c3c-4a5c-8aeb-153e0034ee82', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6cf33160a0>]}
2021-04-14 12:05:31.396332 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '36db33af-8c3c-4a5c-8aeb-153e0034ee82', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6cf5ad2550>]}
2021-04-14 12:05:31.396467 (MainThread): Found 3 models, 7 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-04-14 12:05:31.397014 (MainThread): 
2021-04-14 12:05:31.397176 (MainThread): Acquiring new bigquery connection "master".
2021-04-14 12:05:31.398134 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_poc-dbt-310711_dbt_poc_ds".
2021-04-14 12:05:31.398357 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-04-14 12:05:31.404236 (ThreadPoolExecutor-0_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-04-14 12:05:32.356911 (MainThread): 17:35:32 | Concurrency: 4 threads (target='dev')
2021-04-14 12:05:32.357097 (MainThread): 17:35:32 | 
2021-04-14 12:05:32.359046 (Thread-1): Began running node model.dbt_poc.stg_customers
2021-04-14 12:05:32.359242 (Thread-2): Began running node model.dbt_poc.stg_orders
2021-04-14 12:05:32.359586 (Thread-1): Acquiring new bigquery connection "model.dbt_poc.stg_customers".
2021-04-14 12:05:32.360125 (Thread-2): Acquiring new bigquery connection "model.dbt_poc.stg_orders".
2021-04-14 12:05:32.360266 (Thread-1): Compiling model.dbt_poc.stg_customers
2021-04-14 12:05:32.360417 (Thread-2): Compiling model.dbt_poc.stg_orders
2021-04-14 12:05:32.361729 (Thread-1): Writing injected SQL for node "model.dbt_poc.stg_customers"
2021-04-14 12:05:32.363034 (Thread-2): Writing injected SQL for node "model.dbt_poc.stg_orders"
2021-04-14 12:05:32.363434 (Thread-1): finished collecting timing info
2021-04-14 12:05:32.363589 (Thread-2): finished collecting timing info
2021-04-14 12:05:32.363746 (Thread-1): finished collecting timing info
2021-04-14 12:05:32.363912 (Thread-2): finished collecting timing info
2021-04-14 12:05:32.364210 (Thread-1): Finished running node model.dbt_poc.stg_customers
2021-04-14 12:05:32.364578 (Thread-2): Finished running node model.dbt_poc.stg_orders
2021-04-14 12:05:32.365181 (Thread-4): Began running node test.dbt_poc.not_null_stg_customers_customer_id
2021-04-14 12:05:32.365458 (Thread-3): Began running node test.dbt_poc.unique_stg_customers_customer_id
2021-04-14 12:05:32.365774 (Thread-4): Acquiring new bigquery connection "test.dbt_poc.not_null_stg_customers_customer_id".
2021-04-14 12:05:32.365928 (Thread-1): Began running node model.dbt_poc.customers
2021-04-14 12:05:32.366135 (Thread-2): Began running node test.dbt_poc.accepted_values_stg_orders_status__placed__shipped__completed__return_pending__returned
2021-04-14 12:05:32.366434 (Thread-3): Acquiring new bigquery connection "test.dbt_poc.unique_stg_customers_customer_id".
2021-04-14 12:05:32.366560 (Thread-4): Compiling test.dbt_poc.not_null_stg_customers_customer_id
2021-04-14 12:05:32.366879 (Thread-1): Acquiring new bigquery connection "model.dbt_poc.customers".
2021-04-14 12:05:32.367290 (Thread-2): Acquiring new bigquery connection "test.dbt_poc.accepted_values_stg_orders_status__placed__shipped__completed__return_pending__returned".
2021-04-14 12:05:32.367436 (Thread-3): Compiling test.dbt_poc.unique_stg_customers_customer_id
2021-04-14 12:05:32.375685 (Thread-4): Writing injected SQL for node "test.dbt_poc.not_null_stg_customers_customer_id"
2021-04-14 12:05:32.375812 (Thread-1): Compiling model.dbt_poc.customers
2021-04-14 12:05:32.375945 (Thread-2): Compiling test.dbt_poc.accepted_values_stg_orders_status__placed__shipped__completed__return_pending__returned
2021-04-14 12:05:32.379678 (Thread-3): Writing injected SQL for node "test.dbt_poc.unique_stg_customers_customer_id"
2021-04-14 12:05:32.381041 (Thread-1): Writing injected SQL for node "model.dbt_poc.customers"
2021-04-14 12:05:32.391413 (Thread-4): finished collecting timing info
2021-04-14 12:05:32.392803 (Thread-2): Writing injected SQL for node "test.dbt_poc.accepted_values_stg_orders_status__placed__shipped__completed__return_pending__returned"
2021-04-14 12:05:32.393064 (Thread-4): finished collecting timing info
2021-04-14 12:05:32.393198 (Thread-3): finished collecting timing info
2021-04-14 12:05:32.393338 (Thread-1): finished collecting timing info
2021-04-14 12:05:32.393669 (Thread-4): Finished running node test.dbt_poc.not_null_stg_customers_customer_id
2021-04-14 12:05:32.393845 (Thread-3): finished collecting timing info
2021-04-14 12:05:32.394014 (Thread-1): finished collecting timing info
2021-04-14 12:05:32.394100 (Thread-2): finished collecting timing info
2021-04-14 12:05:32.394201 (Thread-4): Began running node test.dbt_poc.not_null_stg_orders_order_id
2021-04-14 12:05:32.394658 (Thread-3): Finished running node test.dbt_poc.unique_stg_customers_customer_id
2021-04-14 12:05:32.394943 (Thread-1): Finished running node model.dbt_poc.customers
2021-04-14 12:05:32.395048 (Thread-2): finished collecting timing info
2021-04-14 12:05:32.395283 (Thread-4): Acquiring new bigquery connection "test.dbt_poc.not_null_stg_orders_order_id".
2021-04-14 12:05:32.395460 (Thread-3): Began running node test.dbt_poc.unique_stg_orders_order_id
2021-04-14 12:05:32.395821 (Thread-2): Finished running node test.dbt_poc.accepted_values_stg_orders_status__placed__shipped__completed__return_pending__returned
2021-04-14 12:05:32.396042 (Thread-1): Began running node test.dbt_poc.not_null_customers_customer_id
2021-04-14 12:05:32.396167 (Thread-4): Compiling test.dbt_poc.not_null_stg_orders_order_id
2021-04-14 12:05:32.396499 (Thread-3): Acquiring new bigquery connection "test.dbt_poc.unique_stg_orders_order_id".
2021-04-14 12:05:32.396642 (Thread-2): Began running node test.dbt_poc.unique_customers_customer_id
2021-04-14 12:05:32.396992 (Thread-1): Acquiring new bigquery connection "test.dbt_poc.not_null_customers_customer_id".
2021-04-14 12:05:32.398368 (Thread-4): unclosed <socket.socket fd=5, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.7', 49604), raddr=('142.250.182.74', 443)>
2021-04-14 12:05:32.398488 (Thread-3): Compiling test.dbt_poc.unique_stg_orders_order_id
2021-04-14 12:05:32.398834 (Thread-2): Acquiring new bigquery connection "test.dbt_poc.unique_customers_customer_id".
2021-04-14 12:05:32.398991 (Thread-1): Compiling test.dbt_poc.not_null_customers_customer_id
2021-04-14 12:05:32.402076 (Thread-3): Writing injected SQL for node "test.dbt_poc.unique_stg_orders_order_id"
2021-04-14 12:05:32.402170 (Thread-4): unclosed <socket.socket fd=6, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.0.7', 55182), raddr=('142.250.67.42', 443)>
2021-04-14 12:05:32.402323 (Thread-2): Compiling test.dbt_poc.unique_customers_customer_id
2021-04-14 12:05:32.405846 (Thread-1): Writing injected SQL for node "test.dbt_poc.not_null_customers_customer_id"
2021-04-14 12:05:32.409568 (Thread-2): Writing injected SQL for node "test.dbt_poc.unique_customers_customer_id"
2021-04-14 12:05:32.413523 (Thread-4): Writing injected SQL for node "test.dbt_poc.not_null_stg_orders_order_id"
2021-04-14 12:05:32.413789 (Thread-3): finished collecting timing info
2021-04-14 12:05:32.414227 (Thread-3): finished collecting timing info
2021-04-14 12:05:32.414569 (Thread-3): Finished running node test.dbt_poc.unique_stg_orders_order_id
2021-04-14 12:05:32.414683 (Thread-2): finished collecting timing info
2021-04-14 12:05:32.414878 (Thread-1): finished collecting timing info
2021-04-14 12:05:32.415102 (Thread-2): finished collecting timing info
2021-04-14 12:05:32.415210 (Thread-4): finished collecting timing info
2021-04-14 12:05:32.415349 (Thread-1): finished collecting timing info
2021-04-14 12:05:32.415585 (Thread-2): Finished running node test.dbt_poc.unique_customers_customer_id
2021-04-14 12:05:32.415713 (Thread-4): finished collecting timing info
2021-04-14 12:05:32.415960 (Thread-1): Finished running node test.dbt_poc.not_null_customers_customer_id
2021-04-14 12:05:32.416274 (Thread-4): Finished running node test.dbt_poc.not_null_stg_orders_order_id
2021-04-14 12:05:32.417128 (MainThread): Connection 'master' was properly closed.
2021-04-14 12:05:32.417251 (MainThread): Connection 'test.dbt_poc.not_null_customers_customer_id' was properly closed.
2021-04-14 12:05:32.417322 (MainThread): Connection 'test.dbt_poc.unique_customers_customer_id' was properly closed.
2021-04-14 12:05:32.417386 (MainThread): Connection 'test.dbt_poc.not_null_stg_orders_order_id' was properly closed.
2021-04-14 12:05:32.417447 (MainThread): Connection 'test.dbt_poc.unique_stg_orders_order_id' was properly closed.
2021-04-14 12:05:32.421454 (MainThread): 17:35:32 | Done.
2021-04-14 12:05:32.422513 (MainThread): Acquiring new bigquery connection "generate_catalog".
2021-04-14 12:05:32.422583 (MainThread): 17:35:32 | Building catalog
2021-04-14 12:05:32.423370 (MainThread): Opening a new connection, currently in state init
2021-04-14 12:05:33.359051 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "poc-dbt-310711.information_schema".
2021-04-14 12:05:33.372769 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2021-04-14 12:05:33.375869 (ThreadPoolExecutor-1_0): On poc-dbt-310711.information_schema: /* {"app": "dbt", "dbt_version": "0.19.1", "profile_name": "db_bigq_profile", "target_name": "dev", "connection_name": "poc-dbt-310711.information_schema"} */

    with tables as (
        select
            project_id as table_database,
            dataset_id as table_schema,
            table_id as original_table_name,

            concat(project_id, '.', dataset_id, '.', table_id) as relation_id,

            row_count,
            size_bytes as size_bytes,
            case
                when type = 1 then 'table'
                when type = 2 then 'view'
                else 'external'
            end as table_type,

            REGEXP_CONTAINS(table_id, '^.+[0-9]{8}$') and coalesce(type, 0) = 1 as is_date_shard,
            REGEXP_EXTRACT(table_id, '^(.+)[0-9]{8}$') as shard_base_name,
            REGEXP_EXTRACT(table_id, '^.+([0-9]{8})$') as shard_name

        from `poc-dbt-310711`.`dbt_poc_ds`.__TABLES__
        where (upper(dataset_id) = upper('dbt_poc_ds'))
    ),

    extracted as (

        select *,
            case
                when is_date_shard then shard_base_name
                else original_table_name
            end as table_name

        from tables

    ),

    unsharded_tables as (

        select
            table_database,
            table_schema,
            table_name,
            coalesce(table_type, 'external') as table_type,
            is_date_shard,

            struct(
                min(shard_name) as shard_min,
                max(shard_name) as shard_max,
                count(*) as shard_count
            ) as table_shards,

            sum(size_bytes) as size_bytes,
            sum(row_count) as row_count,

            max(relation_id) as relation_id

        from extracted
        group by 1,2,3,4,5

    ),

    info_schema_columns as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            table_catalog as table_database,
            table_schema,
            table_name,

            -- use the "real" column name from the paths query below
            column_name as base_column_name,
            ordinal_position as column_index,

            is_partitioning_column,
            clustering_ordinal_position

        from `poc-dbt-310711`.`dbt_poc_ds`.INFORMATION_SCHEMA.COLUMNS
        where ordinal_position is not null

    ),

    info_schema_column_paths as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            field_path as column_name,
            data_type as column_type,
            column_name as base_column_name,
            description as column_comment

        from `poc-dbt-310711`.`dbt_poc_ds`.INFORMATION_SCHEMA.COLUMN_FIELD_PATHS

    ),

    columns as (

        select * except (base_column_name)
        from info_schema_columns
        join info_schema_column_paths using (relation_id, base_column_name)

    ),

    column_stats as (

        select
            table_database,
            table_schema,
            table_name,
            max(relation_id) as relation_id,
            max(case when is_partitioning_column = 'YES' then 1 else 0 end) = 1 as is_partitioned,
            max(case when is_partitioning_column = 'YES' then column_name else null end) as partition_column,
            max(case when clustering_ordinal_position is not null then 1 else 0 end) = 1 as is_clustered,
            array_to_string(
                array_agg(
                    case
                        when clustering_ordinal_position is not null then column_name
                        else null
                    end ignore nulls
                    order by clustering_ordinal_position
                ), ', '
            ) as clustering_columns

        from columns
        group by 1,2,3

    )

    select
        unsharded_tables.table_database,
        unsharded_tables.table_schema,
        case
            when is_date_shard then concat(unsharded_tables.table_name, '*')
            else unsharded_tables.table_name
        end as table_name,
        unsharded_tables.table_type,

        -- coalesce name and type for External tables - these columns are not
        -- present in the COLUMN_FIELD_PATHS resultset
        coalesce(columns.column_name, '<unknown>') as column_name,
        -- invent a row number to account for nested fields -- BQ does
        -- not treat these nested properties as independent fields
        row_number() over (
            partition by relation_id
            order by columns.column_index, columns.column_name
        ) as column_index,
        coalesce(columns.column_type, '<unknown>') as column_type,
        columns.column_comment,

        'Shard count' as `stats__date_shards__label`,
        table_shards.shard_count as `stats__date_shards__value`,
        'The number of date shards in this table' as `stats__date_shards__description`,
        is_date_shard as `stats__date_shards__include`,

        'Shard (min)' as `stats__date_shard_min__label`,
        table_shards.shard_min as `stats__date_shard_min__value`,
        'The first date shard in this table' as `stats__date_shard_min__description`,
        is_date_shard as `stats__date_shard_min__include`,

        'Shard (max)' as `stats__date_shard_max__label`,
        table_shards.shard_max as `stats__date_shard_max__value`,
        'The last date shard in this table' as `stats__date_shard_max__description`,
        is_date_shard as `stats__date_shard_max__include`,

        '# Rows' as `stats__num_rows__label`,
        row_count as `stats__num_rows__value`,
        'Approximate count of rows in this table' as `stats__num_rows__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_rows__include`,

        'Approximate Size' as `stats__num_bytes__label`,
        size_bytes as `stats__num_bytes__value`,
        'Approximate size of table as reported by BigQuery' as `stats__num_bytes__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_bytes__include`,

        'Partitioned By' as `stats__partitioning_type__label`,
        partition_column as `stats__partitioning_type__value`,
        'The partitioning column for this table' as `stats__partitioning_type__description`,
        is_partitioned as `stats__partitioning_type__include`,

        'Clustered By' as `stats__clustering_fields__label`,
        clustering_columns as `stats__clustering_fields__value`,
        'The clustering columns for this table' as `stats__clustering_fields__description`,
        is_clustered as `stats__clustering_fields__include`

    -- join using relation_id (an actual relation, not a shard prefix) to make
    -- sure that column metadata is picked up through the join. This will only
    -- return the column information for the "max" table in a date-sharded table set
    from unsharded_tables
    left join columns using (relation_id)
    left join column_stats using (relation_id)
  
2021-04-14 12:05:37.672886 (MainThread): 17:35:37 | Catalog written to /home/msonowal/development/dbt-poc/target/catalog.json
2021-04-14 12:05:37.673023 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6cf5b53940>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6cf01be0a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6cf01be7c0>]}
2021-04-14 12:05:37.673133 (MainThread): Flushing usage events
2021-04-14 12:05:38.628240 (MainThread): Connection 'generate_catalog' was properly closed.
2021-04-14 12:05:38.628598 (MainThread): Connection 'poc-dbt-310711.information_schema' was properly closed.
2021-04-14 12:05:48.416881 (MainThread): Running with dbt=0.19.1
2021-04-14 12:05:48.549455 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.serve.ServeTask'>, debug=False, defer=None, log_cache_events=False, log_format='default', open_browser=True, partial_parse=None, port=8080, profile=None, profiles_dir='/home/msonowal/.dbt', project_dir=None, record_timing_info=None, rpc_method=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, use_cache=True, use_colors=None, vars='{}', warn_error=False, which='serve', write_json=True)
2021-04-14 12:05:48.550122 (MainThread): Tracking: tracking
2021-04-14 12:05:48.555882 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6f8e313520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6f8fd13190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6f8e3119d0>]}
2021-04-14 12:05:48.556936 (MainThread): Serving docs at 0.0.0.0:8080
2021-04-14 12:05:48.557004 (MainThread): To access from your browser, navigate to:  http://localhost:8080
2021-04-14 12:05:48.557043 (MainThread): Press Ctrl+C to exit.


2021-04-14 12:05:53.592806 (MainThread): subprocess 16920 is still running
2021-04-14 12:10:17.123308 (MainThread): Flushing usage events
2021-04-14 12:10:18.091651 (MainThread): ctrl-c
